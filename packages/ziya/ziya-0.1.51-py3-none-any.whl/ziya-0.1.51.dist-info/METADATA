Metadata-Version: 2.1
Name: ziya
Version: 0.1.51
Summary: 
Author: Vishnu Krishnaprasad
Author-email: vishnukool@gmail.com
Requires-Python: >=3.9,<4.0
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Dist: boto3 (>=1.34.88,<2.0.0)
Requires-Dist: jinja2 (>=3.1.3,<4.0.0)
Requires-Dist: langchain (>=0.3,<0.4)
Requires-Dist: langchain-anthropic (>=0.2,<0.3)
Requires-Dist: langchain-aws (>=0.2,<0.3)
Requires-Dist: langchain-cli (>=0.0.15)
Requires-Dist: langchain-community (>=0.3.1,<0.4.0)
Requires-Dist: langchain-google-genai (>=2.0.11,<3.0.0)
Requires-Dist: langchainhub (>=0.1.15)
Requires-Dist: langgraph (>=0.2,<0.3)
Requires-Dist: patch-ng (>=1.17)
Requires-Dist: pydantic (>=2.9.2,<3.0.0)
Requires-Dist: pydevd-pycharm (>=243.18137.19,<244.0.0)
Requires-Dist: tiktoken (>=0.8.0,<0.9.0)
Requires-Dist: transformers (>=4.36.2,<5.0.0)
Requires-Dist: uvicorn (>=0.23.2,<0.24.0)
Requires-Dist: whatthepatch (>=1.0.2)
Description-Content-Type: text/markdown

# Ziya

## Documentation
See the [GitHub Repository](https://github.com/ziya-ai/ziya)

## Overview
Ziya is a code assist tool for AWS Bedrock models. It can read your entire codebase and answer questions.

The current version only performs read operations. However, future versions will be able to:

1. Write and edit code.
2. Search the web for resources.
3. Run commands locally.
4. Iteratively continue to do 1,2,3 for a given objective. 

## Pre-requisites
### Setup AWS credentials:
The easiest way is to set the env variables with access to AWS Bedrock claude models.

```bash
export AWS_ACCESS_KEY_ID=<YOUR-KEY>
export AWS_SECRET_ACCESS_KEY=<YOUR-SECRET>
```
### Installation

```bash
pip install ziya
```

## Run Ziya

```bash 
ziya
```
Then navigate to http://localhost:6969 in your browser and start chatting with your codebase. 

When you ask a question Ziya sends your entire codebase as context to the LLM, along with your question and any chat history.
```
> Entering new AgentExecutor chain...
Reading user's current codebase: /Users/vkrishnaprasad/personal_projects/ziya
ziya
    ├── .gitignore
    ├── DEVELOPMENT.md
    ├── LICENSE
    ├── README.md
    └── pyproject.toml
    app
        ├── __init__.py
        ├── main.py
        └── server.py
...
```

### Options

`--exclude`: Comma-separated list of files or directories or file suffix patterns to exclude from the codebase. Eg: "--exclude 'tst,build,*.py'"

`--profile`: AWS profile to use for the Bedrock LLM.

`--model`: The AWS Bedrock Model to use, one of `sonnet3.5-v2`(default), `sonnet3.5`, `sonnet`, `haiku` or `opus`.

`--port`: The port number for frontend app. Default is `6969`.

`--max-depth`: Maximum depth for folder structure traversal. Default is `15`.

```bash
ziya --exclude='tst,build,*.py' --profile=ziya --model=sonnet3.5 --port=8080
```

