{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the easy_search.yaml defaults file\n",
    "easy_search_yaml_path = Path(\"/Users/heispv/Documents/pymseqs/pymmseqs/defaults/easy_search.yaml\")\n",
    "\n",
    "with open(easy_search_yaml_path, \"r\") as f:\n",
    "    defaults = yaml.safe_load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [\"easy-search\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_arg(\n",
    "    args,\n",
    "    flag,\n",
    "    value,\n",
    "    default,\n",
    "):\n",
    "    if value != default:\n",
    "        if isinstance(value, bool):\n",
    "            args.extend([flag, \"1\" if value else \"0\"])\n",
    "        else:\n",
    "            args.extend([flag, str(value)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed_sub_mat: aa:VTML80.out,nucl:nucleotide.out\n",
      "Not default\n",
      "split_memory_limit: 0\n",
      "is default: False\n",
      "\n",
      "Not default\n",
      "Checking comma_separated_str\n",
      "Not default\n",
      "Not default\n"
     ]
    }
   ],
   "source": [
    "twin_argument = \"aa:VTML80.out,nucl:nucleotide.ut\"\n",
    "comma_separated_str = \"query, target, fident,alnlen,mismatch,gapopen,qend,qstart,tstart,tend,evalue,bits\"\n",
    "split_memory_limit = \"2M\"\n",
    "required_args = [\"input1.fasta\", \"input2.fasta\", \"output.fasta\"]\n",
    "my_v = 1\n",
    "\n",
    "for param_name, param_info in defaults.items():\n",
    "        if param_info['required']:\n",
    "            if param_name == \"query_fasta\": \n",
    "                if isinstance(required_args, list):\n",
    "                    for arg in required_args:\n",
    "                        args.append(arg)\n",
    "                else:\n",
    "                    args.append(str(required_args))\n",
    "            \n",
    "        if param_info['required'] == False:\n",
    "\n",
    "            # Check if the parameter name is a single character\n",
    "            if len(param_name) > 1:\n",
    "                cmd_param = f\"--{param_name.replace('_', '-')}\"\n",
    "            else:\n",
    "                cmd_param = f\"-{param_name}\"\n",
    "            \n",
    "\n",
    "            default_value = param_info['default']\n",
    "            # Checking twin arguments\n",
    "            if param_info['twin']:\n",
    "                if param_name == \"seed_sub_mat\":\n",
    "                    is_default_twin = twin_argument == default_value\n",
    "                    if not is_default_twin:\n",
    "                        add_arg(args, cmd_param, twin_argument, default_value)\n",
    "\n",
    "            # Checking comma_separated_str\n",
    "            elif param_info['type'] == \"comma_separated_str\":\n",
    "                if param_name == \"format_output\":\n",
    "                    default_list = [item.strip() for item in default_value.split(\",\")]\n",
    "                    argument_list = [item.strip() for item in comma_separated_str.split(\",\")]\n",
    "                    is_default = default_list == argument_list\n",
    "                    if not is_default:\n",
    "                        add_arg(args, cmd_param, ','.join(argument_list), default_value)\n",
    "            \n",
    "            elif param_info['type'] == \"str\":\n",
    "                if param_name == \"split_memory_limit\":\n",
    "                    is_default = split_memory_limit == default_value\n",
    "                    if not is_default:\n",
    "                        add_arg(args, cmd_param, split_memory_limit, default_value)\n",
    "            \n",
    "            else:\n",
    "                if param_name == \"v\":\n",
    "                    is_default = my_v == default_value\n",
    "                    if not is_default:\n",
    "                        add_arg(args, cmd_param, my_v, default_value)\n",
    "\n",
    "\n",
    "           \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['easy-search',\n",
       " 'input1.fasta',\n",
       " 'input2.fasta',\n",
       " 'output.fasta',\n",
       " '--seed-sub-mat',\n",
       " 'aa:VTML80.out,nucl:nucleotide.ut',\n",
       " '--split-memory-limit',\n",
       " '2M',\n",
       " '--format-output',\n",
       " 'query,target,fident,alnlen,mismatch,gapopen,qend,qstart,tstart,tend,evalue,bits',\n",
       " '-v',\n",
       " '1']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_value = \"1,2,3,     5\"\n",
    "default_value = \"1,2,3\"\n",
    "args = []\n",
    "cmd_param = \"-f\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_list = [item.strip() for item in str(current_value).split(\",\")]\n",
    "default_list = [item.strip() for item in str(default_value).split(\",\")]\n",
    "if current_list != default_list:\n",
    "    cleaned_value = \",\".join(current_list)\n",
    "    args.extend([cmd_param, cleaned_value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-f', '1,2,3,5']"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML file has been generated successfully!\n"
     ]
    }
   ],
   "source": [
    "import yaml\n",
    "import re\n",
    "\n",
    "\n",
    "def parse_argument(argument_line):\n",
    "    \"\"\"\n",
    "    Parse each argument in the documentation line and return a dictionary containing all the necessary details.\n",
    "    \"\"\"\n",
    "    # Matching pattern for command-line arguments\n",
    "    pattern = r'(--?[a-zA-Z0-9_-]+)\\s*(\\s+[A-Za-z]+)?\\s*(\\[\\S+\\])?\\s*(\\[\\S+.*\\])?'\n",
    "\n",
    "    match = re.match(pattern, argument_line.strip())\n",
    "    if not match:\n",
    "        return None\n",
    "\n",
    "    # Extract matched groups\n",
    "    option_name = match.group(1).strip()\n",
    "    data_type = match.group(2).strip() if match.group(2) else None\n",
    "    default_value = match.group(3).strip() if match.group(3) else None\n",
    "    description = match.group(4).strip() if match.group(4) else \"\"\n",
    "\n",
    "    # Determine if required\n",
    "    required = \"<\" in option_name and \">\" in option_name\n",
    "    should_exist = required and \"i:\" in option_name\n",
    "\n",
    "    # Set the argument type, defaults to 'str'\n",
    "    if data_type:\n",
    "        data_type = data_type.strip()\n",
    "\n",
    "    # Extract possible choices\n",
    "    choices = []\n",
    "    choices_pattern = r'(\\d+):\\s*([^\\[]+)'\n",
    "    choices_match = re.findall(choices_pattern, description)\n",
    "    if choices_match:\n",
    "        choices = [int(choice[0]) for choice in choices_match]\n",
    "\n",
    "    return {\n",
    "        \"name\": option_name.replace('-', '_'),\n",
    "        \"required\": required,\n",
    "        \"type\": \"path\" if data_type and \"path\" in data_type.lower() else \"str\",  # Default to 'str' unless it's a path\n",
    "        \"description\": description.strip(),\n",
    "        \"default\": default_value.strip() if default_value else None,\n",
    "        \"choices\": choices if choices else None,\n",
    "        \"twin\": \"TWIN\" in argument_line,\n",
    "        \"should_exist\": should_exist\n",
    "    }\n",
    "\n",
    "\n",
    "def parse_documentation(doc_str):\n",
    "    \"\"\"\n",
    "    Parses the documentation string to extract command-line arguments.\n",
    "    \"\"\"\n",
    "    lines = doc_str.splitlines()\n",
    "    argument_lines = []\n",
    "\n",
    "    in_options = False\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "\n",
    "        if line.lower().startswith('options:'):\n",
    "            in_options = True\n",
    "            continue\n",
    "        elif in_options and (line.startswith('--') or line.startswith('-')):\n",
    "            argument_lines.append(line)\n",
    "        elif in_options and not line.startswith(' ') and line != \"\":\n",
    "            break  # End of options section\n",
    "\n",
    "    # Parse the arguments\n",
    "    parsed_arguments = []\n",
    "    for arg_line in argument_lines:\n",
    "        parsed_arg = parse_argument(arg_line)\n",
    "        if parsed_arg:\n",
    "            parsed_arguments.append(parsed_arg)\n",
    "\n",
    "    return parsed_arguments\n",
    "\n",
    "\n",
    "def generate_yaml(parsed_arguments, output_file):\n",
    "    \"\"\"\n",
    "    Generates the YAML configuration file based on parsed arguments.\n",
    "    \"\"\"\n",
    "    yaml_data = {}\n",
    "    for arg in parsed_arguments:\n",
    "        arg_data = {\n",
    "            \"required\": arg[\"required\"],\n",
    "            \"type\": arg[\"type\"],\n",
    "            \"default\": arg[\"default\"] or \"\",\n",
    "            \"choices\": arg[\"choices\"] or None,\n",
    "            \"description\": arg[\"description\"],\n",
    "            \"twin\": arg[\"twin\"],\n",
    "            \"should_exist\": arg[\"should_exist\"]\n",
    "        }\n",
    "        yaml_data[arg[\"name\"]] = arg_data\n",
    "\n",
    "    with open(output_file, \"w\") as file:\n",
    "        yaml.dump(yaml_data, file, default_flow_style=False)\n",
    "\n",
    "\n",
    "\n",
    "# Example usage\n",
    "\n",
    "# Load the documentation (replace this with your actual documentation)\n",
    "documentation = \"\"\"\n",
    "usage: mmseqs easy-cluster <i:fastaFile1[.gz|.bz2]> ... <i:fastaFileN[.gz|.bz2]> <o:clusterPrefix> <tmpDir> [options]\n",
    " By Martin Steinegger <martin.steinegger@snu.ac.kr>\n",
    "options: prefilter:                      \n",
    " --seed-sub-mat TWIN              Substitution matrix file for k-mer generation [aa:VTML80.out,nucl:nucleotide.out]\n",
    " -s FLOAT                         Sensitivity: 1.0 faster; 4.0 fast; 7.5 sensitive [4.000]\n",
    " -k INT                           k-mer length (0: automatically set to optimum) [0]\n",
    " --target-search-mode INT         target search mode (0: regular k-mer, 1: similar k-mer) [0]\n",
    " --k-score TWIN                   k-mer threshold for generating similar k-mer lists [seq:2147483647,prof:2147483647]\n",
    " --alph-size TWIN                 Alphabet size (range 2-21) [aa:21,nucl:5]\n",
    " --max-seqs INT                   Maximum results per query sequence allowed to pass the prefilter (affects sensitivity) [20]\n",
    " --split INT                      Split input into N equally distributed chunks. 0: set the best split automatically [0]\n",
    " --split-mode INT                 0: split target db; 1: split query db; 2: auto, depending on main memory [2]\n",
    " --split-memory-limit BYTE        Set max memory per split. E.g. 800B, 5K, 10M, 1G. Default (0) to all available system memory [0]\n",
    " --comp-bias-corr INT             Correct for locally biased amino acid composition (range 0-1) [1]\n",
    " --comp-bias-corr-scale FLOAT     Correct for locally biased amino acid composition (range 0-1) [1.000]\n",
    " --diag-score BOOL                Use ungapped diagonal scoring during prefilter [1]\n",
    " --exact-kmer-matching INT        Extract only exact k-mers for matching (range 0-1) [0]\n",
    " --mask INT                       Mask sequences in prefilter stage with tantan: 0: w/o low complexity masking, 1: with low complexity masking [1]\n",
    " --mask-prob FLOAT                Mask sequences if probability is above threshold [0.900]\n",
    " --mask-lower-case INT            Lowercase letters will be excluded from k-mer search 0: include region, 1: exclude region [0]\n",
    " --mask-n-repeat INT              Repeat letters that occur > threshold in a row [0]\n",
    " --min-ungapped-score INT         Accept only matches with ungapped alignment score above threshold [15]\n",
    " --add-self-matches BOOL          Artificially add entries of queries with themselves (for clustering) [0]\n",
    " --spaced-kmer-mode INT           0: use consecutive positions in k-mers; 1: use spaced k-mers [1]\n",
    " --spaced-kmer-pattern STR        User-specified spaced k-mer pattern []\n",
    " --local-tmp STR                  Path where some of the temporary files will be created []\n",
    "align:\n",
    " -c FLOAT                         List matches above this fraction of aligned (covered) residues (see --cov-mode) [0.800]\n",
    " --cov-mode INT                   0: coverage of query and target\n",
    "                                  1: coverage of target\n",
    "                                  2: coverage of query\n",
    "                                  3: target seq. length has to be at least x% of query length\n",
    "                                  4: query seq. length has to be at least x% of target length\n",
    "                                  5: short seq. needs to be at least x% of the other seq. length [0]\n",
    " --alignment-mode INT             How to compute the alignment: 0 automatic, 1 only score and end_pos, 2 also start_pos and cov, 3 also seq.id, 4 only ungapped alignment [3]\n",
    " --alignment-output-mode INT      How to compute the alignment: 0 automatic, 1 only score and end_pos, 2 also start_pos and cov, 3 also seq.id, 4 only ungapped alignment [0]\n",
    " --wrapped-scoring BOOL           Double the (nucleotide) query sequence during the scoring process to allow wrapped diagonal scoring around end and start [0]\n",
    "\"\"\"\n",
    "\n",
    "# Parse the documentation and generate YAML\n",
    "parsed_args = parse_documentation(documentation)\n",
    "generate_yaml(parsed_args, 'testing.yaml')\n",
    "\n",
    "print(\"YAML file has been generated successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
