from bioscience.base import *

import math
import sys
import os
import threading
import warnings
import numpy as np
import time

def nmi(dataset, deviceCount = 0, mode = 1, debug = False):
    """
    Application of the Normalized Mutual Information (NMI) correlation method.
    
    :param dataset: The dataset object to be binarized.
    :type dataset: :class:`bioscience.base.models.Dataset`
    
    param deviceCount: Number of GPU devices to execute
    :type deviceCount: int
    
    :param mode: Type of execution of the algorithm: `mode=1` for sequential execution, `mode=2` for parallel execution on CPUs and `mode=3` for execution on a multi-GPU architecture.
    :type mode: int
    
    :return: A CorrelationModel object that stores values generated by a correlation method.
    :rtype: :class:`bioscience.base.models.CorrelationModel`      
    """ 
    
    oModel = None
    if (dataset is not None):
        sMode = ""
        if mode == 2: # NUMBA: CPU Parallel mode
            # To be developed
            sMode = "NUMBA - CPU Parallel mode (to be developed)"
        elif mode == 3: # NUMBA: GPU Parallel mode
            # To be developed
            sMode = "NUMBA - GPU Parallel mode (to be developed)"
        else: # Sequential mode
            oModel = __nmiSequential(dataset, debug)
            deviceCount = 0
            sMode = "CPU Sequential"
    
    return oModel

def __normalizedNmi(dataset):    
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    maxValueDataset = -1
    dataNormalized = np.zeros((iRows,iCols+1), dtype=np.int64)
    for ulCountRow in range(iRows):
        maxValue = np.int64(np.floor(dataset.data[ulCountRow][0]))
        minValue = np.int64(np.floor(dataset.data[ulCountRow][0]))
        for ulCountCol in range(iCols):
            iExp = np.int64(np.floor(dataset.data[ulCountRow][ulCountCol]))
            dataNormalized[ulCountRow][ulCountCol] = iExp     
            if iExp < minValue:
                minValue = iExp
            if iExp > maxValue:
                maxValue = iExp
        
        for ulCountCol in range(iCols):
            dataNormalized[ulCountRow][ulCountCol] = dataset.data[ulCountRow][ulCountCol] - minValue
        
        maxValue = maxValue - minValue + 1
        dataNormalized[ulCountRow][iCols] = maxValue
        if maxValueDataset < maxValue:
            maxValueDataset = maxValue
    
    return dataNormalized, maxValueDataset
        

def __nmiSequential(dataset, debug):
    iRows = dataset.data.shape[0]
    iCols = dataset.data.shape[1]
    fExecutionTime = None
    
    maxPairs = 0
    for i in range(iRows):
        for j in range(i + 1, iRows):
            maxPairs += 1
            
    # Get maxValueDataset and dataNormalized
    dataNormalized, maxValueDataset = __normalizedNmi(dataset)
    nmiResults = np.full((maxPairs,((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)),-1, dtype=np.float64) # [0] --> Mutual information ::: NMI [1] --> entropyGen1 ::: [2] --> entropyGen2 ::: [3 - maxValueDataset] --> probMaps
    
    if debug == True:
        start_time = time.time()
    
    pattern = 0
    while pattern < maxPairs:
        
        # Get R1 and R2 from index results vector
        r1 = 0
        r2 = -1
        auxPat = pattern - iRows + 1
        
        if auxPat < 0:
            r2 = auxPat + iRows

        j = iRows - 2
        while r2 == -1:
            auxPat -= j
            r1 += 1
            if auxPat < 0:
                r2 = (j + auxPat) + (r1 + 1)
            j -= 1
        
        if r1 < iRows and r2 < iRows:
            
            # NMI: Calculation mutual information
            for iColumn in range(iCols):
                valGen1Column = dataNormalized[r1][iColumn]
                valGen2Column = dataNormalized[r2][iColumn]                
                nmiResults[pattern][valGen1Column + 3] += 1
                nmiResults[pattern][maxValueDataset + 3 + valGen2Column] += 1
                nmiResults[pattern][(valGen1Column + maxValueDataset * valGen2Column) + (maxValueDataset + maxValueDataset) + 3] += 1           

            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                if nmiResults[pattern][i] != -1:
                    nmiResults[pattern][i] = (nmiResults[pattern][i] + 1) / iCols   
                    
            mi = 0.0
            for iCont in range(maxValueDataset * maxValueDataset):
                index = (maxValueDataset + maxValueDataset) + 3 + iCont
                if nmiResults[pattern][index] > 0:
                    doubleValue = nmiResults[pattern][index]
                    doubleValue2 = nmiResults[pattern][(iCont % maxValueDataset) + 3]
                    doubleValue3 = nmiResults[pattern][(iCont // maxValueDataset) + 3 + maxValueDataset]
                    if doubleValue > 0 and doubleValue2 > 0 and doubleValue3 > 0:
                        mi += doubleValue * math.log(doubleValue / (doubleValue2 * doubleValue3))

            mi /= math.log(2)
            nmiResults[pattern][0] = mi
            
            # NMI: Calculation entropy
            maxValGene1 = dataNormalized[r1][iCols]
            maxValGene2 = dataNormalized[r2][iCols]
            
            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                nmiResults[pattern][i] = -1
            
            for iColumn in range(iCols):
                valGen1Column = int(np.floor(dataNormalized[r1][iColumn]))
                valGen2Column = int(np.floor(dataNormalized[r2][iColumn]))
                nmiResults[pattern][valGen1Column + 3] += 1
                nmiResults[pattern][maxValueDataset + 3 + valGen2Column] += 1
            
            for i in range(3, ((maxValueDataset + maxValueDataset) + (maxValueDataset * maxValueDataset) + 3)):
                if nmiResults[pattern][i] != -1:
                    nmiResults[pattern][i] = (nmiResults[pattern][i] + 1) / iCols
            
            dEntropyG1 = 0.0
            for i in range(maxValGene1):
                varAuxG1 = nmiResults[pattern][3 + i]
                if varAuxG1 > 0:
                    dEntropyG1 -= varAuxG1 * math.log(varAuxG1)

            dEntropyG2 = 0.0
            for i in range(maxValGene2):
                varAuxG2 = nmiResults[pattern][3 + i + maxValueDataset]
                if varAuxG2 > 0:
                    dEntropyG2 -= varAuxG2 * math.log(varAuxG2)
            
            dEntropyG1 /= math.log(2)
            dEntropyG2 /= math.log(2)

            nmiResults[pattern][1] = dEntropyG1
            nmiResults[pattern][2] = dEntropyG2
            
            # Get calculation value
            denom = (nmiResults[pattern][1] + nmiResults[pattern][2])
            if denom == 0:
                dNMI = None
            else:
                dNMI = 2.0 * nmiResults[pattern][0] / denom                    
            
            nmiResults[pattern][0] = dNMI
                
        pattern += 1
    
    if debug == True:
        end_time = time.time()
        fExecutionTime = end_time - start_time
    
    oCorrelationResults = CorrelationModel(name=NMI, results=nmiResults[:,0], rows = iRows, executionTime=fExecutionTime)
    return oCorrelationResults