Various services that are integrated with Harbor. The link in the service name will lead you to a dedicated page in Harbor's wiki with details on getting started with the service.

# Frontends

This section covers services that can provide you with an interface for interacting with the language models.

- [Open WebUI](./2.1.1-Frontend:-Open-WebUI)<br/>
widely adopted and feature rich web interface for interacting with LLMs. Supports OpenAI-compatible and Ollama backends, multi-users, multi-model chats, custom prompts, TTS, Web RAG, RAG, and much much more.

- [ComfyUI](./2.1.2-Frontend:-ComfyUI)<br/>
The most powerful and modular diffusion model GUI, api and backend with a graph/nodes interface.

- [LibreChat](./2.1.3-Frontend:-LibreChat)<br/>
Open-source ChatGPT UI alternative supporting multiple AI providers (Anthropic, AWS, OpenAI, Azure, Groq, Mistral, Google) with features like model switching, message search, and multi-user support. Includes integration with DALL-E-3 and various APIs.

- [HuggingFace ChatUI](./2.1.4-Frontend:-ChatUI)<br/>
A chat interface using open source models, eg OpenAssistant or Llama. It is a SvelteKit app and it [powers the HuggingChat app on hf.co/chat](https://huggingface.co/chat/).

- [Lobe Chat](./2.1.5-Frontend:-Lobe-Chat)<br/>
An open-source, modern-design AI chat framework. Supports Multi AI Providers( OpenAI / Claude 3 / Gemini / Ollama / Azure / DeepSeek), Knowledge Base (file upload / knowledge management / RAG ), Multi-Modals (Vision/TTS) and plugin system.

- [hollama](./2.1.6-Frontend:-hollama)<br/>
A minimal web-UI for talking to Ollama servers.

- [parllama](./2.1.7-Frontend:-parllama)<br/>
TUI for Ollama

- [BionicGPT](./2.1.8-Frontend:-BionicGPT)<br/>
on-premise LLM web UI with support for OpenAI-compatible backends

- [AnythingLLM](./2.1.9-Frontend:-AnythingLLM)<br/>
The all-in-one Desktop & Docker AI application with built-in RAG, AI agents, and more.

- [Chat Nio](./2.1.10-Frontend:-Chat-Nio)<br/>
Comprehensive LLM web interface with built-in marketplace

- [Mikupad](./2.1.11-Frontend:-Mikupad)<br/>
LLM Frontend in a single HMTL file

# Backends

This section covers services that provide the LLM inference capabilities.

- [Ollama](./2.2.1-Backend:-Ollama)<br/>
Get up and running with Llama 3.2, Mistral, Gemma 2, and other large language models.

- [llama.cpp](./2.2.2-Backend:-llama.cpp)<br/>
LLM inference in C/C++

- [vLLM](./2.2.3-Backend:-vLLM)<br/>
A high-throughput and memory-efficient inference and serving engine for LLMs

- [TabbyAPI](./2.2.4-Backend:-TabbyAPI)<br/>
An OAI compatible exllamav2 API that's both lightweight and fast

- [Aphrodite Engine](./2.2.5-Backend:-Aphrodite-Engine)<br/>
Large-scale LLM inference engine

- [mistral.rs](./2.2.6-Backend:-mistral.rs)<br/>
Blazingly fast LLM inference.

- [openedai-speech](./2.2.7-Backend:-openedai-speech)<br/>
An OpenAI API compatible text to speech server using Coqui AI's xtts_v2 and/or piper tts as the backend.

- [Parler](./2.2.8-Backend:-Parler)<br/>
Inference and training library for high-quality TTS models.

- [text-generation-inference](./2.2.9-Backend:-text-generation-inference)<br/>
Inference engine from HuggingFace.

- [lmdeploy](./2.2.10-Backend:-lmdeploy)

- [AirLLM](./2.2.11-Backend:-AirLLM)<br/>
70B inference with single 4GB GPU (very slow, though)

- [SGLang](./2.2.12-Backend:-SGLang)<br/>
SGLang is a fast serving framework for large language models and vision language models.

- [ktransformers](./2.2.13-Backend:-KTransformers)<br/>
A Flexible Framework for Experiencing Cutting-edge LLM Inference Optimizations

- [Speaches, aka Faster Whisper Server](./2.2.14-Backend:-Speaches)<br/>
an OpenAI API-compatible speech server (formerly `faster-whisper-server`), both TTS and STT

- [Nexa SDK](./2.2.15-Backend:-Nexa-SDK)<br/>
Nexa SDK is a comprehensive toolkit for supporting ONNX and GGML models.

- [KoboldCpp](./2.2.16-Backend:-KoboldCpp)<br/>
KoboldCpp is an easy-to-use AI text-generation software for GGML and GGUF models.

# Satellite services

Additional services that can be integrated with various Frontends and Backends to enable more features.

- [SearXNG](./2.3.1-Satellite:-SearXNG)<br/>
A privacy-respecting, hackable metasearch engine. Highly configurable and can be used for Web RAG use-cases.

- [Perplexica](./2.3.2-Satellite:-Perplexica)<br/>
An AI-powered search engine. It is an Open source alternative to Perplexity AI.

- [Dify](./2.3.3-Satellite:-Dify)<br/>
An open-source LLM app development platform.

- [Plandex](./2.3.4-Satellite:-Plandex)<br/>
AI driven development in your terminal.

- [üöÖ LiteLLM](./2.3.5-Satellite:-LiteLLM)<br/>
LLM proxy that can aggregate multiple inference APIs together into a single endpoint.

- [langfuse](./2.3.6-Satellite:-langfuse)<br/>
Open source LLM engineering platform: LLM Observability, metrics, evals, prompt management, playground, datasets.

- [‚óè Open Interpreter](./2.3.7-Satellite:-Open-Interpreter)<br/>
A natural language interface for computers.

- [cloudflared](./2.3.8-Satellite:-cloudflared)<br/>
A helper service allowing to expose Harbor services over the internet.

- [cmdh](./2.3.9-Satellite:-cmdh)<br/>
Create Linux commands from natural language, in the shell.

- [fabric](./2.3.10-Satellite:-fabric)<br/>
LLM-driven processing of the text data in the terminal.

- [txtai RAG](./2.3.11-Satellite:-txtai-RAG)<br/>
RAG WebUI built with txtai.

- [TextGrad](./2.3.12-Satellite:-TextGrad)<br/>
Automatic "Differentiation" via Text - using large language models to backpropagate textual gradients.

- [aider](./2.3.13-Satellite:-aider)<br/>
Aider is AI pair programming in your terminal.

- [aichat](./2.3.14-Satellite:-aichat)<br/>
All-in-one LLM CLI tool featuring Shell Assistant, Chat-REPL, RAG, AI tools & agents.

- [autogpt](./2.3.15-Satellite:-AutoGPT)<br/>
Create, deploy, and manage continuous AI agents that automate complex workflows.

- [omnichain](./2.3.16-Satellite:-omnichain)<br/>
Visual programming for AI language models

- [Harbor Bench](./5.1.-Harbor-Bench)<br/>
Harbor's own tool to evaluate LLMs and inference backends against custom tasks.

- [lm-evaluation-harness](./2.3.17-Satellite:-lm-evaluation-harness)<br/>
A de-facto standard framework for the few-shot evaluation of language models.

- [JupyterLab](./2.3.18-Satellite:-JupyterLab)<br/>
Helper service to author/run Jupyter notebooks in Python with access to Harbor services.

- [ol1](./2.3.19-Satellite:-ol1)<br/>
A simple Gradio app implementing an o1-like chain of reasoning with Ollama.

- [Harbor Boost](./5.2.-Harbor-Boost)<br/>
Connects to downstream LLM API and serves a wrapper with custom workflow. For example, it can be used to add a CoT (Chain of Thought) to an existing LLM API, and much more. Scriptable with Python.

- [OpenHands](./2.3.20-Satellite:-OpenHands)<br/>
A platform for software development agents powered by AI.

- [LitLytics](./2.3.21-Satellite:-LitLytics)<br/>
Simple analytics platform that leverages LLMs to automate data analysis.

- [Repopack](./2.3.22-Satellite:-Repopack)<br/>
A powerful tool that packs your entire repository into a single, AI-friendly file.

- [n8n](./2.3.23-Satellite:-n8n)<br/>
Fair-code workflow automation platform with native AI capabilities.

- [Bolt.new](./2.3.24-Satellite:-Bolt.new)<br/>
Prompt, run, edit, and deploy full-stack web applications.

- [Open WebUI Pipelines](./2.3.25-Satellite:-Open-WebUI-Pipelines)<br/>
UI-Agnostic OpenAI API Plugin Framework.

- [Qdrant](./2.3.26-Satellite:-Qdrant)<br/>
Qdrant - High-performance, massive-scale Vector Database and Vector Search Engine.

- [K6](./2.3.27-Satellite:-K6)<br/>
A modern load testing tool, using Go and JavaScript - https://k6.io

- [Promptfoo](./2.3.28-Satellite:-Promptfoo)<br/>
Test your prompts, agents, and RAGs. A developer-friendly local tool for testing LLM applications.

- [Webtop](./2.3.29-Satellite:-Webtop)<br/>
Linux in a web browser supporting popular desktop environments.

- [OmniParser](./2.3.30-Satellite:-OmniParser)<br/>
A simple screen parsing tool towards pure vision based GUI agent.

- [Flowise](./2.3.31-Satellite:-Flowise)<br/>
Drag & drop UI to build your customized LLM flow.

- [LangFlow](./2.3.32-Satellite:-LangFlow)<br/>
A low-code app builder for RAG and multi-agent AI applications.

- [OptiLLM](./2.3.33-Satellite:-OptiLLM)<br/>
Optimising LLM proxy that implements many advanced workflows to boost the performance of the LLMs.

- [Morphic](./2.3.34-Satellite-Morphic)<br/>
An AI-powered search engine with a generative UI, similar to Perplexity and Perplexica.

- [SQL Chat](./2.3.35-Satellite-SQL-Chat)<br/>
Chat-based SQL client, which uses natural language to communicate with the database.

- [gptme](./2.3.36-Satellite-gptme)<br/>
A simple CLI tool to interact with LLMs.

- [traefik](./2.3.37-Satellite-traefik)<br/>
A modern HTTP reverse proxy and load balancer that makes deploying microservices easy.

- [Latent Scope](./2.3.38-Satellite-Latent-Scope)<br/>
A new kind of workflow + tool for visualizing and exploring datasets through the lens of latent spaces.