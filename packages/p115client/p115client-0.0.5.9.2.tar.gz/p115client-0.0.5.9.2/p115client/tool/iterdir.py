#!/usr/bin/env python3
# encoding: utf-8

__author__ = "ChenyangGao <https://chenyanggao.github.io>"
__all__ = [
    "ID_TO_DIRNODE_CACHE", "P115ID", "unescape_115_charref", "posix_escape_name", 
    "type_of_attr", "get_path_to_cid", "get_file_count", "get_ancestors", 
    "get_ancestors_to_cid", "get_id_to_path", "get_id_to_sha1", "get_id_to_pickcode", 
    "iter_nodes_skim", "iter_stared_dirs_raw", "iter_stared_dirs", "ensure_attr_path", 
    "ensure_attr_path_by_category_get", "iterdir_raw", "iterdir", "iterdir_limited", 
    "iter_files_raw", "iter_files", "traverse_files", "iter_dirs", "iter_dupfiles", 
    "iter_image_files", "share_extract_payload", "share_iterdir", "share_iter_files", 
    "iter_selected_nodes", "iter_selected_nodes_by_pickcode", "iter_selected_nodes_using_category_get", 
    "iter_selected_nodes_using_edit", "iter_selected_nodes_using_star_event", 
    "iter_selected_dirs_using_star", "iter_files_with_dirname", "iter_files_with_path", 
    "iter_files_with_path_by_export_dir", "iter_parents_3_level", "iter_dir_nodes", 
]
__doc__ = "è¿™ä¸ªæ¨¡å—æä¾›äº†ä¸€äº›å’Œç›®å½•ä¿¡æ¯ç½—åˆ—æœ‰å…³çš„å‡½æ•°"

from asyncio import create_task, sleep as async_sleep, Lock as AsyncLock
from collections import defaultdict
from collections.abc import (
    AsyncIterable, AsyncIterator, Callable, Collection, Coroutine, Iterable, Iterator, 
    Mapping, Sequence, 
)
from dataclasses import dataclass
from errno import EIO, ENOENT, ENOTDIR
from functools import partial
from itertools import chain, count, cycle, islice, takewhile
from math import inf
from operator import itemgetter
from re import compile as re_compile
from string import digits, hexdigits
from threading import Lock
from time import sleep, time
from types import EllipsisType
from typing import cast, overload, Any, Final, Literal, NamedTuple, TypedDict
from warnings import warn
from weakref import WeakValueDictionary

from asynctools import async_chain, async_filter, async_map, to_list
from concurrenttools import run_as_thread, taskgroup_map, threadpool_map
from iterutils import (
    as_gen_step, bfs_gen, chunked, async_foreach, ensure_aiter, foreach, 
    flatten, iter_unique, run_gen_step, run_gen_step_iter, through, 
    async_through, with_iter_next, Yield, YieldFrom, 
)
from iter_collect import iter_keyed_dups, SupportsLT
from orjson import loads
from p115client import (
    check_response, normalize_attr, normalize_attr_simple, 
    P115Client, P115OSError, P115Warning, 
)
from p115client.const import CLASS_TO_TYPE, SUFFIX_TO_TYPE
from p115client.type import P115DictAttrLike
from posixpatht import joins, path_is_dir_form, splitext, splits

from .edit import update_desc, update_star
from .fs_files import is_timeouterror, iter_fs_files, iter_fs_files_threaded, iter_fs_files_asynchronized
from .life import iter_life_behavior_once, life_show


CRE_SHARE_LINK_search1 = re_compile(r"(?:/s/|share\.115\.com/)(?P<share_code>[a-z0-9]+)\?password=(?:(?P<receive_code>[a-z0-9]{4}))?").search
CRE_SHARE_LINK_search2 = re_compile(r"(?P<share_code>[a-z0-9]+)(?:-(?P<receive_code>[a-z0-9]{4}))?").search
CRE_115_CHARREF_sub = re_compile("\\[\x02([0-9]+)\\]").sub
WEBAPI_BASE_URLS = (
    "http://webapi.115.com", 
    "https://webapi.115.com", 
    "http://webapi.115.com", 
    "http://115cdn.com/webapi", 
    "http://webapi.115.com", 
    "http://115vod.com/webapi", 
)
PROAPI_BASE_URLS = (
    "http://proapi.115.com", 
    "https://proapi.115.com", 
    "http://proapi.115.com", 
    "https://proapi.115.com", 
)
APS_BASE_URLS = (
    "http://115cdn.com/aps", 
    "http://aps.115.com", 
    "http://115vod.com/aps", 
)

_n_get_ancestors = 0
_n_get_count = 0


class DirNode(NamedTuple):
    name: str
    parent_id: int


@dataclass(frozen=True, unsafe_hash=True)
class OverviewAttr:
    is_dir: bool
    id: int
    parent_id: int
    name: str
    ctime: int
    mtime: int
    def __getitem__(self, key, /):
        try:
            return getattr(self, key)
        except AttributeError as e:
            raise LookupError(key) from e


#: ç”¨äºç¼“å­˜æ¯ä¸ªç”¨æˆ·ï¼ˆæ ¹æ®ç”¨æˆ· id åŒºåˆ«ï¼‰çš„æ¯ä¸ªç›®å½• id åˆ°æ‰€å¯¹åº”çš„ (åç§°, çˆ¶id) çš„å…ƒç»„çš„å­—å…¸çš„å­—å…¸
ID_TO_DIRNODE_CACHE: Final[defaultdict[int, dict[int, tuple[str, int] | DirNode]]] = defaultdict(dict)


class SharePayload(TypedDict):
    share_code: str
    receive_code: None | str


def _overview_attr(info: Mapping, /) -> OverviewAttr:
    if "n" in info:
        is_dir = "fid" not in info
        name = info["n"]
        if is_dir:
            id = int(info["cid"])
            pid = int(info["pid"])
        else:
            id = int(info["fid"])
            pid = int(info["cid"])
        ctime = int(info["tp"])
        mtime = int(info["te"])
    elif "fn" in info:
        is_dir = info["fc"] == "0"
        name = info["fn"]
        id = int(info["fid"])
        pid = int(info["pid"])
        ctime = int(info["uppt"])
        mtime = int(info["upt"])
    elif "file_category" in info:
        is_dir = int(info["file_category"]) == 0
        if is_dir:
            name = info["category_name"]
            id = int(info["category_id"])
            pid = int(info["parent_id"])
            ctime = int(info["pptime"])
            mtime = int(info["ptime"])
        else:
            name = info["file_name"]
            id = int(info["file_id"])
            pid = int(info["category_id"])
            ctime = int(info["user_pptime"])
            mtime = int(info["user_ptime"])
    else:
        raise ValueError(f"can't overview attr data: {info!r}")
    return OverviewAttr(is_dir, id, pid, name, ctime, mtime)


def posix_escape_name(name: str, /, repl: str = "|") -> str:
    """æŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸ºå¦ä¸€ä¸ªå­—ç¬¦ï¼ˆé»˜è®¤ä¸º "|"ï¼‰

    :param name: æ–‡ä»¶å
    :param repl: æ›¿æ¢ä¸ºçš„ç›®æ ‡å­—ç¬¦

    :return: æ›¿æ¢åçš„åå­—
    """
    return name.replace("/", repl)


def unescape_115_charref(s: str, /) -> str:
    """å¯¹ 115 çš„å­—ç¬¦å¼•ç”¨è¿›è¡Œè§£ç 

    :example:

        .. code:: python

            unescape_115_charref("[\x02128074]0å·ï¼šä¼˜è´¨èµ„æº") == "ğŸ‘Š0å·ï¼šä¼˜è´¨èµ„æº"
    """
    return CRE_115_CHARREF_sub(lambda a: chr(int(a[1])), s)


def type_of_attr(attr: Mapping, /) -> int:
    """æ¨æ–­æ–‡ä»¶ä¿¡æ¯æ‰€å±ç±»å‹ï¼ˆè¯•éªŒç‰ˆï¼Œæœªå¿…å‡†ç¡®ï¼‰

    :param attr: æ–‡ä»¶ä¿¡æ¯

    :return: è¿”å›ç±»å‹ä»£ç 

        - 0: ç›®å½•
        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: å…¶å®ƒæ–‡ä»¶
"""
    if attr.get("is_dir") or attr.get("is_directory"):
        return 0
    type: None | int
    if type := CLASS_TO_TYPE.get(attr.get("class", "")):
        return type
    if type := SUFFIX_TO_TYPE.get(splitext(attr["name"])[1].lower()):
        return type
    if attr.get("is_video") or "defination" in attr:
        return 4
    return 99


@overload
def get_path_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    root_id: None | int = None, 
    escape: None | bool | Callable[[str], str] = True, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> str:
    ...
@overload
def get_path_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    root_id: None | int = None, 
    escape: None | bool | Callable[[str], str] = True, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, str]:
    ...
def get_path_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    root_id: None | int = None, 
    escape: None | bool | Callable[[str], str] = True, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> str | Coroutine[Any, Any, str]:
    """è·å–ç›®å½•å¯¹åº”çš„è·¯å¾„ï¼ˆç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½•çš„ id
    :param root_id: æ ¹ç›®å½• idï¼Œå¦‚æœæŒ‡å®šæ­¤å‚æ•°ä¸”ä¸ä¸º Noneï¼Œåˆ™è¿”å›ç›¸å¯¹è·¯å¾„ï¼Œå¦åˆ™è¿”å›ç»å¯¹è·¯å¾„
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param refresh: æ˜¯å¦åˆ·æ–°ã€‚å¦‚æœä¸º Trueï¼Œåˆ™ä¼šæ‰§è¡Œç½‘ç»œè¯·æ±‚ä»¥æŸ¥è¯¢ï¼›å¦‚æœä¸º Falseï¼Œåˆ™ç›´æ¥ä» `id_to_dirnode` ä¸­è·å–
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ç›®å½•å¯¹åº”çš„ç»å¯¹è·¯å¾„æˆ–ç›¸å¯¹è·¯å¾„
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    def gen_step():
        nonlocal cid
        parts: list[str] = []
        if cid and (refresh or cid not in id_to_dirnode):
            if app in ("", "web", "desktop", "harmony"):
                resp = yield client.fs_files({"cid": cid, "limit": 1}, async_=async_, **request_kwargs)
            else:
                resp = yield client.fs_files_app({"cid": cid, "hide_data": 1}, async_=async_, **request_kwargs)
            check_response(resp)
            if cid and int(resp["path"][-1]["cid"]) != cid:
                raise FileNotFoundError(ENOENT, cid)
            parts.extend(info["name"] for info in resp["path"][1:])
            for info in resp["path"][1:]:
                id_to_dirnode[int(info["cid"])] = DirNode(info["name"], int(info["pid"]))
        else:
            while cid and (not root_id or cid != root_id):
                name, cid = id_to_dirnode[cid]
                parts.append(name)
            parts.reverse()
        if root_id is not None and cid != root_id:
            return ""
        if escape is None:
            path = "/".join(parts)
        else:
            path = "/".join(map(escape, parts))
        if root_id is None or root_id:
            return "/" + path
        else:
            return path
    return run_gen_step(gen_step, async_=async_)


@overload
def get_file_count(
    client: str | P115Client, 
    cid: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> int:
    ...
@overload
def get_file_count(
    client: str | P115Client, 
    cid: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, int]:
    ...
def get_file_count(
    client: str | P115Client, 
    cid: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> int | Coroutine[Any, Any, int]:
    """è·å–æ–‡ä»¶æ€»æ•°

    .. caution::
        æˆ‘é€šè¿‡ä¸€äº›ç»éªŒï¼Œæ­é…äº†å¤šä¸ªæ¥å£çš„å æ¯”å’Œå‚æ•°åˆ†å¸ƒï¼Œå¯èƒ½ä¸å¤Ÿåˆç†ï¼Œä»¥åä¼šæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ç›®å½•å†…çš„æ–‡ä»¶æ€»æ•°ï¼ˆä¸åŒ…æ‹¬ç›®å½•ï¼‰
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    n_webapi = len(WEBAPI_BASE_URLS)
    n_proapi = len(PROAPI_BASE_URLS)
    n_apsapi = len(APS_BASE_URLS)
    n_api = n_webapi * 2 + n_proapi * 2 + n_apsapi
    def get_resp():
        global _n_get_count
        n = _n_get_count % n_api
        if n < n_webapi:
            _n_get_count += 1
            return client.fs_files(
                {"cid": cid, "limit": 1, "show_dir": 0}, 
                base_url=WEBAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_webapi
        if n < n_proapi:
            _n_get_count += 1
            return client.fs_files_app(
                {"cid": cid, "hide_data": 1, "show_dir": 0}, 
                base_url=PROAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_proapi
        if n < n_apsapi:
            _n_get_count += 1
            return client.fs_files_aps(
                {"cid": cid, "limit": 1, "show_dir": 0}, 
                base_url=APS_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_apsapi
        if n < n_webapi:
            _n_get_count += 1
            return client.fs_category_get(
                cid, 
                base_url=WEBAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_webapi
        _n_get_count += 1
        return client.fs_category_get_app(
            cid, 
            base_url=PROAPI_BASE_URLS[n], 
            async_=async_, 
            **request_kwargs, 
        )
    def gen_step():
        if cid == 0:
            resp = yield client.fs_space_summury(async_=async_, **request_kwargs)
            check_response(resp)
            return sum(v["count"] for k, v in resp["type_summury"].items() if k.isupper())
        resp = yield get_resp()
        if not resp:
            raise FileNotFoundError(ENOENT, cid)
        check_response(resp)
        resp["cid"] = cid
        if "path" in resp:
            if cid != int(resp["path"][-1]["cid"]):
                raise NotADirectoryError(ENOTDIR, resp)
            if id_to_dirnode is not ...:
                for info in resp["path"][1:]:
                    id_to_dirnode[int(info["cid"])] = DirNode(info["name"], int(info["pid"]))
            return int(resp["count"])
        else:
            if int(resp["file_category"]):
                raise NotADirectoryError(ENOTDIR, resp)
            if id_to_dirnode is not ...:
                pid = 0
                for info in resp["paths"][1:]:
                    node = DirNode(info["file_name"], pid)
                    id_to_dirnode[(pid := int(info["file_id"]))] = node
            return int(resp["count"]) - int(resp.get("folder_count") or 0)
    return run_gen_step(gen_step, async_=async_)


@overload
def get_ancestors(
    client: str | P115Client, 
    attr: dict, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> list[dict]:
    ...
@overload
def get_ancestors(
    client: str | P115Client, 
    attr: dict, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, list[dict]]:
    ...
def get_ancestors(
    client: str | P115Client, 
    attr: dict, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> list[dict] | Coroutine[Any, Any, list[dict]]:
    """è·å–æŸä¸ªèŠ‚ç‚¹å¯¹åº”çš„ç¥–å…ˆèŠ‚ç‚¹åˆ—è¡¨ï¼ˆåªæœ‰ idã€parent_id å’Œ name çš„ä¿¡æ¯ï¼‰

    .. caution::
        æˆ‘é€šè¿‡ä¸€äº›ç»éªŒï¼Œæ­é…äº†å¤šä¸ªæ¥å£çš„å æ¯”å’Œå‚æ•°åˆ†å¸ƒï¼Œå¯èƒ½ä¸å¤Ÿåˆç†ï¼Œä»¥åä¼šæ ¹æ®å®é™…æƒ…å†µè°ƒæ•´

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param attr: å¾…æŸ¥è¯¢èŠ‚ç‚¹çš„ä¿¡æ¯ï¼ˆå¿…é¡»æœ‰ id å’Œ parent_idï¼‰
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ç›®å½•æ‰€å¯¹åº”çš„ç¥–å…ˆä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸€æ¡çš„ç»“æ„å¦‚ä¸‹

        .. code:: python

            {
                "id": int, # ç›®å½•çš„ id
                "parent_id": int, # ä¸Šçº§ç›®å½•çš„ id
                "name": str, # åå­—
            }
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    n_webapi = len(WEBAPI_BASE_URLS)
    n_proapi = len(PROAPI_BASE_URLS)
    n_apsapi = len(APS_BASE_URLS)
    n_api = n_webapi * 2 + n_proapi * 2 + n_apsapi
    def get_resp():
        global _n_get_ancestors
        n = _n_get_ancestors % n_api
        if n < n_webapi:
            _n_get_ancestors += 1
            return client.fs_files(
                {"cid": attr["parent_id"], "limit": 1}, 
                base_url=WEBAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_webapi
        if n < n_proapi:
            _n_get_ancestors += 1
            return client.fs_files_app(
                {"cid": attr["parent_id"], "hide_data": 1}, 
                base_url=PROAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_proapi
        if n < n_apsapi:
            _n_get_ancestors += 1
            return client.fs_files_aps(
                {"cid": attr["parent_id"], "limit": 1}, 
                base_url=APS_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        if attr.get("is_dir", False) or attr.get("is_directory", False):
            _n_get_ancestors = 0
            return get_resp()
        n -= n_apsapi
        if n < n_webapi:
            _n_get_ancestors += 1
            return client.fs_category_get(
                attr["id"], 
                base_url=WEBAPI_BASE_URLS[n], 
                async_=async_, 
                **request_kwargs, 
            )
        n -= n_webapi
        _n_get_ancestors += 1
        return client.fs_category_get_app(
            attr["id"], 
            base_url=PROAPI_BASE_URLS[n], 
            async_=async_, 
            **request_kwargs, 
        )
    def gen_step():
        if not attr["parent_id"]:
            return [{"id": 0, "parent_id": 0, "name": ""}]
        resp = yield get_resp()
        if not resp:
            raise FileNotFoundError(ENOENT, attr)
        check_response(resp)
        resp["attr"] = attr
        ancestors: list[dict] = [{"id": 0, "parent_id": 0, "name": ""}]
        add_ancestor = ancestors.append
        pid = 0
        if "path" in resp:
            if attr["parent_id"] != int(resp["path"][-1]["cid"]):
                raise FileNotFoundError(ENOENT, resp)
            for info in resp["path"][1:]:
                add_ancestor({
                    "parent_id": pid, 
                    "id": (pid := int(info["cid"])), 
                    "name": info["name"], 
                })
        else:
            for info in resp["paths"]:
                add_ancestor({
                    "parent_id": pid, 
                    "id": (pid := int(info["file_id"])), 
                    "name": info["file_name"], 
                })
        if id_to_dirnode is not ...:
            for ans in ancestors[1:]:
                id_to_dirnode[ans["id"]] = DirNode(ans["name"], ans["parent_id"])
        return ancestors
    return run_gen_step(gen_step, async_=async_)


@overload
def get_ancestors_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    refresh: bool = False, 
    id_to_dirnode: None  | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> list[dict]:
    ...
@overload
def get_ancestors_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    refresh: bool = False, 
    id_to_dirnode: None  | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, list[dict]]:
    ...
def get_ancestors_to_cid(
    client: str | P115Client, 
    cid: int = 0, 
    refresh: bool = False, 
    id_to_dirnode: None  | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> list[dict] | Coroutine[Any, Any, list[dict]]:
    """è·å–ç›®å½•å¯¹åº”çš„ç¥–å…ˆèŠ‚ç‚¹åˆ—è¡¨ï¼ˆåªæœ‰ idã€parent_id å’Œ name çš„ä¿¡æ¯ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½•çš„ id
    :param refresh: æ˜¯å¦åˆ·æ–°ã€‚å¦‚æœä¸º Trueï¼Œåˆ™ä¼šæ‰§è¡Œç½‘ç»œè¯·æ±‚ä»¥æŸ¥è¯¢ï¼›å¦‚æœä¸º Falseï¼Œåˆ™ç›´æ¥ä» `id_to_dirnode` ä¸­è·å–
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: ç›®å½•æ‰€å¯¹åº”çš„ç¥–å…ˆä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸€æ¡çš„ç»“æ„å¦‚ä¸‹

        .. code:: python

            {
                "id": int, # ç›®å½•çš„ id
                "parent_id": int, # ä¸Šçº§ç›®å½•çš„ id
                "name": str, # åå­—
            }
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    def gen_step():
        nonlocal cid
        parts: list[dict] = []
        if cid and (refresh or cid not in id_to_dirnode):
            if app in ("", "web", "desktop", "harmony"):
                resp = yield client.fs_files({"cid": cid, "limit": 1}, async_=async_, **request_kwargs)
            else:
                resp = yield client.fs_files_app({"cid": cid, "hide_data": 1}, async_=async_, **request_kwargs)
            check_response(resp)
            if cid and int(resp["path"][-1]["cid"]) != cid:
                raise FileNotFoundError(ENOENT, cid)
            parts.append({"id": 0, "name": "", "parent_id": 0})
            for info in resp["path"][1:]:
                id, pid, name = int(info["cid"]), int(info["pid"]), info["name"]
                id_to_dirnode[id] = DirNode(name, pid)
                parts.append({"id": id, "name": name, "parent_id": pid})
        else:
            while cid:
                id = cid
                name, cid = id_to_dirnode[cid]
                parts.append({"id": id, "name": name, "parent_id": cid})
            parts.append({"id": 0, "name": "", "parent_id": 0})
            parts.reverse()
        return parts
    return run_gen_step(gen_step, async_=async_)


class P115ID(P115DictAttrLike, int):

    def __str__(self, /) -> str:
        return int.__repr__(self)


# TODO: ä½¿ç”¨ search æ¥å£ä»¥åœ¨ç‰¹å®šç›®å½•ä¹‹ä¸‹æœç´¢æŸä¸ªåå­—ï¼Œä»¥ä¾¿å‡å°‘é£æ§
@overload
def get_id_to_path(
    client: str | P115Client, 
    path: str | Sequence[str], 
    ensure_file: None | bool = None, 
    is_posixpath: bool = False, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> int:
    ...
@overload
def get_id_to_path(
    client: str | P115Client, 
    path: str | Sequence[str], 
    ensure_file: None | bool = None, 
    is_posixpath: bool = False, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, int]:
    ...
def get_id_to_path(
    client: str | P115Client, 
    path: str | Sequence[str], 
    ensure_file: None | bool = None, 
    is_posixpath: bool = False, 
    refresh: bool = False, 
    id_to_dirnode: None | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> int | Coroutine[Any, Any, int]:
    """è·å–è·¯å¾„å¯¹åº”çš„ id

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param path: è·¯å¾„
    :param ensure_file: æ˜¯å¦ç¡®ä¿ä¸ºæ–‡ä»¶

        - True: å¿…é¡»æ˜¯æ–‡ä»¶
        - False: å¿…é¡»æ˜¯ç›®å½•
        - None: å¯ä»¥æ˜¯ç›®å½•æˆ–æ–‡ä»¶

    :param is_posixpath: ä½¿ç”¨ posixpathï¼Œä¼šæŠŠ "/" è½¬æ¢ä¸º "|"ï¼Œå› æ­¤è§£æçš„æ—¶å€™ï¼Œä¼šå¯¹ "|" è¿›è¡Œç‰¹åˆ«å¤„ç†
    :param refresh: æ˜¯å¦åˆ·æ–°ã€‚å¦‚æœä¸º Trueï¼Œåˆ™ä¼šæ‰§è¡Œç½‘ç»œè¯·æ±‚ä»¥æŸ¥è¯¢ï¼›å¦‚æœä¸º Falseï¼Œåˆ™ç›´æ¥ä» `id_to_dirnode` ä¸­è·å–
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: æ–‡ä»¶æˆ–ç›®å½•çš„ id
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    error = FileNotFoundError(ENOENT, f"no such path: {path!r}")
    def gen_step():
        nonlocal client, ensure_file
        if not isinstance(path, str):
            patht = ["", *filter(None, path)]
            if len(patht) == 1:
                return 0
            if is_posixpath:
                for i in range(1, len(patht)):
                    patht[i] = patht[i].replace("/", "|")
        elif path in (".", "..", "/"):
            if ensure_file:
                raise error
            return 0
        elif path.startswith("æ ¹ç›®å½• > "):
            patht = path.split(" > ")
            patht[0] = ""
            if is_posixpath:
                for i in range(1, len(patht)):
                    patht[i] = patht[i].replace("/", "|")
        elif is_posixpath:
            if ensure_file is None and path.endswith("/"):
                ensure_file = False
            patht = ["", *filter(None, path.split("/"))]
        else:
            if ensure_file is None and path_is_dir_form(path):
                ensure_file = False
            patht, _ = splits("/" + path)
        if len(patht) == 1:
            if ensure_file:
                raise error
            return 0
        stop = len(patht) - bool(ensure_file)
        obj = "|" if is_posixpath else "/"
        for i in range(stop):
            if obj in patht[i]:
                break
        else:
            i += 1
        j = 1
        pid = 0
        if stop > 1 and not refresh and id_to_dirnode:
            if stop == 2:
                if is_posixpath:
                    needle = (patht[1].replace("/", "|"), pid)
                else:
                    needle = (patht[1], pid)
                for k, t in id_to_dirnode.items():
                    if is_posixpath:
                        t = (t[0].replace("/", "|"), t[1])
                    if t == needle:
                        pid = k
                        j = 2
            else:
                if is_posixpath:
                    table = {(n.replace("/", "|"), pid): k for k, (n, pid) in id_to_dirnode.items()}
                else:
                    table = {cast(tuple[str, int], tuple(t)): k for k, t in id_to_dirnode.items()}
                try:
                    for j in range(1, stop):
                        if is_posixpath:
                            needle = (patht[j].replace("/", "|"), pid)
                        else:
                            needle = (patht[j], pid)
                        pid = table[needle]
                    j += 1
                except KeyError:
                    pass
        if j >= i:
            i = j
            cid = pid
        else:
            if ensure_file and len(patht) == i:
                i -= 1
            if app in ("", "web", "desktop", "harmony"):
                fs_dir_getid: Callable = client.fs_dir_getid
            else:
                fs_dir_getid = partial(client.fs_dir_getid_app, app=app)
            cid = 0
            while i > 1:
                dirname = "/".join(patht[:i])
                resp = yield fs_dir_getid(dirname, async_=async_, **request_kwargs)
                if not (resp["state"] and (cid := resp["id"])):
                    if len(patht) == i and ensure_file is None:
                        ensure_file = True
                        i -= 1
                        continue
                    raise error
                cid = int(cid)
                if not refresh and cid not in id_to_dirnode:
                    yield get_path_to_cid(
                        client, 
                        cid, 
                        id_to_dirnode=id_to_dirnode, 
                        app=app, 
                        async_=async_, 
                        **request_kwargs, 
                    )
                break
        if len(patht) == i:
            return cid
        for name in patht[i:-1]:
            if async_:
                async def request():
                    nonlocal cid
                    async for info in iterdir_raw(
                        client, 
                        cid, 
                        ensure_file=False, 
                        app=app, 
                        id_to_dirnode=id_to_dirnode, 
                        async_=True, 
                        **request_kwargs, 
                    ):
                        attr = _overview_attr(info)
                        if (attr.name.replace("/", "|") if is_posixpath else attr.name) == name:
                            cid = attr.id
                            break
                    else:
                        raise error
                yield request
            else:
                for info in iterdir_raw(
                    client, 
                    cid, 
                    ensure_file=False, 
                    app=app, 
                    id_to_dirnode=id_to_dirnode, 
                    **request_kwargs, 
                ):
                    attr = _overview_attr(info)
                    if (attr.name.replace("/", "|") if is_posixpath else attr.name) == name:
                        cid = attr.id
                        break
                else:
                    raise error
        name = patht[-1]
        if async_:
            async def request():
                async for info in iterdir_raw(
                    client, 
                    cid, 
                    app=app, 
                    id_to_dirnode=id_to_dirnode, 
                    async_=True, 
                    **request_kwargs, 
                ):
                    attr = _overview_attr(info)
                    if (attr.name.replace("/", "|") if is_posixpath else attr.name) == name:
                        if ensure_file:
                            if not attr.is_dir:
                                return P115ID(attr.id, info, about="path")
                        elif attr.is_dir:
                            return P115ID(attr.id, info, about="path")
                else:
                    raise error
            return (yield request)
        else:
            for info in iterdir_raw(
                client, 
                cid, 
                app=app, 
                id_to_dirnode=id_to_dirnode, 
                **request_kwargs, 
            ):
                attr = _overview_attr(info)
                if (attr.name.replace("/", "|") if is_posixpath else attr.name) == name:
                    if ensure_file:
                        if not attr.is_dir:
                            return P115ID(attr.id, info, about="path")
                    elif attr.is_dir:
                        return P115ID(attr.id, info, about="path")
            else:
                raise error
    return run_gen_step(gen_step, async_=async_)


@overload
def get_id_to_pickcode(
    client: str | P115Client, 
    pickcode: str, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> P115ID:
    ...
@overload
def get_id_to_pickcode(
    client: str | P115Client, 
    pickcode: str, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, P115ID]:
    ...
def get_id_to_pickcode(
    client: str | P115Client, 
    pickcode: str, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> P115ID | Coroutine[Any, Any, P115ID]:
    if not 17 <= len(pickcode) <= 18 or not pickcode.isalnum():
        raise ValueError(f"bad pickcode: {pickcode!r}")
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def gen_step():
        resp = yield client.download_url_web(pickcode, base_url=True, async_=async_, **request_kwargs)
        if file_id := resp.get("file_id"):
            msg_code = resp.get("msg_code", False)
            resp["is_dir"] = msg_code and msg_code != 50028
            return P115ID(file_id, resp, about="pickcode")
        check_response(resp)
    return run_gen_step(gen_step, async_=async_)


@overload
def get_id_to_sha1(
    client: str | P115Client, 
    sha1: str, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> P115ID:
    ...
@overload
def get_id_to_sha1(
    client: str | P115Client, 
    sha1: str, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> Coroutine[Any, Any, P115ID]:
    ...
def get_id_to_sha1(
    client: str | P115Client, 
    sha1: str, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> P115ID | Coroutine[Any, Any, P115ID]:
    if len(sha1) != 40 or sha1.strip(hexdigits):
        raise ValueError(f"bad sha1: {sha1!r}")
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def gen_step():
        resp = yield client.fs_shasearch(sha1, base_url=True, async_=async_, **request_kwargs)
        check_response(resp)
        resp["data"]["file_sha1"] = sha1.upper()
        return P115ID(resp["data"]["file_id"], resp["data"], about="sha1")
    return run_gen_step(gen_step, async_=async_)


@overload
def iter_nodes_skim(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    batch_size: int = 50_000, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_nodes_skim(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    batch_size: int = 50_000, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_nodes_skim(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    batch_size: int = 50_000, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è·å–ä¸€ç»„èŠ‚ç‚¹çš„ç®€ç•¥ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param batch_size: æ‰¹æ¬¡å¤§å°ï¼Œåˆ†æ‰¹æ¬¡ï¼Œæ¯æ¬¡æäº¤çš„ id æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè·å–èŠ‚ç‚¹çš„ç®€ç•¥ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def gen_step():
        file_skim = client.fs_file_skim
        for batch in chunked(ids, batch_size):
            resp = yield file_skim(batch, method="POST", async_=async_, **request_kwargs)
            if resp.get("error") == "æ–‡ä»¶ä¸å­˜åœ¨":
                continue
            check_response(resp)
            for a in resp["data"]:
                a["file_name"] = unescape_115_charref(a["file_name"])
            yield YieldFrom(resp["data"], identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def _iter_fs_files(
    client: str | P115Client, 
    payload: int | str | dict = 0, 
    first_page_size: int = 0, 
    page_size: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def _iter_fs_files(
    client: str | P115Client, 
    payload: int | str | dict = 0, 
    first_page_size: int = 0, 
    page_size: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def _iter_fs_files(
    client: str | P115Client, 
    payload: int | str | dict = 0, 
    first_page_size: int = 0, 
    page_size: int = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è¿­ä»£ç›®å½•ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param payload: è¯·æ±‚å‚æ•°ï¼Œå¦‚æœæ˜¯ int æˆ– strï¼Œåˆ™è§†ä¸º cid
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param ensure_file: æ˜¯å¦ç¡®ä¿ä¸ºæ–‡ä»¶

        - True: å¿…é¡»æ˜¯æ–‡ä»¶
        - False: å¿…é¡»æ˜¯ç›®å½•
        - None: å¯ä»¥æ˜¯ç›®å½•æˆ–æ–‡ä»¶

    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆæ–‡ä»¶å’Œç›®å½•ï¼‰
    """
    if isinstance(payload, (int, str)):
        payload = {"cid": payload}
    show_files = payload.get("suffix") or payload.get("type")
    if show_files:
        payload.setdefault("show_dir", 0)
    if not ensure_file:
        payload["count_folders"] = 1
    if ensure_file:
        payload["show_dir"] = 0
        if not show_files:
            payload.setdefault("cur", 1)
    elif ensure_file is False:
        payload["show_dir"] = 1
        payload["nf"] = 1
    if payload.get("type") == 99:
        payload.pop("type", None)
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    def gen_step():
        request_kwargs.update(
            app=app, 
            page_size=page_size, 
            raise_for_changed_count=raise_for_changed_count, 
        )
        if cooldown <= 0 or max_workers == 1:
            it = iter_fs_files(
                client, 
                payload, 
                first_page_size=first_page_size, 
                async_=async_, 
                **request_kwargs, 
            )
        elif async_:
            it = iter_fs_files_asynchronized(
                client, 
                payload, 
                cooldown=cooldown, 
                max_workers=max_workers, 
                **request_kwargs, 
            )
        else:
            it = iter_fs_files_threaded(
                client, 
                payload, 
                cooldown=cooldown, 
                max_workers=max_workers, 
                **request_kwargs, 
            )
        do_next = anext if async_ else next
        try:
            while True:
                resp = yield do_next(it) # type: ignore
                if id_to_dirnode is not ...:
                    for info in resp["path"][1:]:
                        pid, name = int(info["cid"]), info["name"]
                        id_to_dirnode[pid] = DirNode(name, int(info["pid"]))
                if ensure_file is None:
                    yield YieldFrom(resp["data"], identity=True)
                else:
                    for info in resp["data"]:
                        attr = _overview_attr(info)
                        if attr.is_dir:
                            if id_to_dirnode is not ...:
                                id_to_dirnode[attr.id] = DirNode(attr.name, attr.parent_id)
                        elif ensure_file is False:
                            return
                        yield Yield(info, identity=True)
        except (StopAsyncIteration, StopIteration):
            pass
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_stared_dirs_raw(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_stared_dirs_raw(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_stared_dirs_raw(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ä»¥è¿­ä»£è·å¾—æ‰€æœ‰è¢«æ‰“ä¸Šæ˜Ÿæ ‡çš„ç›®å½•ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¢«æ‰“ä¸Šæ˜Ÿæ ‡çš„ç›®å½•ä¿¡æ¯
    """
    return _iter_fs_files(
        client, 
        payload={
            "asc": asc, "cid": 0, "count_folders": 1, "cur": 0, "fc_mix": 0, 
            "o": order, "offset": 0, "show_dir": 1, "star": 1, 
        }, 
        page_size=page_size, 
        first_page_size=first_page_size, 
        id_to_dirnode=id_to_dirnode, 
        raise_for_changed_count=raise_for_changed_count, 
        ensure_file=False, 
        app=app, 
        cooldown=cooldown, 
        max_workers=max_workers, 
        async_=async_, # type: ignore
        **request_kwargs, 
    )


@overload
def iter_stared_dirs(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_stared_dirs(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_stared_dirs(
    client: str | P115Client, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ä»¥è¿­ä»£è·å¾—æ‰€æœ‰è¢«æ‰“ä¸Šæ˜Ÿæ ‡çš„ç›®å½•ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¢«æ‰“ä¸Šæ˜Ÿæ ‡çš„ç›®å½•ä¿¡æ¯
    """
    do_map = lambda f, it: it if not callable(f) else (async_map if async_ else map)(f, it)
    return do_map(normalize_attr, iter_stared_dirs_raw( # type: ignore
        client, 
        page_size=page_size, 
        first_page_size=first_page_size, 
        order=order, 
        asc=asc, 
        id_to_dirnode=id_to_dirnode, 
        raise_for_changed_count=raise_for_changed_count, 
        app=app, 
        cooldown=cooldown, 
        max_workers=max_workers, 
        async_=async_, # type: ignore
        **request_kwargs, 
    ))


@overload
def ensure_attr_path[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    page_size: int = 0, 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    use_star: bool = False, 
    life_event_cooldown: int | float = 0.5, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    make_up_missing: bool = True, 
    app: str = "web", 
    errors: Literal["ignore", "raise", "warn"] = "raise", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[D]:
    ...
@overload
def ensure_attr_path[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    page_size: int = 0, 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    use_star: bool = False, 
    life_event_cooldown: int | float = 0.5, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    make_up_missing: bool = True, 
    app: str = "web", 
    errors: Literal["ignore", "raise", "warn"] = "raise", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[D]:
    ...
def ensure_attr_path[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    page_size: int = 0, 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    use_star: bool = False, 
    life_event_cooldown: int | float = 0.5, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    make_up_missing: bool = True, 
    app: str = "web", 
    errors: Literal["ignore", "raise", "warn"] = "raise", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[D] | AsyncIterator[D]:
    """ä¸ºä¸€ç»„æ–‡ä»¶ä¿¡æ¯æ·»åŠ  "path" æˆ– "ancestors" å­—æ®µ

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param attrs: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ä¿¡æ¯
    :param page_size: åˆ†é¡µå¤§å°
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param use_star: è·å–ç›®å½•ä¿¡æ¯æ—¶ï¼Œæ˜¯å¦å…è®¸ä½¿ç”¨æ˜Ÿæ ‡
    :param life_event_cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0 æ—¶ï¼Œä¸¤æ¬¡æ‹‰å–æ“ä½œäº‹ä»¶çš„æ¥å£è°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš”è¿™ä¹ˆå¤šç§’
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param make_up_missing: æ˜¯å¦è¡¥å…¨ç¼ºå¤±çš„èŠ‚ç‚¹ä¿¡æ¯
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param errors: å¦‚ä½•å¤„ç†é”™è¯¯

        - "ignore": å¿½ç•¥å¼‚å¸¸åç»§ç»­
        - "raise": æŠ›å‡ºå¼‚å¸¸
        - "warn": è¾“å‡ºè­¦å‘Šä¿¡æ¯åç»§ç»­

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿”å›è¿™ä¸€ç»„æ–‡ä»¶ä¿¡æ¯
    """
    if not (with_ancestors or with_path):
        if async_:
            return ensure_aiter(attrs)
        else:
            return iter(attrs)
    if make_up_missing and not isinstance(attrs, Collection):
        attrs = tuple(attrs)
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if page_size <= 0:
        page_size = 10_000
    elif page_size < 16:
        page_size = 16
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ...:
        id_to_dirnode = {}
    if with_ancestors:
        id_to_ancestors: dict[int, list[dict]] = {}
        def get_ancestors(id: int, attr: dict | tuple[str, int] | DirNode, /) -> list[dict]:
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if pid == 0:
                ancestors = [{"id": 0, "parent_id": 0, "name": ""}]
            else:
                if pid not in id_to_ancestors:
                    id_to_ancestors[pid] = get_ancestors(pid, id_to_dirnode[pid])
                ancestors = [*id_to_ancestors[pid]]
            ancestors.append({"id": id, "parent_id": pid, "name": name})
            return ancestors
    if with_path:
        if isinstance(escape, bool):
            if escape:
                from posixpatht import escape
            else:
                escape = posix_escape_name
        escape = cast(None | Callable[[str], str], escape)
        id_to_path: dict[int, str] = {}
        def get_path(attr: dict | tuple[str, int] | DirNode, /) -> str:
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if escape is not None:
                name = escape(name)
            if pid == 0:
                dirname = "/"
            elif pid in id_to_path:
                dirname = id_to_path[pid]
            else:
                dirname = id_to_path[pid] = get_path(id_to_dirnode[pid]) + "/"
            return dirname + name
    def gen_step():
        if make_up_missing:
            pids: set[int] = set()
            add_pid = pids.add
            for attr in attrs:
                if pid := attr["parent_id"]:
                    add_pid(pid)
                if attr.get("is_dir", False) or attr.get("is_directory", False):
                    id_to_dirnode[attr["id"]] = DirNode(attr["name"], pid)
            find_ids: set[int]
            do_through: Callable = async_through if async_ else through
            while pids:
                if find_ids := pids - id_to_dirnode.keys():
                    try:
                        if use_star:
                            yield do_through(iter_selected_nodes_using_star_event(
                                client, 
                                find_ids, 
                                normalize_attr=None, 
                                id_to_dirnode=id_to_dirnode, 
                                cooldown=life_event_cooldown, 
                                app=app, 
                                async_=async_, # type: ignore
                                **request_kwargs, 
                            ))
                        else:
                            yield do_through(iter_selected_nodes_by_pickcode(
                                client, 
                                find_ids, 
                                normalize_attr=None, 
                                id_to_dirnode=id_to_dirnode, 
                                ignore_deleted=None, 
                                async_=async_, # type: ignore
                                **request_kwargs, 
                            ))
                    except Exception as e:
                        match errors:
                            case "raise":
                                raise
                            case "warn":
                                warn(f"{type(e).__module__}.{type(e).__qualname__}: {e}", category=P115Warning)
                pids = {ppid for pid in pids if (ppid := id_to_dirnode[pid][1])}
            del pids, find_ids, add_pid
        for attr in attrs:
            try:
                if with_ancestors:
                    attr["ancestors"] = get_ancestors(attr["id"], attr)
                if with_path:
                    attr["path"] = get_path(attr)
            except Exception as e:
                match errors:
                    case "raise":
                        raise
                    case "warn":
                        warn(f"{type(e).__module__}.{type(e).__qualname__}: {e} of {attr}", category=P115Warning)
                attr.setdefault("ancestors", None)
                attr.setdefault("path", "")
            yield Yield(attr, identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def ensure_attr_path_by_category_get[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[D]:
    ...
@overload
def ensure_attr_path_by_category_get[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[D]:
    ...
def ensure_attr_path_by_category_get[D: dict](
    client: str | P115Client, 
    attrs: Iterable[D], 
    with_ancestors: bool = False, 
    with_path: bool = True, 
    escape: None | bool | Callable[[str], str] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[D] | AsyncIterator[D]:
    """ä¸ºä¸€ç»„æ–‡ä»¶ä¿¡æ¯æ·»åŠ  "path" æˆ– "ancestors" å­—æ®µ

    .. caution::
        é£æ§éå¸¸ä¸¥é‡ï¼Œå»ºè®®ä¸è¦ä½¿ç”¨

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param attrs: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ä¿¡æ¯
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨
    """
    if not (with_ancestors or with_path):
        if async_:
            return ensure_aiter(attrs)
        return attrs # type: ignore
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ...:
        id_to_dirnode = {}
    if app in ("", "web", "desktop", "harmony"):
        request_kwargs.setdefault("base_url", cycle(("http://webapi.115.com", "https://webapi.115.com")).__next__)
        func: Callable = partial(client.fs_category_get, **request_kwargs)
    else:
        request_kwargs.setdefault("base_url", cycle(("http://proapi.115.com", "https://proapi.115.com")).__next__)
        func = partial(client.fs_category_get_app, app=app, **request_kwargs)
    if with_ancestors:
        id_to_node: dict[int, dict] = {0: {"id": 0, "parent_id": 0, "name": ""}}
        def get_ancestors(id: int, attr: dict | tuple[str, int] | DirNode, /) -> list[dict]:
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
                if pid in id_to_node:
                    me = id_to_node[pid] = {"id": id, "parent_id": pid, "name": name}
                else:
                    me = id_to_node[pid]
            else:
                pid = attr["parent_id"]
                name = attr["name"]
                me = {"id": id, "parent_id": pid, "name": name}
            if pid == 0:
                ancestors = [id_to_node[0]]
            else:
                ancestors = get_ancestors(pid, id_to_dirnode[pid])
            ancestors.append(me)
            return ancestors
    if with_path:
        if isinstance(escape, bool):
            if escape:
                from posixpatht import escape
            else:
                escape = posix_escape_name
        escape = cast(None | Callable[[str], str], escape)
        id_to_path: dict[int, str] = {}
        def get_path(attr: dict | tuple[str, int] | DirNode, /) -> str:
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if escape is not None:
                name = escape(name)
            if pid == 0:
                dirname = "/"
            elif pid in id_to_path:
                dirname = id_to_path[pid]
            else:
                dirname = id_to_path[pid] = get_path(id_to_dirnode[pid]) + "/"
            return dirname + name
    waiting: WeakValueDictionary[int, Any] = WeakValueDictionary()
    none: set[int] = set()
    if async_:
        async def async_project(attr: D, /) -> D:
            id = attr["id"]
            pid = attr["parent_id"]
            if pid and pid not in id_to_dirnode:
                async with waiting.setdefault(pid, AsyncLock()):
                    if pid in none:
                        return attr
                    if pid not in id_to_dirnode:
                        resp = await func(id, async_=True)
                        if not resp:
                            none.add(pid)
                            return attr
                        check_response(resp)
                        pid = 0
                        for info in resp["paths"][1:]:
                            fid = int(info["file_id"])
                            id_to_dirnode[fid] = DirNode(info["file_name"], pid)
                            pid = fid
                        if not resp["sha1"]:
                            id_to_dirnode[id] = DirNode(resp["file_name"], pid)
            if with_ancestors:
                attr["ancestors"] = get_ancestors(id, attr)
            if with_path:
                attr["path"] = get_path(attr)
            return attr
        return taskgroup_map(async_project, attrs, max_workers=max_workers)
    else:
        def project(attr: D, /) -> D:
            id = attr["id"]
            pid = attr["parent_id"]
            if pid and pid not in id_to_dirnode:
                with waiting.setdefault(pid, Lock()):
                    if pid in none:
                        return attr
                    if pid not in id_to_dirnode:
                        resp = func(id)
                        if not resp:
                            none.add(pid)
                            return attr
                        check_response(resp)
                        pid = 0
                        for info in resp["paths"][1:]:
                            fid = int(info["file_id"])
                            id_to_dirnode[fid] = DirNode(info["file_name"], pid)
                            pid = fid
                        if not resp["sha1"]:
                            id_to_dirnode[id] = DirNode(resp["file_name"], pid)
            if with_ancestors:
                attr["ancestors"] = get_ancestors(id, attr)
            if with_path:
                attr["path"] = get_path(attr)
            return attr
        return threadpool_map(project, attrs, max_workers=max_workers)


@overload
def iterdir_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iterdir_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iterdir_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è¿­ä»£ç›®å½•ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param show_dir: å±•ç¤ºæ–‡ä»¶å¤¹ã€‚0: å¦ï¼Œ1: æ˜¯
    :param fc_mix: æ–‡ä»¶å¤¹ç½®é¡¶ã€‚0: æ–‡ä»¶å¤¹åœ¨æ–‡ä»¶ä¹‹å‰ï¼Œ1: æ–‡ä»¶å’Œæ–‡ä»¶å¤¹æ··åˆå¹¶æŒ‰æŒ‡å®šæ’åº
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param ensure_file: æ˜¯å¦ç¡®ä¿ä¸ºæ–‡ä»¶

        - True: å¿…é¡»æ˜¯æ–‡ä»¶
        - False: å¿…é¡»æ˜¯ç›®å½•
        - None: å¯ä»¥æ˜¯ç›®å½•æˆ–æ–‡ä»¶

    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆæ–‡ä»¶å’Œç›®å½•ï¼‰
    """
    return _iter_fs_files(
        client, 
        payload={
            "asc": asc, "cid": cid, "cur": 1, "count_folders": 1, "fc_mix": fc_mix, 
            "show_dir": show_dir, "o": order, "offset": 0, 
        }, 
        page_size=page_size, 
        first_page_size=first_page_size, 
        id_to_dirnode=id_to_dirnode, 
        raise_for_changed_count=raise_for_changed_count, 
        ensure_file=ensure_file, 
        app=app, 
        cooldown=cooldown, 
        max_workers=max_workers, 
        async_=async_, # type: ignore
        **request_kwargs, 
    )


@overload
def iterdir(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iterdir(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iterdir(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    show_dir: Literal[0, 1] = 1, 
    fc_mix: Literal[0, 1] = 1, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    ensure_file: None | bool = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è¿­ä»£ç›®å½•ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param show_dir: å±•ç¤ºæ–‡ä»¶å¤¹ã€‚0: å¦ï¼Œ1: æ˜¯
    :param fc_mix: æ–‡ä»¶å¤¹ç½®é¡¶ã€‚0: æ–‡ä»¶å¤¹åœ¨æ–‡ä»¶ä¹‹å‰ï¼Œ1: æ–‡ä»¶å’Œæ–‡ä»¶å¤¹æ··åˆå¹¶æŒ‰æŒ‡å®šæ’åº
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param ensure_file: æ˜¯å¦ç¡®ä¿ä¸ºæ–‡ä»¶

        - True: å¿…é¡»æ˜¯æ–‡ä»¶
        - False: å¿…é¡»æ˜¯ç›®å½•
        - None: å¯ä»¥æ˜¯ç›®å½•æˆ–æ–‡ä»¶

    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆæ–‡ä»¶å’Œç›®å½•ï¼‰
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ... and (with_ancestors or with_path):
        id_to_dirnode = {}
    def gen_step():
        nonlocal cid
        it = iterdir_raw(
            client, 
            cid=cid, 
            page_size=page_size, 
            first_page_size=first_page_size, 
            order=order, 
            asc=asc, 
            show_dir=show_dir, 
            fc_mix=fc_mix, 
            id_to_dirnode=id_to_dirnode, 
            raise_for_changed_count=raise_for_changed_count, 
            ensure_file=ensure_file, 
            app=app, 
            cooldown=cooldown, 
            max_workers=max_workers, 
            async_=async_, # type: ignore
            **request_kwargs, 
        )
        do_map = lambda f, it: it if not callable(f) else (async_map if async_ else map)(f, it)
        dirname = ""
        pancestors: list[dict] = []
        if with_ancestors or with_path:
            def process(info: dict, /) -> dict:
                nonlocal dirname, pancestors, id_to_dirnode
                id_to_dirnode = cast(dict, id_to_dirnode)
                attr = normalize_attr(info)
                if not pancestors:
                    cid = attr["parent_id"]
                    while cid:
                        name, pid = id_to_dirnode[cid]
                        pancestors.append({"id": cid, "parent_id": pid, "name": name})
                        cid = pid
                    pancestors.append({"id": 0, "parent_id": 0, "name": ""})
                    pancestors.reverse()
                if with_ancestors:
                    attr["ancestors"] = [
                        *pancestors, 
                        {"id": attr["id"], "parent_id": attr["parent_id"], "name": attr["name"]}, 
                    ]
                if with_path:
                    if not dirname:
                        if escape is None:
                            dirname = "/".join(info["name"] for info in pancestors) + "/"
                        else:
                            dirname = "/".join(escape(info["name"]) for info in pancestors) + "/"
                    name = attr["name"]
                    if escape is not None:
                        name = escape(name)
                    attr["path"] = dirname + name
                return attr
            yield YieldFrom(do_map(process, it), identity=True) # type: ignore
        else:
            yield YieldFrom(do_map(normalize_attr, it), identity=True) # type: ignore
    return run_gen_step_iter(gen_step, async_=async_)


def iterdir_limited(
    client: str | P115Client, 
    cid: int = 0, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    ensure_file: None | bool = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è¿­ä»£ç›®å½•ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯ï¼Œä½†å—é™ï¼Œæ–‡ä»¶æˆ–ç›®å½•æœ€å¤šåˆ†åˆ«è·å– max(1201, 2402 - æ­¤ç±»å‹è¢«ç½®é¡¶çš„ä¸ªæ•°) ä¸ª

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param ensure_file: æ˜¯å¦ç¡®ä¿ä¸ºæ–‡ä»¶

        - True: å¿…é¡»æ˜¯æ–‡ä»¶
        - False: å¿…é¡»æ˜¯ç›®å½•
        - None: å¯ä»¥æ˜¯ç›®å½•æˆ–æ–‡ä»¶

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„æ–‡ä»¶ä¿¡æ¯ï¼ˆæ–‡ä»¶å’Œç›®å½•ï¼‰
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    seen_dirs: set[int] = set()
    add_dir = seen_dirs.add
    seen_files: set[int] = set()
    add_file = seen_files.add
    ancestors: list[dict] = [{"id": 0, "name": "", "parent_id": 0}]
    payload = {
        "asc": 1, "cid": cid, "count_folders": 1, "cur": 1, "fc_mix": 0, "limit": 10_000, 
        "offset": 0, "show_dir": 1,  
    }
    if ensure_file is not None:
        if ensure_file:
            payload["show_dir"] = 0
        else:
            payload["nf"] = 1
    def request(params={}, /):
        resp = yield client.fs_files_aps(
            {**payload, **params}, 
            base_url=True, 
            async_=async_, 
            **request_kwargs, 
        )
        check_response(resp)
        if cid and int(resp["path"][-1]["cid"]) != cid:
            raise FileNotFoundError(ENOENT, cid)
        ancestors[1:] = [
            {"id": int(info["cid"]), "name": info["name"], "parent_id": int(info["pid"])} 
            for info in resp["path"][1:]
        ]
        return resp
    def iter_attrs(resp):
        if with_path:
            names: Iterator[str] = (info["name"] for info in ancestors)
            if escape is not None:
                names = map(escape, names)
            dirname = "/".join(names) + "/"
        for attr in map(normalize_attr, resp["data"]):
            is_dir = ensure_file is False or attr.get("is_dir") or attr.get("is_directory")
            fid = attr["id"]
            if is_dir:
                if fid in seen_dirs:
                    continue
                add_dir(fid)
            else:
                if fid in seen_files:
                    continue
                add_file(fid)
            name = attr["name"]
            if id_to_dirnode is not ...:
                id_to_dirnode[fid] = DirNode(name, cid)
            if with_ancestors:
                attr["ancestors"] = [*ancestors, {"id": fid, "name": name, "parent_id": cid}]
            if with_path:
                if escape is not None:
                    name = escape(name)
                attr["path"] = dirname + name
            yield attr
    def gen_step():
        resp: dict = yield run_gen_step(request, async_=async_)
        yield YieldFrom(iter_attrs(resp), identity=True)
        count = int(resp["count"])
        count_fetched = len(resp["data"])
        if count > count_fetched:
            count_dirs = int(resp.get("folder_count") or 0)
            count_files = count - count_dirs
            count_top_dirs = 0
            count_top_files = 0
            for attr in map(normalize_attr, resp["data"]):
                is_dir = ensure_file is False or attr.get("is_dir") or attr.get("is_directory")
                if attr["is_top"]:
                    if is_dir:
                        count_top_dirs += 1
                    else:
                        count_top_files += 1
                elif not cid and is_dir and attr["name"] in ("æˆ‘çš„æ¥æ”¶", "æ‰‹æœºç›¸å†Œ", "äº‘ä¸‹è½½", "æˆ‘çš„æ—¶å…‰è®°å½•"):
                    count_top_dirs += 1
                else:
                    break
            else:
                if diff := count_dirs - len(seen_dirs):
                    warn(f"lost {diff} directories: cid={cid}", category=P115Warning)
                if diff := count_files - len(seen_files):
                    warn(f"lost {diff} files: cid={cid}", category=P115Warning)
                return
            count_top = count_top_dirs + count_top_files
            if count <= count_fetched * 2 - count_top:
                resp = request({"asc": 0, "offset": count_top, "limit": count - count_fetched})
                yield YieldFrom(iter_attrs(resp), identity=True)
                return
            if diff := count_dirs - len(seen_dirs):
                if diff > count_fetched - count_top_dirs:
                    resp = request({"nf": 1, "offset": len(seen_dirs)})
                    yield YieldFrom(iter_attrs(resp), identity=True)
                    diff = count_dirs - len(seen_dirs)
                if diff > 0:
                    resp = request({"asc": 0, "nf": 1, "offset": count_top_dirs, "limit": diff})
                    yield YieldFrom(iter_attrs(resp), identity=True)
                    
                    if diff := count_dirs - len(seen_dirs):
                        warn(f"lost {diff} directories: cid={cid}", category=P115Warning)
            if diff := count_files - len(seen_files):
                if diff > count_fetched - count_top_files:
                    resp = request({"show_dir": 0, "offset": len(seen_files)})
                    yield YieldFrom(iter_attrs(resp), identity=True)
                    diff = count_files - len(seen_files)
                if diff > 0:
                    resp = request({"asc": 0, "show_dir": 0, "offset": count_top_files, "limit": diff})
                    yield YieldFrom(iter_attrs(resp), identity=True)
                    if diff := count_files - len(seen_files):
                        warn(f"lost {diff} files: cid={cid}", category=P115Warning)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_files_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_files_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_files_raw(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param cur: ä»…å½“å‰ç›®å½•ã€‚0: å¦ï¼ˆå°†éå†å­ç›®å½•æ ‘ä¸Šæ‰€æœ‰å¶å­èŠ‚ç‚¹ï¼‰ï¼Œ1: æ˜¯
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    suffix = suffix.strip(".")
    if not (type or suffix):
        raise ValueError("please set the non-zero value of suffix or type")
    payload: dict = {
        "asc": asc, "cid": cid, "count_folders": 0, "cur": cur, "o": order, 
        "offset": 0, "show_dir": 0, 
    }
    if suffix:
        payload["suffix"] = suffix
    elif type != 99:
        payload["type"] = type
    return _iter_fs_files(
        client, 
        payload=payload, 
        page_size=page_size, 
        first_page_size=first_page_size, 
        id_to_dirnode=id_to_dirnode, 
        raise_for_changed_count=raise_for_changed_count, 
        ensure_file=True, 
        app=app, 
        cooldown=cooldown, 
        max_workers=max_workers, 
        async_=async_, # type: ignore
        **request_kwargs, 
    )


@overload
def iter_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    use_star: None | bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    use_star: None | bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    first_page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    use_star: None | bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param first_page_size: é¦–æ¬¡æ‹‰å–çš„åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param cur: ä»…å½“å‰ç›®å½•ã€‚0: å¦ï¼ˆå°†éå†å­ç›®å½•æ ‘ä¸Šæ‰€æœ‰å¶å­èŠ‚ç‚¹ï¼‰ï¼Œ1: æ˜¯
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param use_star: è·å–ç›®å½•ä¿¡æ¯æ—¶ï¼Œæ˜¯å¦å…è®¸ä½¿ç”¨æ˜Ÿæ ‡ ï¼ˆå¦‚æœä¸º Noneï¼Œåˆ™é‡‡ç”¨æµå¤„ç†ï¼Œå¦åˆ™é‡‡ç”¨æ‰¹å¤„ç†ï¼‰
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ... and (with_ancestors or with_path):
        id_to_dirnode = {}
    if with_ancestors or with_path:
        cache: list[dict] = []
        add_to_cache = cache.append
    if with_ancestors:
        id_to_ancestors: dict[int, list[dict]] = {}
        def get_ancestors(id: int, attr: dict | tuple[str, int] | DirNode, /) -> list[dict]:
            nonlocal id_to_dirnode
            id_to_dirnode = cast(dict, id_to_dirnode)
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if pid == 0:
                ancestors = [{"id": 0, "parent_id": 0, "name": ""}]
            else:
                if pid not in id_to_ancestors:
                    id_to_ancestors[pid] = get_ancestors(pid, id_to_dirnode[pid])
                ancestors = [*id_to_ancestors[pid]]
            ancestors.append({"id": id, "parent_id": pid, "name": name})
            return ancestors
    if with_path:
        id_to_path: dict[int, str] = {}
        def get_path(attr: dict | tuple[str, int] | DirNode, /) -> str:
            nonlocal id_to_dirnode
            id_to_dirnode = cast(dict, id_to_dirnode)
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if escape is not None:
                name = escape(name)
            if pid == 0:
                dirname = "/"
            elif pid in id_to_path:
                dirname = id_to_path[pid]
            else:
                dirname = id_to_path[pid] = get_path(id_to_dirnode[pid]) + "/"
            return dirname + name
    def gen_step():
        it = iter_files_raw(
            client, 
            cid=cid, 
            page_size=page_size, 
            first_page_size=first_page_size, 
            suffix=suffix, 
            type=type, 
            order=order, 
            asc=asc, 
            cur=cur, 
            id_to_dirnode=id_to_dirnode, 
            raise_for_changed_count=raise_for_changed_count, 
            app=app, 
            cooldown=cooldown, 
            max_workers=max_workers, 
            async_=async_, # type: ignore
            **request_kwargs, 
        )
        do_map = lambda f, it: it if not callable(f) else (async_map if async_ else map)(f, it)
        if with_path or with_ancestors:
            if use_star is None:
                return YieldFrom(ensure_attr_path_by_category_get(
                    client, 
                    do_map(normalize_attr, it), # type: ignore
                    with_ancestors=with_ancestors, 
                    with_path=with_path, 
                    escape=escape, 
                    id_to_dirnode=id_to_dirnode, 
                    app=app, 
                    async_=async_, # type: ignore
                    **request_kwargs, 
                ))
            do_filter = async_filter if async_ else filter
            def process(info):
                attr = normalize_attr(info)
                try:
                    if with_ancestors:
                        attr["ancestors"] = get_ancestors(attr["id"], attr)
                    if with_path:
                        attr["path"] = get_path(attr)
                except KeyError:
                    add_to_cache(attr)
                else:
                    return attr
            yield YieldFrom(do_filter(bool, do_map(process, it)), identity=True) # type: ignore
        else:
            yield YieldFrom(do_map(normalize_attr, it), identity=True) # type: ignore
        if (with_ancestors or with_path) and cache:
            yield YieldFrom(ensure_attr_path(
                client, 
                cache, 
                page_size=page_size, 
                with_ancestors=with_ancestors, 
                with_path=with_path, 
                use_star=use_star, # type: ignore
                escape=escape, 
                id_to_dirnode=id_to_dirnode, 
                app=app, 
                async_=async_, # type: ignore
                **request_kwargs, 
            ), identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def traverse_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = True, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def traverse_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = True, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def traverse_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = True, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆä¼šæ ¹æ®ç»Ÿè®¡ä¿¡æ¯ï¼Œåˆ†è§£ä»»åŠ¡ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param auto_splitting_tasks: æ˜¯å¦æ ¹æ®ç»Ÿè®¡ä¿¡æ¯è‡ªåŠ¨æ‹†åˆ†ä»»åŠ¡
    :param auto_splitting_threshold: å¦‚æœ `auto_splitting_tasks` ä¸º Trueï¼Œä¸”ç›®å½•å†…çš„æ–‡ä»¶æ•°å¤§äº `auto_splitting_threshold`ï¼Œåˆ™åˆ†æ‹†æ­¤ä»»åŠ¡åˆ°å®ƒçš„å„ä¸ªç›´æ¥å­ç›®å½•ï¼Œå¦åˆ™æ‰¹é‡æ‹‰å–
    :param auto_splitting_statistics_timeout: å¦‚æœæ‰§è¡Œç»Ÿè®¡è¶…è¿‡æ­¤æ—¶é—´ï¼Œåˆ™ç«‹å³ç»ˆæ­¢ï¼Œå¹¶è®¤ä¸ºæ–‡ä»¶æ˜¯æ— é™å¤š
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    suffix = suffix.strip(".")
    if not (type or suffix):
        raise ValueError("please set the non-zero value of suffix or type")
    if suffix:
        suffix = "." + suffix.lower()
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ... and (with_ancestors or with_path):
        id_to_dirnode = {}
    auto_splitting_tasks = auto_splitting_tasks and auto_splitting_threshold > 0
    def gen_step():
        nonlocal cid
        if auto_splitting_tasks:
            get_count = partial(
                get_file_count, 
                client, 
                id_to_dirnode=id_to_dirnode, 
                **{**request_kwargs, "timeout": auto_splitting_statistics_timeout}
            )
        gen = bfs_gen(cid)
        send = gen.send
        for cid in gen:
            if auto_splitting_tasks:
                try:
                    file_count: float = yield get_count(cid, async_=async_)
                except Exception as e:
                    if not is_timeouterror(e):
                        raise
                    file_count = inf
            else:
                file_count = 0
            if file_count <= auto_splitting_threshold:
                if with_ancestors or with_path:
                    yield YieldFrom(iter_files_with_path(
                        client, 
                        cid, 
                        page_size=page_size, 
                        suffix=suffix, 
                        type=type, 
                        with_ancestors=with_ancestors, 
                        with_path=with_path, 
                        escape=escape, 
                        normalize_attr=normalize_attr, 
                        id_to_dirnode=id_to_dirnode, 
                        raise_for_changed_count=raise_for_changed_count, 
                        app=app, 
                        cooldown=cooldown, 
                        max_workers=max_workers, 
                        async_=async_, # type: ignore
                        **request_kwargs, 
                    ), identity=True)
                else:
                    yield YieldFrom(iter_files(
                        client, 
                        cid, 
                        page_size=page_size, 
                        suffix=suffix, 
                        type=type, 
                        normalize_attr=normalize_attr, 
                        id_to_dirnode=id_to_dirnode, 
                        raise_for_changed_count=raise_for_changed_count, 
                        app=app, 
                        cooldown=cooldown, 
                        max_workers=max_workers, 
                        async_=async_, # type: ignore
                        **request_kwargs, 
                    ), identity=True)
            else:
                with with_iter_next(iterdir(
                    client, 
                    cid, 
                    page_size=page_size, 
                    with_ancestors=with_ancestors, 
                    with_path=with_path, 
                    escape=escape, 
                    normalize_attr=normalize_attr, 
                    id_to_dirnode=id_to_dirnode, 
                    app=app, 
                    raise_for_changed_count=raise_for_changed_count, 
                    async_=async_, 
                    **request_kwargs, 
                )) as get_next:
                    attr = yield get_next
                    if attr.get("is_dir") or attr.get("is_directory"):
                        send(attr["id"])
                    elif (
                        suffix and 
                        suffix == splitext(attr["name"])[1].lower() or 
                        type > 7 or 
                        type_of_attr(attr) == type
                    ):
                        yield Yield(attr, identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_dirs(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    with_pickcode: bool = False, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_dirs(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    with_pickcode: bool = False, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_dirs(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    with_pickcode: bool = False, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–ç›®å½•ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• idï¼ˆå¦‚æœæ˜¯ intï¼‰ æˆ–è€… pickcodeï¼ˆå¦‚æœæ˜¯ strï¼‰
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param with_pickcode: æ˜¯å¦éœ€è¦åŒ…å«æå–ç 
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…ç›®å½•ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    from .download import iter_download_nodes
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    it = iter_download_nodes(
        client, 
        cid, 
        files=False, 
        max_workers=max_workers, 
        async_=async_, # type: ignore
        **request_kwargs, 
    )
    do_map: Callable = async_map if async_ else map
    def project(info: dict, /) -> dict:
        attr = {"id": int(info["fid"]), "parent_id": int(info["pid"]), "name": info["fn"]}
        if id_to_dirnode is not ...:
            id_to_dirnode[attr["id"]] = DirNode(attr["name"], attr["parent_id"])
        return attr
    it = do_map(project, it)
    if with_pickcode:
        file_skim = client.fs_file_skim
        @as_gen_step(async_=async_)
        def batch_load_pickcode(batch: Sequence[dict], /):
            resp = yield file_skim(
                (a["id"] for a in batch), 
                method="POST", 
                async_=async_, 
                **request_kwargs, 
            )
            check_response(resp)
            maps = {int(a["file_id"]): a["pick_code"] for a in resp["data"]}
            for attr in batch:
                attr["pickcode"] = maps[attr["id"]]
            return batch
        def gen_step(iterable):
            batch_map = taskgroup_map if async_ else threadpool_map
            with with_iter_next(batch_map(
                batch_load_pickcode, 
                chunked(iterable, 3000), 
                max_workers=max_workers, 
            )) as get_next:
                while True:
                    batch = yield get_next
                    yield YieldFrom(batch, identity=True)
        it = run_gen_step_iter(gen_step(it), async_=async_)
    return it


@overload
def iter_dupfiles[K](
    client: str | P115Client, 
    cid: int = 0, 
    key: Callable[[dict], K] = itemgetter("sha1", "size"), 
    keep_first: None | bool | Callable[[dict], SupportsLT] = None, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = False, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[tuple[K, dict]]:
    ...
@overload
def iter_dupfiles[K](
    client: str | P115Client, 
    cid: int = 0, 
    key: Callable[[dict], K] = itemgetter("sha1", "size"), 
    keep_first: None | bool | Callable[[dict], SupportsLT] = None, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = False, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[tuple[K, dict]]:
    ...
def iter_dupfiles[K](
    client: str | P115Client, 
    cid: int = 0, 
    key: Callable[[dict], K] = itemgetter("sha1", "size"), 
    keep_first: None | bool | Callable[[dict], SupportsLT] = None, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    auto_splitting_tasks: bool = False, 
    auto_splitting_threshold: int = 300_000, 
    auto_splitting_statistics_timeout: None | int | float = 5, 
    with_ancestors: bool = False, 
    with_path: bool = False, 
    escape: None | bool | Callable[[str], str] = True, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[tuple[K, dict]] | AsyncIterator[tuple[K, dict]]:
    """éå†ä»¥è¿­ä»£è·å¾—æ‰€æœ‰é‡å¤æ–‡ä»¶

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: å¾…è¢«éå†çš„ç›®å½• idï¼Œé»˜è®¤ä¸ºæ ¹ç›®å½•
    :param key: å‡½æ•°ï¼Œç”¨æ¥ç»™æ–‡ä»¶åˆ†ç»„ï¼Œå½“å¤šä¸ªæ–‡ä»¶è¢«åˆ†é…åˆ°åŒä¸€ç»„æ—¶ï¼Œå®ƒä»¬ç›¸äº’ä¹‹é—´æ˜¯é‡å¤æ–‡ä»¶å…³ç³»
    :param keep_first: ä¿ç•™æŸä¸ªé‡å¤æ–‡ä»¶ä¸è¾“å‡ºï¼Œé™¤æ­¤ä»¥å¤–çš„é‡å¤æ–‡ä»¶éƒ½è¾“å‡º

        - å¦‚æœä¸º Noneï¼Œåˆ™è¾“å‡ºæ‰€æœ‰é‡å¤æ–‡ä»¶ï¼ˆä¸ä½œä¿ç•™ï¼‰
        - å¦‚æœæ˜¯ Callableï¼Œåˆ™ä¿ç•™å€¼æœ€å°çš„é‚£ä¸ªæ–‡ä»¶
        - å¦‚æœä¸º Trueï¼Œåˆ™ä¿ç•™æœ€æ—©å…¥ç»„çš„é‚£ä¸ªæ–‡ä»¶
        - å¦‚æœä¸º Falseï¼Œåˆ™ä¿ç•™æœ€æ™šå…¥ç»„çš„é‚£ä¸ªæ–‡ä»¶

    :param page_size: åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param auto_splitting_tasks: æ˜¯å¦æ ¹æ®ç»Ÿè®¡ä¿¡æ¯è‡ªåŠ¨æ‹†åˆ†ä»»åŠ¡
    :param auto_splitting_threshold: å¦‚æœ `auto_splitting_tasks` ä¸º Trueï¼Œä¸”ç›®å½•å†…çš„æ–‡ä»¶æ•°å¤§äº `auto_splitting_threshold`ï¼Œåˆ™åˆ†æ‹†æ­¤ä»»åŠ¡åˆ°å®ƒçš„å„ä¸ªç›´æ¥å­ç›®å½•ï¼Œå¦åˆ™æ‰¹é‡æ‹‰å–
    :param auto_splitting_statistics_timeout: å¦‚æœæ‰§è¡Œç»Ÿè®¡è¶…è¿‡æ­¤æ—¶é—´ï¼Œåˆ™ç«‹å³ç»ˆæ­¢ï¼Œå¹¶è®¤ä¸ºæ–‡ä»¶æ˜¯æ— é™å¤š
    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param with_path: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "path"
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å› key å’Œ é‡å¤æ–‡ä»¶ä¿¡æ¯ çš„å…ƒç»„
    """
    return iter_keyed_dups(
        traverse_files(
            client, 
            cid, 
            page_size=page_size, 
            suffix=suffix, 
            type=type, 
            auto_splitting_tasks=auto_splitting_tasks, 
            auto_splitting_threshold=auto_splitting_threshold, 
            auto_splitting_statistics_timeout=auto_splitting_statistics_timeout, 
            with_ancestors=with_ancestors, 
            with_path=with_path, 
            escape=escape, 
            normalize_attr=normalize_attr, 
            id_to_dirnode=id_to_dirnode, 
            raise_for_changed_count=raise_for_changed_count, 
            app=app, 
            cooldown=cooldown, 
            async_=async_, # type: ignore
            **request_kwargs, 
        ), 
        key=key, 
        keep_first=keep_first, 
    )


@overload
def iter_image_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 8192, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    raise_for_changed_count: bool = False, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_image_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 8192, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    raise_for_changed_count: bool = False, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_image_files(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 8192, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    raise_for_changed_count: bool = False, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å«å›¾ç‰‡çš„ CDN é“¾æ¥ï¼‰

    .. tip::
        è¿™ä¸ªå‡½æ•°çš„æ•ˆæœç›¸å½“äº ``iter_files(client, cid, type=2, ...)`` æ‰€è·å–çš„æ–‡ä»¶åˆ—è¡¨ï¼Œåªæ˜¯è¿”å›ä¿¡æ¯æœ‰äº›ä¸åŒï¼Œé€Ÿåº¦ä¼¼ä¹è¿˜æ˜¯ ``iter_files`` æ›´å¿«

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param cur: ä»…å½“å‰ç›®å½•ã€‚0: å¦ï¼ˆå°†éå†å­ç›®å½•æ ‘ä¸Šæ‰€æœ‰å¶å­èŠ‚ç‚¹ï¼‰ï¼Œ1: æ˜¯
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„å›¾ç‰‡æ–‡ä»¶ä¿¡æ¯
    """
    def normalize(attr: dict, /):
        for key, val in attr.items():
            if key.endswith(("_id", "_type", "_size", "time")) or key.startswith("is_") or val in "01":
                attr[key] = int(val)
        attr["id"] = attr["file_id"]
        attr["name"] = attr["file_name"]
        return attr
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if page_size <= 0:
        page_size = 8192
    elif page_size < 16:
        page_size = 16
    payload = {"asc": asc, "cid": cid, "cur": cur, "limit": page_size, "o": order, "offset": 0}
    def gen_step():
        offset = 0
        count = 0
        while True:
            resp = check_response((yield client.fs_imglist_app(payload, async_=async_, **request_kwargs)))
            if int(resp["cid"]) != cid:
                raise FileNotFoundError(ENOENT, cid)
            if count == 0:
                count = int(resp.get("count") or 0)
            elif count != int(resp.get("count") or 0):
                message = f"cid={cid} detected count changes during traversing: {count} => {resp['count']}"
                if raise_for_changed_count:
                    raise P115OSError(EIO, message)
                else:
                    warn(message, category=P115Warning)
                count = int(resp.get("count") or 0)
            if offset != resp["offset"]:
                break
            yield YieldFrom(map(normalize, resp["data"]), identity=True)
            offset += len(resp["data"])
            if offset >= count:
                break
            payload["offset"] = offset
    return run_gen_step_iter(gen_step, async_=async_)


def share_extract_payload(link: str, /) -> SharePayload:
    """ä»é“¾æ¥ä¸­æå– share_code å’Œ receive_code

    .. hint::
        `link` æ”¯æŒ 3 ç§å½¢å¼ï¼ˆåœ†æ‹¬å·ä¸­çš„å­—ç¬¦è¡¨ç¤ºå¯æœ‰å¯æ— ï¼‰ï¼š

        1. http(s)://115.com/s/{share_code}?password={receive_code}(#) æˆ– http(s)://share.115.com/{share_code}?password={receive_code}(#)
        2. (/){share_code}-{receive_code}(/)
        3. {share_code}
    """
    m = CRE_SHARE_LINK_search1(link)
    if m is None:
        m = CRE_SHARE_LINK_search2(link)
    if m is None:
        raise ValueError("not a valid 115 share link")
    return cast(SharePayload, m.groupdict())


@overload
def share_iterdir(
    client: str | P115Client, 
    share_code: str, 
    receive_code: str = "", 
    cid: int = 0, 
    page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def share_iterdir(
    client: str | P115Client, 
    share_code: str, 
    receive_code: str = "", 
    cid: int = 0, 
    page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def share_iterdir(
    client: str | P115Client, 
    share_code: str, 
    receive_code: str = "", 
    cid: int = 0, 
    page_size: int = 0, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """å¯¹åˆ†äº«é“¾æ¥è¿­ä»£ç›®å½•ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param share_code: åˆ†äº«ç 
    :param receive_code: æ¥æ”¶ç 
    :param cid: ç›®å½•çš„ id
    :param page_size: åˆ†é¡µå¤§å°
    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¢«æ‰“ä¸Šæ˜Ÿæ ‡çš„ç›®å½•ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if page_size < 0:
        page_size = 10_000
    def gen_step():
        nonlocal receive_code
        if not receive_code:
            resp = yield client.share_info(share_code, async_=async_, **request_kwargs)
            check_response(resp)
            receive_code = resp["data"]["receive_code"]
        payload = {
            "share_code": share_code, 
            "receive_code": receive_code, 
            "cid": cid, 
            "limit": page_size, 
            "offset": 0, 
            "asc": asc, 
            "o": order, 
        }
        count = 0
        while True:
            resp = yield client.share_snap(payload, base_url=True, async_=async_, **request_kwargs)
            check_response(resp)
            if count == (count := resp["data"]["count"]):
                break
            for attr in resp["data"]["list"]:
                attr["share_code"] = share_code
                attr["receive_code"] = receive_code
                if normalize_attr is not None:
                    attr = normalize_attr(attr)
                yield Yield(attr, identity=True)
            payload["offset"] += page_size # type: ignore
            if payload["offset"] >= count: # type: ignore
                break
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def share_iter_files(
    client: str | P115Client, 
    share_link: str, 
    receive_code: str = "", 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def share_iter_files(
    client: str | P115Client, 
    share_link: str, 
    receive_code: str = "", 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def share_iter_files(
    client: str | P115Client, 
    share_link: str, 
    receive_code: str = "", 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """æ‰¹é‡è·å–åˆ†äº«é“¾æ¥ä¸­çš„æ–‡ä»¶åˆ—è¡¨

    .. hint::
        `share_link` æ”¯æŒ 3 ç§å½¢å¼ï¼ˆåœ†æ‹¬å·ä¸­çš„å­—ç¬¦è¡¨ç¤ºå¯æœ‰å¯æ— ï¼‰ï¼š

        1. http(s)://115.com/s/{share_code}?password={receive_code}(#) æˆ– http(s)://share.115.com/{share_code}?password={receive_code}(#)
        2. (/){share_code}-{receive_code}(/)
        3. {share_code}

        å¦‚æœä½¿ç”¨ç¬¬ 3 ç§å½¢å¼ï¼Œè€Œä¸”åˆä¸æä¾› `receive_code`ï¼Œåˆ™è®¤ä¸ºè¿™æ˜¯ä½ è‡ªå·±æ‰€åšçš„åˆ†äº«ï¼Œä¼šå°è¯•è‡ªåŠ¨å»è·å–è¿™ä¸ªå¯†ç 

        å¦‚æœ `share_link` ä¸­æœ‰ `receive_code`ï¼Œè€Œä½ åˆå•ç‹¬æä¾›äº† `receive_code`ï¼Œåˆ™åè€…çš„ä¼˜å…ˆçº§æ›´é«˜

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param share_link: åˆ†äº«ç æˆ–åˆ†äº«é“¾æ¥
    :param receive_code: å¯†ç 
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤åˆ†äº«é“¾æ¥ä¸‹çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯ï¼Œç”±äºæ¥å£è¿”å›ä¿¡æ¯æœ‰é™ï¼Œæ‰€ä»¥æ¯”è¾ƒç®€ç•¥

        .. code:: python

            {
                "id": int, 
                "sha1": str, 
                "name": str, 
                "size": int, 
                "path": str, 
            }

    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def gen_step():
        payload: dict = cast(dict, share_extract_payload(share_link))
        if receive_code:
            payload["receive_code"] = receive_code
        elif not payload["receive_code"]:
            resp = yield client.share_info(payload["share_code"], async_=async_, **request_kwargs)
            check_response(resp)
            payload["receive_code"] = resp["data"]["receive_code"]
        payload["cid"] = 0
        it = share_iterdir(client, **payload, async_=async_, **request_kwargs)
        do_next: Callable = anext if async_ else next
        try:
            while True:
                attr = yield do_next(it)
                if attr.get("is_dir") or attr.get("is_directory"):
                    payload["cid"] = attr["id"]
                    resp = yield client.share_downlist(payload, async_=async_, **request_kwargs)
                    check_response(resp)
                    for info in resp["data"]["list"]:
                        fid, sha1 = info["fid"].split("_", 1)
                        yield Yield({
                            "id": int(fid), 
                            "sha1": sha1, 
                            "name": info["fn"], 
                            "size": int(info["si"]), 
                            "path": f"/{info['pt']}/{info['fn']}", 
                        }, identity=True)
                else:
                    yield Yield({k: attr[k] for k in ("id", "sha1", "name", "size", "path")}, identity=True)
        except (StopIteration, StopAsyncIteration):
            pass
    return run_gen_step(gen_step, async_=async_)


@overload
def iter_selected_nodes(
    client: str | P115Client, 
    ids: Iterable[int], 
    ignore_deleted: bool = True, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_nodes(
    client: str | P115Client, 
    ids: Iterable[int], 
    ignore_deleted: bool = True, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_nodes(
    client: str | P115Client, 
    ids: Iterable[int], 
    ignore_deleted: bool = True, 
    normalize_attr: None | Callable[[dict], dict] = normalize_attr, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è·å–ä¸€ç»„ id çš„ä¿¡æ¯

    .. caution::
        é£æ§éå¸¸ä¸¥é‡ï¼Œå»ºè®®ä¸è¦ä½¿ç”¨

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param ignore_deleted: å¿½ç•¥å·²ç»è¢«åˆ é™¤çš„
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿè¯¦ç»†çš„ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    get_base_url = cycle(("http://webapi.115.com", "https://webapi.115.com")).__next__
    request_kwargs.setdefault("base_url", get_base_url)
    def project(resp: dict, /) -> None | dict:
        if resp.get("code") == 20018:
            return None
        check_response(resp)
        info = resp["data"][0]
        was_deleted = int(info.get("aid") or info.get("area_id") or 1) != 1
        if ignore_deleted and was_deleted:
            return None
        if id_to_dirnode is not ... and not was_deleted:
            attr = _overview_attr(info)
            if attr.is_dir:
                id_to_dirnode[attr.id] = DirNode(attr.name, attr.parent_id)
        if normalize_attr is None:
            return info
        return normalize_attr(info)
    if async_:
        request_kwargs["async_"] = True
        return async_filter(None, async_map(
            project, # type: ignore
            taskgroup_map(
                client.fs_file, # type: ignore
                ids, 
                max_workers=max_workers, 
                kwargs=request_kwargs, 
            ), 
        ))
    else:
        return filter(None, map(
            project, 
            threadpool_map(
                client.fs_file, 
                ids, 
                max_workers=max_workers, 
                kwargs=request_kwargs, 
            ), 
        ))


@overload
def iter_selected_nodes_by_pickcode(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    ignore_deleted: None | bool = True, 
    normalize_attr: None | Callable[[dict], dict] = None, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_nodes_by_pickcode(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    ignore_deleted: None | bool = True, 
    normalize_attr: None | Callable[[dict], dict] = None, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20,  
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_nodes_by_pickcode(
    client: str | P115Client, 
    ids: Iterable[int | str], 
    ignore_deleted: None | bool = True, 
    normalize_attr: None | Callable[[dict], dict] = None, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è·å–ä¸€ç»„ id çš„ä¿¡æ¯

    .. caution::
        å¹¶å‘æ•°è¾ƒå¤šæ—¶ï¼Œå®¹æ˜“å‘ç”Ÿ HTTP é“¾æ¥ä¸­æ–­ç°è±¡

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id æˆ– pickcode
    :param ignore_deleted: æ˜¯å¦å¿½ç•¥å·²ç»è¢«åˆ é™¤çš„
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿè¯¦ç»†çš„ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    methods: list[Callable] = []
    if ignore_deleted or ignore_deleted is None:
        methods += (
            partial(client.fs_document, base_url="http://webapi.115.com"), 
            partial(client.fs_document_app, base_url="http://proapi.115.com"), 
            partial(client.fs_document_app, base_url="https://proapi.115.com"), 
        )
    if not ignore_deleted:
       methods += (
            partial(client.fs_supervision, base_url="http://webapi.115.com"), 
            partial(client.fs_supervision_app, base_url="http://proapi.115.com"), 
            partial(client.fs_supervision_app, base_url="https://proapi.115.com"), 
        )
    def get_response(pickcode: str | dict, /, get_method=cycle(methods).__next__):
        if isinstance(pickcode, dict):
            pickcode = pickcode["pick_code"]
        return get_method()(
            pickcode, 
            async_=async_, 
            **request_kwargs, 
        )
    def project(resp: dict, /) -> None | dict:
        was_deleted = resp.get("code") == 31001 or resp.get("msg_code") == 70005
        info = resp.get("data")
        if not info or not info.get("file_id") or ignore_deleted and was_deleted:
            return None
        if not info and not resp["state"] and not was_deleted:
            check_response(resp)
        if id_to_dirnode is not ... and not info["file_sha1"] and not was_deleted:
            id_to_dirnode[int(info["file_id"])] = DirNode(info["file_name"], int(info["parent_id"]))
        if normalize_attr is None:
            return info
        return normalize_attr(info)
    ls_pickcode: list[str] = []
    ls_id: list[int] = []
    append = list.append
    for val in ids:
        if val:
            if isinstance(val, int):
                append(ls_id, val)
            else:
                append(ls_pickcode, val)
    if ls_id:
        it: Any = iter_nodes_skim(client, ls_id, async_=async_, **request_kwargs)
        if async_:
            it = async_chain(ls_pickcode, it)
        else:
            it = chain(ls_pickcode, it)
    else:
        it = ls_pickcode
    if async_:
        return async_filter(None, async_map(project, taskgroup_map( # type: ignore
            get_response, it, max_workers=max_workers, kwargs=request_kwargs)))
    else:
        return filter(None, map(project, threadpool_map(
            get_response, it, max_workers=max_workers, kwargs=request_kwargs)))


@overload
def iter_selected_nodes_using_edit(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_nodes_using_edit(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_nodes_using_edit(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è·å–ä¸€ç»„ id çš„ä¿¡æ¯

    .. caution::
        é€Ÿåº¦è¾ƒæ…¢ï¼Œé£æ§è¾ƒä¸¥é‡ï¼Œå»ºè®®ä¸è¦ä½¿ç”¨

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿè¯¦ç»†çš„ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    get_base_url = cycle(("http://proapi.115.com", "https://proapi.115.com")).__next__
    request_kwargs.setdefault("base_url", get_base_url)
    def project(resp: dict, /) -> None | dict:
        if resp.get("error") == "æ–‡ä»¶ä¸å­˜åœ¨/æ•°æ®åº“é”™è¯¯äº†":
            return None
        check_response(resp)
        info = resp["data"]
        info["id"] = int(info["file_id"])
        info["parent_id"] = int(info["parent_id"])
        info["name"] = info["file_name"]
        info["is_dir"] = not info["sha1"]
        if id_to_dirnode is not ... and info["is_dir"]:
            id_to_dirnode[info["id"]] = DirNode(info["name"], info["parent_id"])
        return info
    args_it = ({"file_id": fid, "show_play_long": 1} for fid in ids)
    if async_:
        request_kwargs["async_"] = True
        return async_filter(None, async_map(
            project, # type: ignore
            taskgroup_map(
                client.fs_edit_app, # type: ignore
                args_it, 
                max_workers=max_workers, 
                kwargs=request_kwargs, 
            ), 
        ))
    else:
        return filter(None, map(
            project, 
            threadpool_map(
                client.fs_edit_app, 
                args_it, 
                max_workers=max_workers, 
                kwargs=request_kwargs, 
            ), 
        ))


@overload
def iter_selected_nodes_using_category_get(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_nodes_using_category_get(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_nodes_using_category_get(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = 20, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """è·å–ä¸€ç»„ id çš„ä¿¡æ¯

    .. caution::
        é£æ§éå¸¸ä¸¥é‡ï¼Œå»ºè®®ä¸è¦ä½¿ç”¨

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿè¯¦ç»†çš„ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    get_method = cycle((
        partial(client.fs_category_get, base_url="http://webapi.115.com"), 
        partial(client.fs_category_get_app, base_url="http://proapi.115.com"), 
        partial(client.fs_category_get, base_url="https://webapi.115.com"), 
        partial(client.fs_category_get_app, base_url="https://proapi.115.com"), 
    )).__next__
    def call(id, /):
        def parse(_, content: bytes):
            resp = loads(content)
            if resp:
                resp["id"] = id
                resp["parent_id"] = int(resp["paths"][-1]["file_id"])
                resp["name"] = resp["file_name"]
                resp["is_dir"] = not resp["sha1"]
            return resp
        return get_method()(id, parse=parse, async_=async_, **request_kwargs)
    def project(resp: dict, /) -> None | dict:
        if not resp:
            return None
        check_response(resp)
        if id_to_dirnode is not ...:
            pid = 0
            for info in resp["paths"][1:]:
                fid = int(info["file_id"])
                id_to_dirnode[fid] = DirNode(info["file_name"], pid)
                pid = fid
            if resp["is_dir"]:
                id_to_dirnode[resp["id"]] = DirNode(resp["name"], pid)
        return resp
    if async_:
        return async_filter(None, async_map(project, taskgroup_map( # type: ignore
            call, ids, max_workers=max_workers)))
    else:
        return filter(None, map(project, threadpool_map(
            call, ids, max_workers=max_workers)))


@overload
def iter_selected_nodes_using_star_event(
    client: str | P115Client, 
    ids: Iterable[int], 
    with_pics: bool = False, 
    normalize_attr: None | bool | Callable[[dict], dict] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_nodes_using_star_event(
    client: str | P115Client, 
    ids: Iterable[int], 
    with_pics: bool = False, 
    normalize_attr: None | bool | Callable[[dict], dict] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_nodes_using_star_event(
    client: str | P115Client, 
    ids: Iterable[int], 
    with_pics: bool = False, 
    normalize_attr: None | bool | Callable[[dict], dict] = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    app: str = "web", 
    cooldown: int | float = 0, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """é€šè¿‡æ‰“æ˜Ÿæ ‡æ¥è·å–ä¸€ç»„ id çš„ä¿¡æ¯

    .. caution::
        å¦‚æœ id å·²ç»è¢«åˆ é™¤ï¼Œåˆ™æ‰“æ˜Ÿæ ‡æ—¶ä¼šæŠ¥é”™

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param with_pics: åŒ…å«å›¾ç‰‡çš„ id
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸ï¼Œå¦‚æœä¸º ...ï¼Œåˆ™å¿½ç•¥
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0 æ—¶ï¼Œä¸¤æ¬¡æ‹‰å–æ“ä½œäº‹ä»¶çš„æ¥å£è°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš”è¿™ä¹ˆå¤šç§’
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿç®€ç•¥çš„ä¿¡æ¯

        .. code:: python

            {
                "id": int, 
                "parent_id": int, 
                "name": str, 
                "is_dir": 0 | 1, 
                "pickcode": str, 
                "sha1": str, 
                "size": int, 
                "star": 0 | 1, 
                "labels": list[dict], 
                "ftype": int, 
                "type": int, 
            }
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    def gen_step():
        nonlocal ids
        ts = int(time())
        ids = set(ids)
        yield life_show(client, async_=async_, **request_kwargs)
        yield update_star(client, ids, async_=async_, **request_kwargs)
        if app in ("", "web", "desktop", "harmony"):
            get_base_url = cycle(("http://webapi.115.com", "https://webapi.115.com")).__next__
        else:
            get_base_url = cycle(("http://proapi.115.com", "https://proapi.115.com")).__next__
        request_kwargs.setdefault("base_url", get_base_url)
        discard = ids.discard
        it = iter_life_behavior_once(
            client, 
            from_time=ts, 
            type="star_file", 
            app=app, 
            cooldown=cooldown, 
            async_=async_, 
            **request_kwargs, 
        )
        if with_pics:
            it2 = iter_life_behavior_once(
                client, 
                from_time=ts, 
                type="star_image_file", 
                app=app, 
                cooldown=cooldown, 
                async_=async_, 
                **request_kwargs, 
            )
            if async_:
                it = async_chain(it, it2)
            else:
                it = chain(it, it2) # type: ignore
        do_next = anext if async_ else next
        try:
            while True:
                event: dict = yield do_next(it) # type: ignore
                fid = int(event["file_id"])
                pid = int(event["parent_id"])
                name = event["file_name"]
                is_dir = not event["file_category"]
                if is_dir and id_to_dirnode is not ...:
                    id_to_dirnode[fid] = DirNode(name, pid)
                if fid in ids:
                    if not normalize_attr:
                        yield Yield(event, identity=True)
                    elif normalize_attr is True:
                        attr = {
                            "id": fid, 
                            "parent_id": pid, 
                            "name": name, 
                            "is_dir": is_dir, 
                            "pickcode": event["pick_code"], 
                            "sha1": event["sha1"], 
                            "size": event["file_size"], 
                            "star": event["is_mark"], 
                            "labels": event["fl"], 
                            "ftype": event["file_type"], 
                        }
                        if attr["is_dir"]:
                            attr["type"] = 0
                        elif event.get("isv"):
                            attr["type"] = 4
                        elif event.get("play_long"):
                            attr["type"] = 3
                        else:
                            attr["type"] = type_of_attr(attr)
                        yield Yield(attr, identity=True)
                    else:
                        yield Yield(normalize_attr(event), identity=True)
                    discard(fid)
                    if not ids:
                        break
        except (StopIteration, StopAsyncIteration):
            pass
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_selected_dirs_using_star(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    already_stared: bool = False, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_selected_dirs_using_star(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    already_stared: bool = False, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_selected_dirs_using_star(
    client: str | P115Client, 
    ids: Iterable[int], 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    raise_for_changed_count: bool = False, 
    app: str = "web", 
    cooldown: int | float = 0, 
    already_stared: bool = False, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """é€šè¿‡æ‰“æ˜Ÿæ ‡æ¥è·å–ä¸€ç»„ id çš„ä¿¡æ¯ï¼ˆä»…æ”¯æŒç›®å½•ï¼‰

    .. caution::
        å¦‚æœ id å·²ç»è¢«åˆ é™¤ï¼Œåˆ™æ‰“æ˜Ÿæ ‡æ—¶ä¼šæŠ¥é”™

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€ç»„ç›®å½•çš„ idï¼ˆå¦‚æœåŒ…æ‹¬æ–‡ä»¶ï¼Œåˆ™ä¼šè¢«å¿½ç•¥ï¼‰
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0 æ—¶ï¼Œä¸¤æ¬¡æ¥å£è°ƒç”¨ä¹‹é—´è‡³å°‘é—´éš”è¿™ä¹ˆå¤šç§’
    :param already_stared: è¯´æ˜æ‰€æœ‰ id éƒ½å·²ç»æ‰“è¿‡æ˜Ÿæ ‡ï¼Œä¸ç”¨å†æ¬¡æ‰“æ˜Ÿæ ‡
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿè¯¦ç»†çš„ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def gen_step():
        nonlocal ids
        ts = int(time())
        ids = set(ids)
        if not already_stared:
            yield update_star(client, ids, async_=async_, **request_kwargs)
        yield update_desc(client, ids, async_=async_, **request_kwargs)
        discard = ids.discard
        it = iter_stared_dirs(
            client, 
            order="user_utime", 
            asc=0, 
            first_page_size=len(ids), 
            id_to_dirnode=id_to_dirnode, 
            normalize_attr=normalize_attr, 
            app=app, 
            cooldown=cooldown, 
            async_=async_, # type: ignore
            **request_kwargs, 
        )
        do_next = anext if async_ else next
        try:
            while True:
                info: dict = yield do_next(it) # type: ignore
                if normalize_attr is None:
                    attr: Any = _overview_attr(info)
                else:
                    attr = info
                if not (attr["mtime"] >= ts and attr["is_dir"]):
                    break
                cid = attr["id"]
                if cid in ids:
                    yield Yield(info, identity=True)
                    discard(cid)
                    if not ids:
                        break
        except (StopIteration, StopAsyncIteration):
            pass
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_files_with_dirname(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    with_parents_4_level: bool = False, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_files_with_dirname(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    with_parents_4_level: bool = False, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_files_with_dirname(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    with_parents_4_level: bool = False, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å« "dir_name" å’Œ "dir_pickcode"ï¼Œå³ç›®å½•çš„åå­—å’Œæå–ç ï¼Œæ ¹ç›®å½•åå­—å’Œæå–ç éƒ½æ˜¯ ""ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param with_parents_4_level: æ·»åŠ ä¸€ä¸ªå­—æ®µ "parents"ï¼ŒåŒ…å«æœ€è¿‘çš„ 4 çº§çˆ¶ç›®å½•åå­—
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    suffix = suffix.strip(".")
    if not (type or suffix):
        raise ValueError("please set the non-zero value of suffix or type")
    payload: dict = {
        "asc": asc, "cid": cid, "count_folders": 0, "cur": 0, "o": order, 
        "offset": 0, "show_dir": 0, 
    }
    if suffix:
        payload["suffix"] = suffix
    elif type != 99:
        payload["type"] = type
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    request_kwargs.update(
        page_size=page_size, 
        app=app, 
        raise_for_changed_count=raise_for_changed_count, 
    )
    if cooldown <= 0:
        request_kwargs["async_"] = async_
        func: Callable = iter_fs_files
    else:
        request_kwargs["cooldown"] = cooldown
        request_kwargs["max_workers"] = max_workers
        func = iter_fs_files_asynchronized if async_ else iter_fs_files_threaded
    pid_to_info = {0: {"dir_name": "", "dir_pickcode": ""}}
    def callback(resp: dict, /):
        files = resp["data"] = list(map(normalize_attr, resp["data"]))
        pids = (pid for a in files if (pid := a["parent_id"]) not in pid_to_info)
        if async_:
            async def request():
                async for info in iter_nodes_skim(
                    client, 
                    pids, 
                    async_=True, 
                    **request_kwargs, 
                ):
                    pid_to_info[int(info["file_id"])] = {
                        "dir_name": info["file_name"], 
                        "dir_pickcode": info["pick_code"], 
                    }
            return request()
        else:
            pid_to_info.update(
                (int(info["file_id"]), {
                    "dir_name": info["file_name"], 
                    "dir_pickcode": info["pick_code"], 
                })
                for info in iter_nodes_skim(
                    client, 
                    pids, 
                    **request_kwargs, 
                )
            )
    def gen_step():
        it = func(client, payload, callback=callback, **request_kwargs)
        get_next = it.__anext__ if async_ else it.__next__
        try:
            while True:
                resp = yield get_next
                for attr in resp["data"]:
                    attr.update(pid_to_info[attr["parent_id"]])
                    yield Yield(attr, identity=True)
        except (StopIteration, StopAsyncIteration):
            pass
    if with_parents_4_level:
        def gen_step2():
            files: list[dict] = []
            add_file = files.append
            def get_pid(attr):
                add_file(attr)
                return attr["parent_id"]
            it = iter_parents_3_level(
                client, 
                iter_unique((async_map if async_ else map)( 
                    get_pid, run_gen_step_iter(gen_step, async_=async_))), # type: ignore
                async_=async_, # type: ignore
                **request_kwargs, 
            )
            if async_:
                async def collect():
                    return {k: v async for k, v in cast(AsyncIterator, it)}
                id_to_parents: dict[int, tuple[str, str, str]] = yield collect
            else:
                id_to_parents = dict(it) # type: ignore
            id_to_parents[0] = ("", "", "")
            for attr in files:
                attr["parents"] = (attr["dir_name"], *id_to_parents[attr["parent_id"]])
                yield Yield(attr, identity=True)
        return run_gen_step_iter(gen_step2, async_=async_)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_files_with_path(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    escape: None | bool | Callable[[str], str] = True, 
    with_ancestors: bool = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    path_already: bool = False, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_files_with_path(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    escape: None | bool | Callable[[str], str] = True, 
    with_ancestors: bool = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    path_already: bool = False, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_files_with_path(
    client: str | P115Client, 
    cid: int = 0, 
    page_size: int = 0, 
    suffix: str = "", 
    type: Literal[1, 2, 3, 4, 5, 6, 7, 99] = 99, 
    order: Literal["file_name", "file_size", "file_type", "user_utime", "user_ptime", "user_otime"] = "user_ptime", 
    asc: Literal[0, 1] = 1, 
    cur: Literal[0, 1] = 0, 
    normalize_attr: Callable[[dict], dict] = normalize_attr, 
    escape: None | bool | Callable[[str], str] = True, 
    with_ancestors: bool = True, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    path_already: bool = False, 
    raise_for_changed_count: bool = False, 
    app: str = "android", 
    cooldown: int | float = 0.5, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å« "path"ï¼Œå¯é€‰ "ancestors"ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id
    :param page_size: åˆ†é¡µå¤§å°
    :param suffix: åç¼€åï¼ˆä¼˜å…ˆçº§é«˜äº typeï¼‰
    :param type: æ–‡ä»¶ç±»å‹

        - 1: æ–‡æ¡£
        - 2: å›¾ç‰‡
        - 3: éŸ³é¢‘
        - 4: è§†é¢‘
        - 5: å‹ç¼©åŒ…
        - 6: åº”ç”¨
        - 7: ä¹¦ç±
        - 99: ä»…æ–‡ä»¶

    :param order: æ’åº

        - "file_name": æ–‡ä»¶å
        - "file_size": æ–‡ä»¶å¤§å°
        - "file_type": æ–‡ä»¶ç§ç±»
        - "user_utime": ä¿®æ”¹æ—¶é—´
        - "user_ptime": åˆ›å»ºæ—¶é—´
        - "user_otime": ä¸Šä¸€æ¬¡æ‰“å¼€æ—¶é—´

    :param asc: å‡åºæ’åˆ—ã€‚0: å¦ï¼Œ1: æ˜¯
    :param cur: ä»…å½“å‰ç›®å½•ã€‚0: å¦ï¼ˆå°†éå†å­ç›®å½•æ ‘ä¸Šæ‰€æœ‰å¶å­èŠ‚ç‚¹ï¼‰ï¼Œ1: æ˜¯
    :param normalize_attr: æŠŠæ•°æ®è¿›è¡Œè½¬æ¢å¤„ç†ï¼Œä½¿ä¹‹ä¾¿äºé˜…è¯»
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param with_ancestors: æ–‡ä»¶ä¿¡æ¯ä¸­æ˜¯å¦è¦åŒ…å« "ancestors"
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param path_already: å¦‚æœä¸º Trueï¼Œåˆ™è¯´æ˜ id_to_dirnode ä¸­å·²ç»å…·å¤‡æ„å»ºè·¯å¾„æ‰€éœ€è¦çš„ç›®å½•èŠ‚ç‚¹ï¼Œæ‰€ä»¥ä¸ä¼šå†å»æ‹‰å–ç›®å½•èŠ‚ç‚¹çš„ä¿¡æ¯
    :param raise_for_changed_count: åˆ†æ‰¹æ‹‰å–æ—¶ï¼Œå‘ç°æ€»æ•°å‘ç”Ÿå˜åŒ–åï¼Œæ˜¯å¦æŠ¥é”™
    :param app: ä½¿ç”¨æŸä¸ª app ï¼ˆè®¾å¤‡ï¼‰çš„æ¥å£
    :param cooldown: å†·å´æ—¶é—´ï¼Œå¤§äº 0ï¼Œåˆ™ä½¿ç”¨æ­¤æ—¶é—´é—´éš”æ‰§è¡Œå¹¶å‘
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    suffix = suffix.strip(".")
    if not (type or suffix):
        raise ValueError("please set the non-zero value of suffix or type")
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    elif id_to_dirnode is ...:
        id_to_dirnode = {}
        path_already = False
    _path_already: None | bool = None if path_already else False
    if not path_already:
        from .download import iter_download_nodes
        def set_path_already(*a):
            nonlocal _path_already
            _path_already = True
        def fetch_dirs(id: int | str, /):
            if id:
                if isinstance(id, int):
                    resp = yield client.fs_file_skim(id, async_=async_, **request_kwargs)
                    check_response(resp)
                    pickcode = resp["data"][0]["pick_code"]
                else:
                    pickcode = id
                with with_iter_next(iter_download_nodes(
                    client, 
                    pickcode, 
                    files=False, 
                    max_workers=None, 
                    async_=async_, 
                    **request_kwargs, 
                )) as get_next_info:
                    while True:
                        info = yield get_next_info
                        id_to_dirnode[int(info["fid"])] = DirNode(info["fn"], int(info["pid"]))
            else:
                with with_iter_next(iterdir(
                    client, 
                    ensure_file=False, 
                    id_to_dirnode=id_to_dirnode, 
                    app=app, 
                    async_=async_, 
                    **request_kwargs, 
                )) as get_next:
                    while True:
                        attr = yield get_next
                        yield run_gen_step(fetch_dirs(attr["pickcode"]), async_=async_)
    if with_ancestors:
        id_to_ancestors: dict[int, list[dict]] = {}
        def get_ancestors(id: int, attr: dict | tuple[str, int] | DirNode, /) -> list[dict]:
            if isinstance(attr, (DirNode, tuple)):
                name, pid = attr
            else:
                pid = attr["parent_id"]
                name = attr["name"]
            if pid == 0:
                ancestors = [{"id": 0, "parent_id": 0, "name": ""}]
            else:
                if pid not in id_to_ancestors:
                    id_to_ancestors[pid] = get_ancestors(pid, id_to_dirnode[pid])
                ancestors = [*id_to_ancestors[pid]]
            ancestors.append({"id": id, "parent_id": pid, "name": name})
            return ancestors
    id_to_path: dict[int, str] = {}
    def get_path(attr: dict | tuple[str, int] | DirNode, /) -> str:
        if isinstance(attr, (DirNode, tuple)):
            name, pid = attr
        else:
            pid = attr["parent_id"]
            name = attr["name"]
        if escape is not None:
            name = escape(name)
        if pid == 0:
            dirname = "/"
        elif pid in id_to_path:
            dirname = id_to_path[pid]
        else:
            dirname = id_to_path[pid] = get_path(id_to_dirnode[pid]) + "/"
        return dirname + name
    def update_path(attr: dict, /) -> dict:
        try:
            if with_ancestors:
                attr["ancestors"] = get_ancestors(attr["id"], attr)
            attr["path"] = get_path(attr)
        except KeyError:
            pass
        return attr
    def gen_step():
        nonlocal _path_already
        cache: list[dict] = []
        add_to_cache = cache.append
        if not path_already:
            if async_:
                task: Any = create_task(run_gen_step(fetch_dirs(cid), async_=True))
            else:
                task = run_as_thread(run_gen_step, fetch_dirs(cid))
            task.add_done_callback(set_path_already)
        with with_iter_next(iter_files(
            client, 
            cid, 
            page_size=page_size, 
            suffix=suffix, 
            type=type, 
            order=order, 
            asc=asc, 
            cur=cur, 
            normalize_attr=normalize_attr, 
            id_to_dirnode=id_to_dirnode, 
            raise_for_changed_count=raise_for_changed_count, 
            max_workers=max_workers, 
            app=app, 
            cooldown=cooldown, 
            async_=async_, # type: ignore
            **request_kwargs, 
        )) as get_next:
            while True:
                attr = yield get_next
                if _path_already is None:
                    yield Yield(update_path(attr), identity=True)
                elif _path_already:
                    if async_:
                        yield task
                    else:
                        task.result()
                    if cache:
                        yield YieldFrom(map(update_path, cache), identity=True)
                        cache.clear()
                    yield Yield(update_path(attr), identity=True)
                    _path_already = None
                else:
                    add_to_cache(attr)
        if cache:
            if async_:
                yield task
            else:
                task.result()
            yield YieldFrom(map(update_path, cache), identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_files_with_path_by_export_dir(
    client: str | P115Client, 
    cid: int, 
    escape: None | bool | Callable[[str], str] = True, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_files_with_path_by_export_dir(
    client: str | P115Client, 
    cid: int, 
    escape: None | bool | Callable[[str], str] = True, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_files_with_path_by_export_dir(
    client: str | P115Client, 
    cid: int, 
    escape: None | bool | Callable[[str], str] = True, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒ…å« "path"ï¼‰

    .. important::
        ç›¸æ¯”è¾ƒäº `iter_files`ï¼Œè¿™ä¸ªå‡½æ•°ä¸“é—¨é’ˆå¯¹è·å–è·¯å¾„çš„é£æ§é—®é¢˜åšäº†ä¼˜åŒ–ï¼Œä¼šç”¨åˆ° å¯¼å‡ºç›®å½•æ ‘ï¼Œå°è¯•è¿›è¡ŒåŒ¹é…ï¼Œä¸èƒ½å”¯ä¸€ç¡®å®šçš„ï¼Œä¼šå†ç”¨å…¶å®ƒåŠæ³•è·å–è·¯å¾„

    .. note::
        é€šè¿‡å‡ ä¸ªæ­¥éª¤ä¸€ç‚¹ç‚¹å‡å°‘è¦æ£€æŸ¥çš„æ•°æ®é‡ï¼š

        1. unique name: å¯¼å‡ºç›®å½•æ ‘ä¸­ï¼Œå”¯ä¸€å‡ºç°çš„åå­—ï¼Œå°±å¯ä»¥ç›´æ¥ç¡®å®šåŒä¸€ä¸ªç›®å½•ä¸‹æ‰€æœ‰èŠ‚ç‚¹çš„è·¯å¾„
        2. unique listdir: å¯¼å‡ºç›®å½•æ ‘ä¸­ï¼Œä¸€ä¸ªç›®å½•ä¸‹æ‰€æœ‰åå­—ï¼ˆå¯ä»¥ç†è§£ä¸º listdirï¼‰çš„ç»„åˆï¼Œåªè¦å®ƒæ˜¯å”¯ä¸€çš„ï¼Œå°±èƒ½å”¯ä¸€ç¡®å®šåŒä¸€ä¸ªç›®å½•ä¸‹æ‰€æœ‰èŠ‚ç‚¹çš„è·¯å¾„
        3. repeat 1-2 for higher dir: å¼•å…¥ç›®å½•çš„åå­—åï¼Œå†è€ƒè™‘ `1` å’Œ `2`ï¼Œåˆå¯æ’é™¤æ‰ä¸€éƒ¨åˆ†
        4. repeat 3: é€šè¿‡åå¤å¼•å…¥æ›´é«˜å±‚çº§çš„ç›®å½•åå­—ï¼Œåå¤æ‰§è¡Œ `3`ï¼Œæœ€åæ€»èƒ½ç¡®å®šå®Œæ•´è·¯å¾„ï¼Œæœ€åçš„æƒ…å†µå°±æ˜¯ç›´åˆ° `cid` ä¸ºæ­¢æ‰æŠŠæ‰€æœ‰æœªå®šé¡¹ç¡®å®š

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• idï¼Œä¸èƒ½ä¸º 0 ï¼ˆå—é™äº export_dir æ¥å£ï¼‰
    :param escape: å¯¹æ–‡ä»¶åè¿›è¡Œè½¬ä¹‰

        - å¦‚æœä¸º Noneï¼Œåˆ™ä¸å¤„ç†ï¼›å¦åˆ™ï¼Œè¿™ä¸ªå‡½æ•°ç”¨æ¥å¯¹æ–‡ä»¶åä¸­æŸäº›ç¬¦å·è¿›è¡Œè½¬ä¹‰ï¼Œä¾‹å¦‚ "/" ç­‰
        - å¦‚æœä¸º Trueï¼Œåˆ™ä½¿ç”¨ `posixpatht.escape`ï¼Œä¼šå¯¹æ–‡ä»¶åä¸­ "/"ï¼Œæˆ–å•ç‹¬å‡ºç°çš„ "." å’Œ ".." ç”¨ "\\" è¿›è¡Œè½¬ä¹‰
        - å¦‚æœä¸º Falseï¼Œåˆ™ä½¿ç”¨ `posix_escape_name` å‡½æ•°å¯¹åå­—è¿›è¡Œè½¬ä¹‰ï¼Œä¼šæŠŠæ–‡ä»¶åä¸­çš„ "/" è½¬æ¢ä¸º "|"
        - å¦‚æœä¸º Callableï¼Œåˆ™ç”¨ä½ æ‰€æä¾›çš„è°ƒç”¨ï¼Œä»¥æˆ–è€…è½¬ä¹‰åçš„åå­—

    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…æ–‡ä»¶ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    from .export_dir import export_dir, export_dir_parse_iter, parse_export_dir_as_patht_iter
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if isinstance(escape, bool):
        if escape:
            from posixpatht import escape
        else:
            escape = posix_escape_name
    escape = cast(None | Callable[[str], str], escape)
    def gen_step():
        append = list.append
        # é¦–å…ˆå¯åŠ¨å¯¼å‡ºç›®å½•çš„åå°ä»»åŠ¡
        export_id = yield export_dir(client, cid, async_=async_, **request_kwargs)
        # åå­— åˆ° parent_id çš„æ˜ å°„ï¼Œå¦‚æœåå­—ä¸å”¯ä¸€ï¼Œåˆ™ parent_id è®¾ä¸º 0
        name_to_pid: dict[str, int] = {}
        # è·å–æŒ‡å®šç›®å½•æ ‘ä¸‹çš„æ‰€æœ‰æ–‡ä»¶èŠ‚ç‚¹ä¿¡æ¯ï¼Œå†æ ¹æ® parent_id åˆ†ç»„
        pid_to_files: defaultdict[int, list[dict]] = defaultdict(list)
        def update_name_to_pid(attr: dict, /):
            pid = attr["parent_id"]
            name = attr["name"]
            append(pid_to_files[pid], attr)
            if name in name_to_pid:
                name_to_pid[name] = 0
            else:
                name_to_pid[name] = pid
        yield foreach(
            update_name_to_pid, 
            iter_files(
                client, 
                cid, 
                app="android", 
                cooldown=0.5, 
                async_=async_, # type: ignore
                **request_kwargs, 
            ), 
        )
        # ä»å¯¼å‡ºçš„ç›®å½•æ ‘æ–‡ä»¶ä¸­è·å–å®Œæ•´è·¯å¾„ï¼Œå†æ ¹æ®æ‰€å½’å±ç›®å½•çš„è·¯å¾„å¯¹åå­—è¿›è¡Œåˆ†ç»„
        dirpatht_to_names: dict[tuple[str, ...], list[str]] = defaultdict(list)
        def update_dirpatht_to_names(patht: list[str], /):
            append(dirpatht_to_names[tuple(patht[:-1])], patht[-1])
        yield foreach(
            update_dirpatht_to_names, 
            export_dir_parse_iter(
                client, 
                export_id=export_id, 
                parse_iter=parse_export_dir_as_patht_iter, 
                async_=async_, # type: ignore
                **request_kwargs, 
            ), 
        )
        if not name_to_pid or not dirpatht_to_names:
            return
        # å°½é‡ä»æ‰€æ”¶é›†åˆ°åå­—ä¸­ç§»é™¤ç›®å½•
        for dir_patht in islice(dirpatht_to_names, 1, None):
            dirpatht_to_names[dir_patht[:-1]].remove(dir_patht[-1])
        # æ”¶é›†æ‰€æœ‰åå­—åˆ°æ‰€å½’å±ç›®å½•çš„è·¯å¾„
        name_to_dirpatht: dict[str, tuple[str, ...]] = {}
        for dir_patht, names in dirpatht_to_names.items():
            for name in names:
                if name in name_to_dirpatht:
                    name_to_dirpatht[name] = ()
                else:
                    name_to_dirpatht[name] = dir_patht
        # ç”¨å”¯ä¸€å‡ºç°è¿‡çš„åå­—ï¼Œå°½é‡ç¡®å®šæ‰€æœ‰ parent_id æ‰€å¯¹åº”çš„è·¯å¾„
        pid_to_dirpatht: dict[int, tuple[str, ...]] = {}
        undetermined: dict[tuple[str, ...], tuple[str, ...]] = {}
        for dir_patht, names in dirpatht_to_names.items():
            if not names:
                continue
            for name in names:
                if (pid := name_to_pid.get(name)) and name_to_dirpatht[name]:
                    pid_to_dirpatht[pid] = dir_patht
                    break
            else:
                names.sort()
                group_key = tuple(names)
                if group_key in undetermined:
                    undetermined[group_key] = ()
                else:
                    undetermined[group_key] = dir_patht
                def detect_file(name: str, /) -> bool:
                    if ext := splitext(name)[-1][1:]:
                        return bool(ext.strip(digits)) and ext.isalnum()
                    return False
                group_key2 = tuple(filter(detect_file, names))
                if group_key != group_key2:
                    if group_key2 in undetermined:
                        undetermined[group_key2] = ()
                    else:
                        undetermined[group_key2] = dir_patht
        # å‡è®¾æ–‡ä»¶ååˆ—è¡¨ç›¸åŒï¼Œå°±å…³è” parent_id åˆ°å®ƒçš„è·¯å¾„ï¼ˆæ³¨æ„ï¼šè¿™æœ‰å¯èƒ½å‡ºé”™ï¼Œä¾‹å¦‚æœ‰ç©ºç›®å½•å’ŒæŸä¸ªæ–‡ä»¶åŒåæ—¶ï¼‰
        if pids := pid_to_files.keys() - pid_to_dirpatht.keys():
            for pid in pids:
                group_key = tuple(sorted(attr["name"] for attr in pid_to_files[pid]))
                if dir_patht := undetermined.get(group_key, ()):
                    pid_to_dirpatht[pid] = dir_patht
            pids = pid_to_files.keys() - pid_to_dirpatht.keys()
            if pids:
                for dir_patht in pid_to_dirpatht.values():
                    del dirpatht_to_names[dir_patht]
        del name_to_pid, name_to_dirpatht, undetermined
        def update_pid_dict(info: dict, /):
            fid = int(info["file_id"])
            if name in name_to_pid:
                name_to_pid[name] = 0
            else:
                name_to_pid[name] = fid
            id_to_pickcode[fid] = info["pick_code"]
        id_to_dirnode: dict[int, tuple[str, int] | DirNode] = {}
        go_back_depth = 1
        while pids:
            id_to_pickcode: dict[int, str] = {}
            name_to_pid = {}
            yield foreach(
                update_pid_dict, 
                iter_nodes_skim(client, pids, async_=async_, **request_kwargs), 
            )
            name_idx = -go_back_depth
            name_to_dirpatht = {}
            name_to_list_dirpatht: dict[str, list[tuple[str, ...]]] = defaultdict(list)
            for dir_patht in dirpatht_to_names:
                if len(dir_patht) > go_back_depth:
                    name = dir_patht[name_idx]
                    append(name_to_list_dirpatht[name], dir_patht)
                    dir_patht = dir_patht[:name_idx]
                    if name in name_to_dirpatht:
                        if name_to_dirpatht[name] != dir_patht:
                            name_to_dirpatht[name] = ()
                    else:
                        name_to_dirpatht[name] = dir_patht
            for name, pid in name_to_pid.items():
                if dir_patht := name_to_dirpatht.get(name, ()):
                    pid_to_dirpatht[pid] = dir_patht
                    for dir_patht in name_to_list_dirpatht[name]:
                        del dirpatht_to_names[dir_patht]
                    del id_to_pickcode[pid]
            # TODO: å†ç”¨æ‰åå­—ç»„åˆåä¹Ÿæ˜¯å”¯ä¸€çš„éƒ¨åˆ†è·¯å¾„
            # TODO: å†ç”¨æ‰åå­—ç»„åˆåå”¯ä¸€çš„éƒ¨åˆ†è·¯å¾„ç»„åˆ
            if len(id_to_pickcode) >= 1000:
                yield through(iter_selected_nodes_using_star_event(
                    client, 
                    id_to_pickcode, 
                    normalize_attr=None, 
                    id_to_dirnode=id_to_dirnode, 
                    app="android", 
                    cooldown=0.5, 
                    async_=async_, # type: ignore
                    **request_kwargs, 
                ))
            else:
                yield through(iter_selected_nodes_by_pickcode(
                    client, 
                    id_to_pickcode.values(), 
                    normalize_attr=None, 
                    id_to_dirnode=id_to_dirnode, 
                    ignore_deleted=None, 
                    async_=async_, # type: ignore
                    **request_kwargs, 
                ))
            pids = {
                pid for id in id_to_pickcode
                if (pid := id_to_dirnode[id][1]) and pid not in id_to_dirnode and pid not in pid_to_dirpatht
            }
            go_back_depth += 1
        for pid in pid_to_files.keys() - pid_to_dirpatht.keys():
            if pid not in id_to_dirnode:
                continue
            ls_pid = [pid]
            name, pid = id_to_dirnode[pid]
            names = [name]
            dir_patht = ()
            while pid:
                if pid in pid_to_dirpatht:
                    dir_patht = pid_to_dirpatht[pid]
                    break
                append(ls_pid, pid)
                name, pid = id_to_dirnode[pid]
                append(names, name)
            else:
                if not pid:
                    dir_patht = ("",)
            if dir_patht:
                ls_pid.reverse()
                names.reverse()
                for pid, name in zip(ls_pid, names):
                    dir_patht = pid_to_dirpatht[pid] = (*dir_patht, name)
        del id_to_dirnode, dirpatht_to_names
        # è¿­ä»£åœ°è¿”å›æ‰€æœ‰æ–‡ä»¶èŠ‚ç‚¹ä¿¡æ¯
        for pid, files in pid_to_files.items():
            if pid not in pid_to_dirpatht:
                continue
            dir_patht = pid_to_dirpatht[pid]
            dir_path = joins(dir_patht) + "/"
            for attr in files:
                name = attr["name"]
                if escape is not None:
                    name = escape(name)
                attr["path"] = dir_path + name
                yield Yield(attr, identity=True)
    return run_gen_step_iter(gen_step, async_=async_)


@overload
def iter_parents_3_level(
    client: str | P115Client, 
    ids: Iterable[int], 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[tuple[int, tuple[str, str, str]]]:
    ...
@overload
def iter_parents_3_level(
    client: str | P115Client, 
    ids: Iterable[int] | AsyncIterable[int], 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[tuple[int, tuple[str, str, str]]]:
    ...
def iter_parents_3_level(
    client: str | P115Client, 
    ids: Iterable[int] | AsyncIterable[int], 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[tuple[int, tuple[str, str, str]]] | AsyncIterator[tuple[int, tuple[str, str, str]]]:
    """è·å–ä¸€æ‰¹ id çš„ä¸Šçº§ç›®å½•ï¼Œæœ€å¤šè·å– 3 çº§

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param ids: ä¸€æ‰¹æ–‡ä»¶æˆ–ç›®å½•çš„ id
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œäº§ç”Ÿ id å’Œ æœ€è¿‘ 3 çº§ç›®å½•åçš„å…ƒç»„çš„ 2 å…ƒç»„
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    def fix_overflow(t: tuple[str, ...], /) -> tuple[str, ...]:
        try:
            start = t.index("æ–‡ä»¶") + 1
            return t[start:][::-1] + ("",) * start
        except ValueError:
            return t[::-1]
    set_names = client.fs_rename_set_names
    reset_names = client.fs_rename_reset_names
    def get_parents(ids: Sequence[int], /):
        data: dict = {f"file_list[{i}][file_id]": id for i, id in enumerate(ids)}
        resp = yield set_names(data, async_=async_, **request_kwargs)
        check_response(resp)
        req_id = resp["req_id"]
        data = {
            "func_list[0][name]": "addParent", 
            "func_list[0][config][level]": 1, 
            "func_list[0][config][position]": 1, 
            "func_list[0][config][separator]": 0, 
            "req_id": req_id, 
        }
        while True:
            resp = yield reset_names(data, async_=async_, **request_kwargs)
            if resp["data"][0]["file_name"]:
                l1 = [d["file_name"] for d in resp["data"]]
                break
            if async_:
                yield async_sleep(0.25)
            else:
                sleep(0.25)
        if len(ids) - l1.count("æ–‡ä»¶") <= 0:
            return ((id, ("" if name == "æ–‡ä»¶" else name, "", "")) for id, name in zip(ids, l1))
        def call(i):
            return check_response(reset_names(
                {**data, "func_list[0][config][level]": i}, 
                async_=async_, 
                **request_kwargs, 
            ))
        ret = batch_map(call, (2, 3), max_workers=2)
        if async_:
            ret = yield to_list(ret)
        resp2, resp3 = cast(Iterable, ret)
        l2 = [d["file_name"] for d in resp2["data"]]
        l3 = (d["file_name"] for d in resp3["data"])
        return ((id, fix_overflow(t)) for id, t in zip(ids, zip(l3, l2, l1)))
    batch_map = taskgroup_map if async_ else threadpool_map
    ids = (async_filter if async_ else filter)(None, ids) # type: ignore
    return flatten(
        batch_map(
            lambda ids, /: run_gen_step(get_parents(ids), async_=async_), 
            chunked(ids, 1150), 
            max_workers=max_workers, 
        ), 
        exclude_types=tuple, 
    )


@overload
def iter_dir_nodes(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False] = False, 
    **request_kwargs, 
) -> Iterator[dict]:
    ...
@overload
def iter_dir_nodes(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[True], 
    **request_kwargs, 
) -> AsyncIterator[dict]:
    ...
def iter_dir_nodes(
    client: str | P115Client, 
    cid: int | str = 0, 
    id_to_dirnode: None | EllipsisType | dict[int, tuple[str, int] | DirNode] = None, 
    max_workers: None | int = None, 
    *, 
    async_: Literal[False, True] = False, 
    **request_kwargs, 
) -> Iterator[dict] | AsyncIterator[dict]:
    """éå†ç›®å½•æ ‘ï¼Œè·å–ç›®å½•èŠ‚ç‚¹ä¿¡æ¯ï¼ˆç®€ç•¥ï¼‰

    :param client: 115 å®¢æˆ·ç«¯æˆ– cookies
    :param cid: ç›®å½• id æˆ– pickcode
    :param id_to_dirnode: å­—å…¸ï¼Œä¿å­˜ id åˆ°å¯¹åº”æ–‡ä»¶çš„ `DirNode(name, parent_id)` å‘½åå…ƒç»„çš„å­—å…¸
    :param max_workers: æœ€å¤§å¹¶å‘æ•°
    :param async_: æ˜¯å¦å¼‚æ­¥
    :param request_kwargs: å…¶å®ƒè¯·æ±‚å‚æ•°

    :return: è¿­ä»£å™¨ï¼Œè¿”å›æ­¤ç›®å½•å†…çš„ï¼ˆä»…ç›®å½•ï¼‰æ–‡ä»¶ä¿¡æ¯
    """
    if isinstance(client, str):
        client = P115Client(client, check_for_relogin=True)
    if id_to_dirnode is None:
        id_to_dirnode = ID_TO_DIRNODE_CACHE[client.user_id]
    from .download import iter_download_nodes
    def gen_step(id: int | str, /):
        if id:
            if isinstance(id, int):
                resp = yield client.fs_file_skim(id, async_=async_, **request_kwargs)
                check_response(resp)
                pickcode = resp["data"][0]["pick_code"]
            else:
                pickcode = id
            with with_iter_next(iter_download_nodes(
                client, 
                pickcode, 
                files=False, 
                max_workers=max_workers, 
                async_=async_, 
                **request_kwargs, 
            )) as get_next_info:
                while True:
                    info = yield get_next_info
                    id = int(info["fid"])
                    parent_id = int(info["pid"])
                    name = info["fn"]
                    if id_to_dirnode is not ...:
                        id_to_dirnode[id] = DirNode(name, parent_id)
                    yield Yield(
                        {"id": id, "parent_id": parent_id, "name": name}, 
                        identity=True, 
                    )
        else:
            with with_iter_next(iterdir(
                client, 
                ensure_file=False, 
                normalize_attr=normalize_attr_simple, 
                id_to_dirnode=id_to_dirnode, 
                async_=async_, 
                **request_kwargs, 
            )) as get_next:
                while True:
                    attr = yield get_next
                    yield Yield(
                        {
                            "id": attr["id"], 
                            "parent_id": attr["parent_id"], 
                            "name": attr["name"], 
                        }, 
                        identity=True, 
                    )
                    yield YieldFrom(
                        run_gen_step_iter(gen_step(attr["pickcode"]), async_=async_), 
                        identity=True, 
                    )
    return run_gen_step_iter(gen_step(cid or 0), async_=async_)

