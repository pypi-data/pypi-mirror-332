{
    "cells": [
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "# Flow Matching for Weather Prediction: Fundamentals\n",
          "\n",
          "This notebook introduces the foundational concepts of flow matching and how they apply to weather prediction. We will:\n",
          "\n",
          "1. Understand the mathematical foundations of flow matching\n",
          "2. Implement a simple flow matching model\n",
          "3. Visualize flow fields and trajectory evolution\n",
          "4. Connect these concepts to weather prediction\n",
          "5. Explore physical constraints in flow matching\n",
          "\n",
          "Flow matching is a powerful approach for modeling complex dynamical systems like weather, as it allows us to learn continuous transformations between states."
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## 1. Setup and Dependencies"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Install WeatherFlow if needed\n",
          "try:\n",
          "    import weatherflow\n",
          "    print(f\"WeatherFlow version: {weatherflow.__version__}\")\n",
          "except ImportError:\n",
          "    !pip install -e ..\n",
          "    import weatherflow\n",
          "    print(f\"WeatherFlow installed, version: {weatherflow.__version__}\")"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Import standard libraries\n",
          "import numpy as np\n",
          "import matplotlib.pyplot as plt\n",
          "import torch\n",
          "import torch.nn as nn\n",
          "import torch.nn.functional as F\n",
          "from torch.utils.data import DataLoader, TensorDataset\n",
          "from tqdm.notebook import tqdm\n",
          "import os\n",
          "import warnings\n",
          "warnings.filterwarnings('ignore')  # Suppress some warnings for cleaner output\n",
          "\n",
          "# Import specific WeatherFlow components\n",
          "from weatherflow.models.flow_matching import WeatherFlowMatch\n",
          "from weatherflow.utils import WeatherVisualizer\n",
          "\n",
          "# Set up matplotlib\n",
          "plt.rcParams['figure.figsize'] = (14, 8)\n",
          "plt.rcParams['figure.dpi'] = 100\n",
          "\n",
          "# Check for GPU availability\n",
          "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
          "print(f\"Using device: {device}\")"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## 2. Flow Matching Theory\n",
          "\n",
          "Flow matching is a technique for learning continuous transformations between probability distributions. It's closely related to continuous normalizing flows and can be used to model complex dynamical systems like weather evolution.\n",
          "\n",
          "### Key Concepts\n",
          "\n",
          "1. **Flow Fields**: Continuous vector fields that describe how a system evolves over time\n",
          "2. **Path Interpolation**: Creating smooth paths between source and target states\n",
          "3. **Vector Field Learning**: Learning velocity fields that can generate these paths\n",
          "4. **ODE Integration**: Using learned vector fields to generate new trajectories\n",
          "\n",
          "### Mathematical Foundation\n",
          "\n",
          "In flow matching, we learn a continuous-time flow that transforms a source distribution $p_0(\\mathbf{x})$ into a target distribution $p_1(\\mathbf{x})$. \n",
          "\n",
          "The key equation is:\n",
          "\n",
          "$$\\mathbf{v}(\\mathbf{x}_t, t) = \\frac{d\\mathbf{x}_t}{dt}$$\n",
          "\n",
          "Where $\\mathbf{v}(\\mathbf{x}_t, t)$ is the velocity field at point $\\mathbf{x}_t$ and time $t$.\n",
          "\n",
          "For straight-line paths between $\\mathbf{x}_0$ and $\\mathbf{x}_1$, the target velocity is simply:\n",
          "\n",
          "$$\\mathbf{v}_\\text{target}(\\mathbf{x}_t, t) = \\frac{\\mathbf{x}_1 - \\mathbf{x}_0}{1}$$\n",
          "\n",
          "The goal is to learn a neural network that can approximate this velocity field."
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "### How Flow Matching Differs from Other Approaches\n",
          "\n",
          "Flow matching has several advantages for weather prediction:\n",
          "\n",
          "1. **Continuous Time**: Models weather as a continuous process, unlike discrete steps in many ML approaches\n",
          "2. **Physical Constraints**: Can incorporate physical laws directly into the flow field\n",
          "3. **Uncertainty Quantification**: Naturally models distributions over possible weather states\n",
          "4. **Flexible Integration**: Can use different numerical methods for different accuracy/speed trade-offs"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## 3. Simple Example: 2D Toy Problem\n",
          "\n",
          "To build intuition, let's start with a simple 2D problem: learning a flow that transforms a Gaussian distribution into a mixture of Gaussians."
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Set random seed for reproducibility\n",
          "np.random.seed(42)\n",
          "torch.manual_seed(42)\n",
          "\n",
          "# Function to generate data from a simple Gaussian\n",
          "def sample_gaussian(n_samples, mean=[0, 0], std=1.0):\n",
          "    return np.random.normal(mean, std, size=(n_samples, 2))\n",
          "\n",
          "# Function to generate data from a mixture of Gaussians\n",
          "def sample_mixture(n_samples, means=[[2, 2], [-2, 2], [0, -2]], std=0.5):\n",
          "    k = len(means)\n",
          "    # Randomly choose which Gaussian to sample from\n",
          "    indices = np.random.choice(k, size=n_samples)\n",
          "    samples = np.zeros((n_samples, 2))\n",
          "    \n",
          "    for i in range(n_samples):\n",
          "        gaussian_idx = indices[i]\n",
          "        samples[i] = np.random.normal(means[gaussian_idx], std)\n",
          "        \n",
          "    return samples\n",
          "\n",
          "# Generate samples\n",
          "n_samples = 1000\n",
          "source_samples = sample_gaussian(n_samples)  # Simple Gaussian\n",
          "target_samples = sample_mixture(n_samples)   # Mixture of Gaussians\n",
          "\n",
          "# Plot the source and target distributions\n",
          "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
          "\n",
          "# Source distribution\n",
          "axes[0].scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.5, s=10)\n",
          "axes[0].set_title('Source Distribution: Single Gaussian')\n",
          "axes[0].set_xlim(-4, 4)\n",
          "axes[0].set_ylim(-4, 4)\n",
          "axes[0].grid(True)\n",
          "axes[0].set_aspect('equal')\n",
          "\n",
          "# Target distribution\n",
          "axes[1].scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.5, s=10)\n",
          "axes[1].set_title('Target Distribution: Mixture of Gaussians')\n",
          "axes[1].set_xlim(-4, 4)\n",
          "axes[1].set_ylim(-4, 4)\n",
          "axes[1].grid(True)\n",
          "axes[1].set_aspect('equal')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "### 3.1 Creating Training Pairs for Flow Matching\n",
          "\n",
          "For flow matching, we need matching pairs of points from the source and target distributions. We'll use simple random pairing for this toy example."
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Convert to PyTorch tensors\n",
          "source_tensor = torch.tensor(source_samples, dtype=torch.float32)\n",
          "target_tensor = torch.tensor(target_samples, dtype=torch.float32)\n",
          "\n",
          "# Create dataset and dataloader\n",
          "dataset = TensorDataset(source_tensor, target_tensor)\n",
          "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
          "\n",
          "# Let's visualize a few pairs of points\n",
          "n_vis = 10\n",
          "fig, ax = plt.subplots(figsize=(8, 8))\n",
          "\n",
          "# Plot all samples as background\n",
          "ax.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.2, s=10, color='blue', label='Source')\n",
          "ax.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.2, s=10, color='red', label='Target')\n",
          "\n",
          "# Plot a few pairs with connecting lines\n",
          "for i in range(n_vis):\n",
          "    ax.plot([source_samples[i, 0], target_samples[i, 0]],\n",
          "             [source_samples[i, 1], target_samples[i, 1]],\n",
          "             'k-', alpha=0.3)\n",
          "    \n",
          "ax.set_title('Matching Pairs for Flow Learning')\n",
          "ax.set_xlim(-4, 4)\n",
          "ax.set_ylim(-4, 4)\n",
          "ax.grid(True)\n",
          "ax.legend()\n",
          "ax.set_aspect('equal')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "### 3.2 Simple Flow Matching Model\n",
          "\n",
          "Now, let's implement a simple flow matching model for this 2D problem."
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "class SimpleFlowModel(nn.Module):\n",
          "    def __init__(self, hidden_dim=64):\n",
          "        super().__init__()\n",
          "        \n",
          "        # Network architecture\n",
          "        self.net = nn.Sequential(\n",
          "            # Input: x and t (2+1=3 dimensions)\n",
          "            nn.Linear(2 + 1, hidden_dim),\n",
          "            nn.SiLU(),  # Smooth activation function\n",
          "            nn.Linear(hidden_dim, hidden_dim),\n",
          "            nn.SiLU(),\n",
          "            nn.Linear(hidden_dim, hidden_dim),\n",
          "            nn.SiLU(),\n",
          "            # Output: velocity vector (2 dimensions)\n",
          "            nn.Linear(hidden_dim, 2)\n",
          "        )\n",
          "    \n",
          "    def forward(self, x, t):\n",
          "        \"\"\"Compute velocity at point x and time t.\"\"\"\n",
          "        # Concatenate x and t\n",
          "        if t.dim() == 1:\n",
          "            # Add channel dimension to t\n",
          "            t = t.unsqueeze(1)\n",
          "        \n",
          "        xt = torch.cat([x, t], dim=1)\n",
          "        \n",
          "        # Compute velocity\n",
          "        velocity = self.net(xt)\n",
          "        return velocity\n",
          "    \n",
          "    def compute_flow_loss(self, x0, x1, t):\n",
          "        \"\"\"Compute flow matching loss.\"\"\"\n",
          "        # Compute straight-line velocity target\n",
          "        v_target = x1 - x0  # For t in [0, 1], velocity = displacement\n",
          "        \n",
          "        # Interpolate between x0 and x1 at time t\n",
          "        x_t = x0 + t.unsqueeze(1) * (x1 - x0)\n",
          "        \n",
          "        # Predict velocity\n",
          "        v_pred = self(x_t, t)\n",
          "        \n",
          "        # Compute MSE loss\n",
          "        loss = F.mse_loss(v_pred, v_target)\n",
          "        return loss"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Instantiate model\n",
          "model = SimpleFlowModel(hidden_dim=64).to(device)\n",
          "\n",
          "# Set up optimizer\n",
          "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
          "\n",
          "# Training loop\n",
          "n_epochs = 50\n",
          "losses = []\n",
          "\n",
          "for epoch in tqdm(range(n_epochs)):\n",
          "    epoch_loss = 0\n",
          "    \n",
          "    for x0, x1 in dataloader:\n",
          "        x0, x1 = x0.to(device), x1.to(device)\n",
          "        \n",
          "        # Generate random times between 0 and 1\n",
          "        t = torch.rand(x0.size(0), device=device)\n",
          "        \n",
          "        # Compute loss\n",
          "        loss = model.compute_flow_loss(x0, x1, t)\n",
          "        \n",
          "        # Backward pass and optimize\n",
          "        optimizer.zero_grad()\n",
          "        loss.backward()\n",
          "        optimizer.step()\n",
          "        \n",
          "        epoch_loss += loss.item() * x0.size(0)\n",
          "    \n",
          "    # Average loss for the epoch\n",
          "    epoch_loss /= len(dataset)\n",
          "    losses.append(epoch_loss)\n",
          "    \n",
          "    # Print progress\n",
          "    if (epoch + 1) % 10 == 0:\n",
          "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")\n",
          "\n",
          "# Plot training loss\n",
          "plt.figure(figsize=(10, 6))\n",
          "plt.plot(losses)\n",
          "plt.xlabel('Epoch')\n",
          "plt.ylabel('Loss')\n",
          "plt.title('Training Loss')\n",
          "plt.grid(True)\n",
          "plt.yscale('log')\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "### 3.3 Visualize Learned Flow Field\n",
          "\n",
          "Now let's visualize the flow field that our model has learned."
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Create a grid of points\n",
          "grid_size = 20\n",
          "x = np.linspace(-4, 4, grid_size)\n",
          "y = np.linspace(-4, 4, grid_size)\n",
          "X, Y = np.meshgrid(x, y)\n",
          "\n",
          "# Put model in evaluation mode\n",
          "model.eval()\n",
          "\n",
          "# Visualize flow field at different time steps\n",
          "time_steps = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
          "fig, axes = plt.subplots(1, len(time_steps), figsize=(20, 4))\n",
          "\n",
          "with torch.no_grad():\n",
          "    for i, t_val in enumerate(time_steps):\n",
          "        # Prepare grid points\n",
          "        grid_points = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
          "        grid_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)\n",
          "        t = torch.ones(grid_points.shape[0], device=device) * t_val\n",
          "        \n",
          "        # Compute velocities\n",
          "        velocities = model(grid_tensor, t).cpu().numpy()\n",
          "        \n",
          "        # Reshape for plotting\n",
          "        U = velocities[:, 0].reshape(grid_size, grid_size)\n",
          "        V = velocities[:, 1].reshape(grid_size, grid_size)\n",
          "        \n",
          "        # Calculate velocity magnitude for coloring\n",
          "        speed = np.sqrt(U**2 + V**2)\n",
          "        \n",
          "        # Plot\n",
          "        axes[i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis',\n",
          "                          linewidth=1, arrowsize=1.5)\n",
          "        axes[i].set_title(f\"t = {t_val}\")\n",
          "        axes[i].set_xlim(-4, 4)\n",
          "        axes[i].set_ylim(-4, 4)\n",
          "        axes[i].grid(True)\n",
          "        axes[i].set_aspect('equal')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "### 3.4 Generate Trajectories using ODE Solver\n",
          "\n",
          "Now that we have a learned flow field, we can use an ODE solver to generate trajectories from the source to the target distribution."
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Import ODE solver\n",
          "from torchdiffeq import odeint\n",
          "\n",
          "# Create a function that returns the velocity at a given point and time\n",
          "def vector_field(t, x):\n",
          "    \"\"\"Vector field function for ODE solver.\"\"\"\n",
          "    model.eval()\n",
          "    with torch.no_grad():\n",
          "        return model(x, t)\n",
          "\n",
          "# Choose initial points from the source distribution\n",
          "n_trajectories = 10\n",
          "initial_points = source_tensor[:n_trajectories].to(device)\n",
          "\n",
          "# Define time span\n",
          "time_span = torch.linspace(0, 1, 100).to(device)\n",
          "\n",
          "# Solve ODE\n",
          "trajectories = odeint(vector_field, initial_points, time_span, method='dopri5')\n",
          "\n",
          "# Move trajectories to CPU and convert to numpy\n",
          "trajectories = trajectories.cpu().numpy()\n",
          "\n",
          "# Plot the trajectories\n",
          "fig, ax = plt.subplots(figsize=(8, 8))\n",
          "\n",
          "# Plot all source and target samples\n",
          "ax.scatter(source_samples[:, 0], source_samples[:, 1], alpha=0.2, s=10, color='blue', label='Source')\n",
          "ax.scatter(target_samples[:, 0], target_samples[:, 1], alpha=0.2, s=10, color='red', label='Target')\n",
          "\n",
          "# Plot the trajectories\n",
          "for i in range(n_trajectories):\n",
          "    ax.plot(trajectories[:, i, 0], trajectories[:, i, 1], alpha=0.7, linewidth=1)\n",
          "\n",
          "ax.set_title('Generated Trajectories')\n",
          "ax.set_xlim(-4, 4)\n",
          "ax.set_ylim(-4, 4)\n",
          "ax.grid(True)\n",
          "ax.legend()\n",
          "ax.set_aspect('equal')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## 4. Extending to Weather-Like Data\n",
          "\n",
          "Now let's move beyond toy problems and extend our approach to more weather-like data. To make the connection to real weather data, we will:\n",
          "\n",
          "1. Generate synthetic weather-like data\n",
          "2. Train a flow matching model on this data\n",
          "3. Visualize the learned flow field\n",
          "\n",
          "Let's create the synthetic data:"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Generate synthetic weather-like data\n",
          "def sample_weather(n_samples, base_flow=2.0, perturbation_std=0.5):\n",
          "    \"\"\"Generate synthetic weather-like data with a base flow and perturbations.\"\"\"\n",
          "    # Base flow (e.g., jet stream)\n",
          "    base_flow_x = np.ones(n_samples) * base_flow\n",
          "    base_flow_y = np.zeros(n_samples)\n",
          "    base_flow = np.stack([base_flow_x, base_flow_y], axis=1)\n",
          "    \n",
          "    # Perturbations (e.g., storms)\n",
          "    perturbations = np.random.normal(0, perturbation_std, size=(n_samples, 2))\n",
          "    \n",
          "    # Combine base flow and perturbations\n",
          "    weather_data = base_flow + perturbations\n",
          "    return weather_data\n",
          "\n",
          "# Generate training data\n",
          "n_samples = 1000\n",
          "weather_source = sample_weather(n_samples)\n",
          "weather_target = sample_weather(n_samples, base_flow=1.0, perturbation_std=0.75)\n",
          "\n",
          "# Convert to tensors\n",
          "weather_source_tensor = torch.tensor(weather_source, dtype=torch.float32)\n",
          "weather_target_tensor = torch.tensor(weather_target, dtype=torch.float32)\n",
          "\n",
          "# Create dataset and dataloader\n",
          "weather_dataset = TensorDataset(weather_source_tensor, weather_target_tensor)\n",
          "weather_dataloader = DataLoader(weather_dataset, batch_size=64, shuffle=True)\n",
          "\n",
          "# Plot the synthetic weather data\n",
          "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
          "\n",
          "# Plot source distribution\n",
          "axes[0].scatter(weather_source[:, 0], weather_source[:, 1], alpha=0.5, s=10)\n",
          "axes[0].set_title('Source Weather Data')\n",
          "axes[0].set_xlim(-4, 4)\n",
          "axes[0].set_ylim(-4, 4)\n",
          "axes[0].grid(True)\n",
          "axes[0].set_aspect('equal')\n",
          "\n",
          "# Plot target distribution\n",
          "axes[1].scatter(weather_target[:, 0], weather_target[:, 1], alpha=0.5, s=10)\n",
          "axes[1].set_title('Target Weather Data')\n",
          "axes[1].set_xlim(-4, 4)\n",
          "axes[1].set_ylim(-4, 4)\n",
          "axes[1].grid(True)\n",
          "axes[1].set_aspect('equal')\n",
          "\n",
          "plt.tight_layout()\n",
          "plt.show()"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "Now that we have the data, lets train a flow matching model:"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Train the flow matching model\n",
          "weather_model = SimpleFlowModel(hidden_dim=64).to(device)\n",
          "weather_optimizer = torch.optim.Adam(weather_model.parameters(), lr=1e-3)\n",
          "\n",
          "# Training loop\n",
          "n_epochs = 50\n",
          "weather_losses = []\n",
          "\n",
          "for epoch in tqdm(range(n_epochs)):\n",
          "    epoch_loss = 0\n",
          "    \n",
          "    for x0, x1 in weather_dataloader:\n",
          "        x0, x1 = x0.to(device), x1.to(device)\n",
          "        \n",
          "        # Generate random times between 0 and 1\n",
          "        t = torch.rand(x0.size(0), device=device)\n",
          "        \n",
          "        # Compute loss\n",
          "        loss = weather_model.compute_flow_loss(x0, x1, t)\n",
          "        \n",
          "        # Backward pass and optimize\n",
          "        weather_optimizer.zero_grad()\n",
          "        loss.backward()\n",
          "        weather_optimizer.step()\n",
          "        \n",
          "        epoch_loss += loss.item() * x0.size(0)\n",
          "    \n",
          "    # Average loss for the epoch\n",
          "    epoch_loss /= len(weather_dataset)\n",
          "    weather_losses.append(epoch_loss)\n",
          "    \n",
          "    # Print progress\n",
          "    if (epoch + 1) % 10 == 0:\n",
          "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")"
        ]
      },
      {
        "cell_type": "markdown",
        "metadata": {},
        "source": [
          "## 5. Visualizing the learned flow field"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Set up the visualization\n",
          "# Visualize learned flow field\n",
          "weather_model.eval()\n",
          "\n",
          "# Define a function to create the plot flow field"
        ]
      },
      {
        "cell_type": "code",
        "execution_count": null,
        "metadata": {},
        "outputs": [],
        "source": [
          "# Visualize flow field for the weather-like data\n",
          "def plot_weather_flow_field(model, time_val, grid_size=32):\n",
          "    \"\"\"Plot the weather flow field at a specific time.\"\"\"\n",
          "    # Create grid for visualization\n",
          "    x = np.linspace(-4, 4, grid_size)\n",
          "    y = np.linspace(-4, 4, grid_size)\n",
          "    X, Y = np.meshgrid(x, y)\n",
          "    grid_points = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
          "    \n",
          "    # Convert to tensor\n",
          "    grid_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)\n",
          "    \n",
          "    # Create time tensor\n",
          "    t = torch.ones(grid_points.shape[0], device=device) * time_val\n",
          "    \n",
          "    # Get flow field\n",
          "    with torch.no_grad():\n",
          "        velocities = model(grid_tensor, t).cpu().numpy()\n",
          "    \n",
          "    # Reshape for plotting\n",
          "    U = velocities[:, 0].reshape(grid_size, grid_size)\n",
          "    V = velocities[:, 1].reshape(grid_size, grid_size)\n",
          "    \n",
          "    # Plot flow field with streamline\n",
          "    plt.streamplot(X, Y, U, V, color='k')\n",
          "    plt.xlabel('X')\n",
          "    plt.ylabel('Y')\n",
          "    plt.title('Learned Flow Field at t=' + str(time_val))\n",
          "    plt.show()\n",
          "\n",
          "# Test the visualization plot\n",
          "# Plot flow fields at different time steps\n",
          "time_steps = [0.0, 0.25, 0.5, 0.75, 1.0]\n",
          "fig, axes = plt.subplots(1, len(time_steps), figsize=(20, 4))\n",
          "\n",
          "for i, t_val in enumerate(time_steps):\n",
          "    \n",
          "    # Prepare grid points\n",
          "    grid_size = 20\n",
          "    x = np.linspace(-4, 4, grid_size)\n",
          "    y = np.linspace(-4, 4, grid_size)\n",
          "    X, Y = np.meshgrid(x, y)\n",
          "    \n",
          "    with torch.no_grad():\n",
          "        # Prepare grid points\n",
          "        grid_points = np.stack([X.flatten(), Y.flatten()], axis=1)\n",
                  "        grid_tensor = torch.tensor(grid_points, dtype=torch.float32).to(device)\n",
        "        t = torch.ones(grid_points.shape[0], device=device) * t_val\n",
        "\n",
        "        # Compute velocities\n",
        "        velocities = weather_model(grid_tensor, t).cpu().numpy()\n",
        "\n",
        "        # Reshape for plotting\n",
        "        U = velocities[:, 0].reshape(grid_size, grid_size)\n",
        "        V = velocities[:, 1].reshape(grid_size, grid_size)\n",
        "\n",
        "        # Calculate velocity magnitude for coloring\n",
        "        speed = np.sqrt(U**2 + V**2)\n",
        "\n",
        "        # Plot\n",
        "        axes[i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis',\n",
        "                          linewidth=1, arrowsize=1.5)\n",
        "        axes[i].set_title(f\"t = {t_val}\")\n",
        "        axes[i].set_xlim(-4, 4)\n",
        "        axes[i].set_ylim(-4, 4)\n",
        "        axes[i].grid(True)\n",
        "        axes[i].set_aspect('equal')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. Physics-Constrained Flow Matching\n",
        "\n",
        "# Now let's incorporate physics constraints into our flow model\n",
        "class PhysicsConstrainedFlow(nn.Module):\n",
        "    def __init__(self, hidden_dim=64):\n",
        "        super().__init__()\n",
        "\n",
        "        # Same network architecture as before\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(2 + 1, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_dim, 2)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        \"\"\"Compute velocity at point x and time t with physics constraints.\"\"\"\n",
        "        # Concatenate x and t\n",
        "        if t.dim() == 1:\n",
        "            t = t.unsqueeze(1)\n",
        "\n",
        "        xt = torch.cat([x, t], dim=1)\n",
        "\n",
        "        # Compute raw velocity\n",
        "        v_raw = self.net(xt)\n",
        "\n",
        "        # Apply physics constraints\n",
        "        v_constrained = self._apply_divergence_free_constraint(v_raw, x)\n",
        "\n",
        "        return v_constrained\n",
        "\n",
        "    def _apply_divergence_free_constraint(self, v, x):\n",
        "        \"\"\"Apply divergence-free constraint to make the flow incompressible.\n",
        "\n",
        "        For weather, this relates to conservation of mass.\n",
        "        \"\"\"\n",
        "        # Simplified implementation for 2D case\n",
        "        # In a real implementation, we would compute the curl of a potential function\n",
        "\n",
        "        # For now, just normalize the vectors to demonstrate the concept\n",
        "        v_norm = torch.norm(v, dim=1, keepdim=True)\n",
        "        v_normalized = v / (v_norm + 1e-8)\n",
        "\n",
        "        # Return normalized vectors (simplified physics constraint)\n",
        "        return v_normalized * v_norm\n",
        "\n",
        "    def compute_flow_loss(self, x0, x1, t):\n",
        "        \"\"\"Compute flow matching loss with physics regularization.\"\"\"\n",
        "        # Compute straight-line velocity target\n",
        "        v_target = x1 - x0\n",
        "\n",
        "        # Interpolate between x0 and x1 at time t\n",
        "        x_t = x0 + t.unsqueeze(1) * (x1 - x0)\n",
        "\n",
        "        # Predict velocity\n",
        "        v_pred = self(x_t, t)\n",
        "\n",
        "        # Compute MSE loss\n",
        "        flow_loss = F.mse_loss(v_pred, v_target)\n",
        "\n",
        "        # Add physics-based regularization\n",
        "        physics_loss = self._compute_physics_loss(v_pred, x_t)\n",
        "\n",
        "        # Total loss\n",
        "        total_loss = flow_loss + 0.1 * physics_loss\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def _compute_physics_loss(self, v, x):\n",
        "        \"\"\"Compute physics-based regularization loss.\n",
        "\n",
        "        For weather, this would include terms for:\n",
        "        - Divergence-free (continuity equation)\n",
        "        - Energy conservation\n",
        "        - Geostrophic balance\n",
        "        etc.\n",
        "        \"\"\"\n",
        "        # Simple physics loss: encourage smoothness of the vector field\n",
        "        # In a real implementation, we would have more sophisticated terms\n",
        "\n",
        "        # Calculate magnitude (for demonstration)\n",
        "        v_norm = torch.norm(v, dim=1)\n",
        "\n",
        "        # Penalize very large velocities (simplified energy constraint)\n",
        "        energy_penalty = torch.mean((v_norm - 1.0)**2)\n",
        "\n",
        "        return energy_penalty\n",
        "\n",
        "# Train the physics-constrained model\n",
        "physics_model = PhysicsConstrainedFlow(hidden_dim=64).to(device)\n",
        "physics_optimizer = torch.optim.Adam(physics_model.parameters(), lr=1e-3)\n",
        "\n",
        "# Training loop\n",
        "n_epochs = 50\n",
        "physics_losses = []\n",
        "\n",
        "for epoch in tqdm(range(n_epochs)):\n",
        "    epoch_loss = 0\n",
        "\n",
        "    for x0, x1 in weather_dataloader:\n",
        "        x0, x1 = x0.to(device), x1.to(device)\n",
        "\n",
        "        # Generate random times between 0 and 1\n",
        "        t = torch.rand(x0.size(0), device=device)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = physics_model.compute_flow_loss(x0, x1, t)\n",
        "\n",
        "        # Backward pass and optimize\n",
        "        physics_optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        physics_optimizer.step()\n",
        "\n",
        "        epoch_loss += loss.item() * x0.size(0)\n",
        "\n",
        "    # Average loss for the epoch\n",
        "    epoch_loss /= len(weather_dataset)\n",
        "    physics_losses.append(epoch_loss)\n",
        "\n",
        "    # Print progress\n",
        "    if (epoch + 1) % 10 == 0:\n",
        "        print(f\"Epoch {epoch+1}/{n_epochs}, Loss: {epoch_loss:.6f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare flow fields from standard and physics-constrained models\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# Time points to visualize\n",
        "vis_times = [0.0, 0.5, 1.0]\n",
        "\n",
        "for i, t_val in enumerate(vis_times):\n",
        "    # Standard model\n",
        "    X, Y, U, V = plot_weather_flow_field(weather_model, t_val)\n",
        "    speed = np.sqrt(U**2 + V**2)\n",
        "\n",
        "    axes[0, i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis')\n",
        "    axes[0, i].set_title(f\"Standard Model, t = {t_val}\")\n",
        "    axes[0, i].set_aspect('equal')\n",
        "    axes[0, i].grid(True)\n",
        "\n",
        "    # Physics-constrained model\n",
        "    X, Y, U, V = plot_weather_flow_field(physics_model, t_val)\n",
        "    speed = np.sqrt(U**2 + V**2)\n",
        "\n",
        "    axes[1, i].streamplot(X, Y, U, V, density=1.5, color=speed, cmap='viridis')\n",
        "    axes[1, i].set_title('title')\n",
        "    axes[1, i].set_aspect('equal')\n",
        "    axes[1, i].grid(True)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Connection to the WeatherFlow Library\n",
        "\n",
        "print(\"\"\"\n",
        "## WeatherFlow Library Implementation\n",
        "\n",
        "The WeatherFlow library implements these concepts at scale for real weather data:\n",
        "\n",
        "1. **WeatherFlowMatch Model**: Neural network for learning weather flow fields\n",
        "   - Convolutional architecture for spatial structure\n",
        "   - Time embedding for temporal dynamics\n",
        "   - Physics-informed constraints for physical consistency\n",
        "\n",
        "2. **ODE Integration**: Uses torchdiffeq for generating predictions\n",
        "   - WeatherFlowODE class wraps the flow model with an ODE solver\n",
        "   - Flexible solver methods (Runge-Kutta, Dopri5, etc.)\n",
        "   - Adjustable tolerances for accuracy vs. speed trade-offs\n",
        "\n",
        "3. **Spherical Geometry**: Accounts for Earth's spherical surface\n",
        "   - Proper handling of coordinate systems\n",
        "   - Accounting for convergence of meridians\n",
        "   - Managing periodic boundary conditions\n",
        "\n",
        "4. **Physics Constraints**: Incorporates atmospheric physics\n",
        "   - Conservation of mass (divergence-free)\n",
        "   - Energy conservation\n",
        "   - Geostrophic balance\n",
        "   - Coriolis effects\n",
        "\n",
        "In the next notebooks, we'll apply these concepts to real ERA5 weather data.\n",
        "\"\"\")\n",
        "\n",
        "# Show an example of using the WeatherFlow library for a simple case\n",
        "from weatherflow.models import WeatherFlowMatch\n",
        "\n",
        "# Create a toy example input (batch_size=1, channels=2, height=16, width=32)\n",
        "toy_input = torch.randn(1, 2, 16, 32).to(device)\n",
        "time_points = torch.tensor([0.5]).to(device)\n",
        "\n",
        "# Create model\n",
        "model = WeatherFlowMatch(\n",
        "    input_channels=2,\n",
        "    hidden_dim=64,\n",
        "    n_layers=3,\n",
        "    physics_informed=True\n",
        ").to(device)\n",
        "\n",
        "# Forward pass\n",
        "with torch.no_grad():\n",
        "    velocity = model(toy_input, time_points)\n",
        "    print(f'Input shape: {toy_input.shape}')\n",
        "    print(f'Output velocity shape: {velocity.shape}')\n",
        "    print(f'Velocity statistics: min={velocity.min().item():.4f}, max={velocity.max().item():.4f}, mean={velocity.mean().item():.4f}')\n",
        "\n",
        "print(\"\"\"\n",
        "## Conclusion\n",
        "\n",
        "In this notebook, we've explored the fundamentals of flow matching and how it applies to weather prediction:\n",
        "\n",
        "1. We implemented a simple flow matching model for 2D distributions\n",
        "2. We visualized flow fields and generated trajectories\n",
        "3. We extended the approach to weather-like data\n",
        "4. We incorporated physics constraints for more realistic flows\n",
        "5. We connected these concepts to the WeatherFlow library\n",
        "\n",
        "In the next notebook, we'll train a full WeatherFlowMatch model on real ERA5 data and evaluate its predictive performance.\n",
        "\"\"\")\n"
      ]
    }
  ]
}