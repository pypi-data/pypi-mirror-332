Metadata-Version: 2.2
Name: simpleaihelper
Version: 0.1.0
Summary: A high-performance wrapper for OpenAI API
Home-page: https://github.com/aixiasang/simpleaihelper
Author: AI Kit Developer
Author-email: aixiasang@163.com
Classifier: Programming Language :: Python :: 3
Classifier: License :: OSI Approved :: MIT License
Classifier: Operating System :: OS Independent
Requires-Python: >=3.7
Description-Content-Type: text/markdown
Requires-Dist: openai>=1.0.0
Dynamic: author
Dynamic: author-email
Dynamic: classifier
Dynamic: description
Dynamic: description-content-type
Dynamic: home-page
Dynamic: requires-dist
Dynamic: requires-python
Dynamic: summary

# SimpleAIHelper

ç®€å•è€Œå¼ºå¤§çš„AIæ¥å£åŠ©æ‰‹ï¼Œè®©ä¸å¤§è¯­è¨€æ¨¡å‹çš„äº¤äº’å˜å¾—ä¼˜é›…ç®€æ´ã€‚

## ğŸ“š ç®€ä»‹

SimpleAIHelper æ˜¯ä¸€ä¸ªè½»é‡çº§PythonåŒ…ï¼Œè®¾è®¡ç”¨äºç®€åŒ–ä¸å„ç§å¤§è¯­è¨€æ¨¡å‹APIçš„äº¤äº’è¿‡ç¨‹ã€‚å®ƒæä¾›äº†ç»Ÿä¸€ã€ä¼˜é›…çš„æ¥å£ï¼Œæ”¯æŒå¤šç§æ¨¡å‹æœåŠ¡ï¼ŒåŒ…æ‹¬OpenAIå®˜æ–¹APIã€ç™¾ç‚¼(QwQ)ã€è±†åŒ…æ¨¡å‹ã€ç¡…è°·æ¨¡å‹ç­‰å…¼å®¹OpenAIæ¥å£çš„æœåŠ¡ã€‚

**é‡è¦è¯´æ˜**ï¼šSimpleAIHelperå®Œå…¨å…¼å®¹OpenAIçš„PythonåŒ…ï¼ˆ`openai`ï¼‰ï¼Œä½¿ç”¨ç›¸åŒçš„åº•å±‚APIç»“æ„ï¼Œä½†æä¾›äº†æ›´ç®€æ´ã€æ›´å¼ºå¤§çš„æ¥å£ã€‚æ‚¨æ— éœ€å­¦ä¹ æ–°çš„APIç»“æ„ï¼Œåªéœ€è¦æŒæ¡æ›´ç®€å•çš„è°ƒç”¨æ–¹å¼ã€‚

### ğŸŒŸ ä¸»è¦ç‰¹ç‚¹

- **ç®€æ´ä¼˜é›…çš„API**ï¼šä½¿ç”¨æœ€å°‘çš„ä»£ç å®ç°å¼ºå¤§åŠŸèƒ½
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šé€‚é…å¤šç§AIæœåŠ¡æä¾›å•†
- **æµå¼è¾“å‡º**ï¼šæ”¯æŒå®æ—¶ã€æµç•…çš„å“åº”æ˜¾ç¤º
- **æ€è€ƒè¿‡ç¨‹åˆ†ç¦»**ï¼šç‹¬ç‰¹çš„æ€è€ƒè¿‡ç¨‹å’Œæœ€ç»ˆç­”æ¡ˆåˆ†ç¦»åŠŸèƒ½
- **ä¼šè¯ç®¡ç†**ï¼šçµæ´»çš„å¯¹è¯å†å²ä¿å­˜å’Œæ¢å¤
- **JSONè¾“å‡º**ï¼šæ”¯æŒç»“æ„åŒ–æ•°æ®è¿”å›
- **å®Œå…¨å…¼å®¹OpenAI**ï¼šåŸºäºå®˜æ–¹openaiåŒ…æ„å»ºï¼Œæ”¯æŒæ‰€æœ‰OpenAIå‚æ•°

## ğŸ”§ å®‰è£…

ä½¿ç”¨pipå®‰è£…æœ€æ–°ç‰ˆæœ¬ï¼š

```bash
pip install simpleaihelper
```

**ä¾èµ–è¯´æ˜**ï¼šSimpleAIHelperä¾èµ–äº`openai`åŒ…ï¼Œå®‰è£…æ—¶ä¼šè‡ªåŠ¨å®‰è£…æ­¤ä¾èµ–ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### åŸºæœ¬ä½¿ç”¨

```python
from simpleaihelper import AI
import os

# åˆå§‹åŒ–å®¢æˆ·ç«¯
api_key = os.environ.get("OPENAI_API_KEY")
client = AI(api_key=api_key)

# ç®€å•é—®ç­”
response = client.ask("Pythonä¸­å¦‚ä½•å®ç°å¤šçº¿ç¨‹ç¼–ç¨‹ï¼Ÿ")
print(response)

# æµå¼è¾“å‡º
for chunk in client.stream_ask("è§£é‡Šä¸€ä¸‹é‡å­è®¡ç®—çš„åŸºæœ¬åŸç†"):
    print(chunk, end="", flush=True)
```

### æ€è€ƒè¿‡ç¨‹åˆ†ç¦»

```python
# è·å–å¸¦æ€è€ƒè¿‡ç¨‹çš„å›ç­”
result = client.think("å¦‚ä½•è®¾è®¡ä¸€ä¸ªé«˜æ€§èƒ½çš„åˆ†å¸ƒå¼ç³»ç»Ÿï¼Ÿ")
print(f"æ€è€ƒè¿‡ç¨‹:\n{result['reasoning']}")
print(f"æœ€ç»ˆç­”æ¡ˆ:\n{result['answer']}")

# ä¼˜é›…çš„æ€è€ƒè¿‡ç¨‹API
result = client.thinking_display("ä»€ä¹ˆæ˜¯CAPå®šç†ï¼Ÿ")
print(f"æ€è€ƒ: {result['reasoning'][:100]}...")
print(f"ç­”æ¡ˆ: {result['answer'][:100]}...")
```

### ä½¿ç”¨ä¼šè¯

```python
# åˆ›å»ºä¼šè¯
session = client.session(system_prompt="ä½ æ˜¯ä¸€ä½è®¡ç®—æœºç§‘å­¦æ•™æˆ")

# è¿›è¡Œå¤šè½®å¯¹è¯
response1 = session.ask("ä»€ä¹ˆæ˜¯è®¾è®¡æ¨¡å¼ï¼Ÿ")
print(response1)

response2 = session.ask("è¯·è¯¦ç»†ä»‹ç»ä¸€ä¸‹å•ä¾‹æ¨¡å¼")  # ä¿æŒä¸Šä¸‹æ–‡
print(response2)

# æµå¼æ€è€ƒ
for chunk in session.stream_think("å·¥å‚æ¨¡å¼å’Œç­–ç•¥æ¨¡å¼æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ"):
    if chunk["type"] == "reasoning":
        print(f"[æ€è€ƒ] {chunk['content']}", end="", flush=True)
    elif chunk["type"] == "answer":
        print(f"[å›ç­”] {chunk['content']}", end="", flush=True)
```

### ä¿å­˜å’Œæ¢å¤ä¼šè¯

```python
# ä¿å­˜ä¼šè¯åˆ°SQLiteæ•°æ®åº“
db = client.load_db("conversations.db")
db.save_session(session)

# æŸ¥çœ‹ä¿å­˜çš„ä¼šè¯
sessions = db.view_sessions()
for s in sessions:
    print(f"ä¼šè¯ID: {s['session_id']}, æ¶ˆæ¯æ•°: {s['message_count']}")

# åŠ è½½å·²æœ‰ä¼šè¯
loaded_session = db.load_session(sessions[0]['session_id'])

# ä½¿ç”¨JSONæ ¼å¼ä¿å­˜
js = client.load_json("conversations.json")
js.save_session(session)
```

## ğŸ“˜ æ ¸å¿ƒåŠŸèƒ½è¯¦è§£

### 1. å®¢æˆ·ç«¯åˆå§‹åŒ–

```python
client = AI(
    api_key="your_api_key",
    base_url="https://api.example.com/v1",  # å¯é€‰ï¼Œæ”¯æŒè‡ªå®šä¹‰APIç«¯ç‚¹
    default_model="gpt-3.5-turbo",  # å¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨çš„æ¨¡å‹
    # å…¶ä»–å¯é€‰å‚æ•°
)
```

**åˆå§‹åŒ–å‚æ•°å®Œå…¨å…¼å®¹OpenAI**ï¼š

| å‚æ•° | æè¿° | é»˜è®¤å€¼ |
|-----|------|-------|
| `api_key` | APIå¯†é’¥ï¼Œç”¨äºè®¤è¯ | å¿…å¡« |
| `base_url` | APIåŸºç¡€URLï¼Œç”¨äºéOpenAIæœåŠ¡ | `"https://api.openai.com/v1"` |
| `default_model` | é»˜è®¤ä½¿ç”¨çš„æ¨¡å‹åç§° | `"gpt-3.5-turbo"` |
| `timeout` | è¯·æ±‚è¶…æ—¶æ—¶é—´(ç§’) | OpenAIé»˜è®¤ |
| `max_retries` | æœ€å¤§é‡è¯•æ¬¡æ•° | OpenAIé»˜è®¤ |
| `organization` | ç»„ç»‡ID(OpenAIå¤šç»„ç»‡ç”¨æˆ·) | æ—  |
| `api_version` | APIç‰ˆæœ¬ | æ—  |
| `http_client` | è‡ªå®šä¹‰HTTPå®¢æˆ·ç«¯ | æ—  |

æ”¯æŒçš„æœåŠ¡ç¤ºä¾‹ï¼š

```python
# OpenAIå®˜æ–¹
client = AI(api_key=os.environ.get("OPENAI_API_KEY"))

# ç™¾ç‚¼(QwQ)
client = AI(
    api_key=os.environ.get("DASHSCOPE_API_KEY"),
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    default_model="qwq-32b"
)

# è±†åŒ…
client = AI(
    api_key=os.environ.get("DOUBAO_API_KEY"),
    base_url="https://ark.cn-beijing.volces.com/api/v3",
    default_model="doubao-lite-128k-240828"
)

# ç¡…è°·
client = AI(
    api_key=os.environ.get("SILICON_API_KEY"), 
    base_url="https://api.siliconflow.cn/v1",
    default_model="deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
)
```

### 2. åŸºæœ¬API

æ‰€æœ‰APIéƒ½æ”¯æŒä¼ é€’é¢å¤–å‚æ•°åˆ°åº•å±‚æ¨¡å‹ï¼š

```python
# åŸºæœ¬é—®ç­”
response = client.ask(
    prompt="å†™ä¸€é¦–å…³äºAIçš„è¯—",
    messages=None,  # å¯é€‰ï¼Œå†å²æ¶ˆæ¯
    model="gpt-4",  # è¦†ç›–é»˜è®¤æ¨¡å‹
    temperature=0.7,  # æ§åˆ¶åˆ›é€ æ€§
    # æ”¯æŒå…¶ä»–OpenAIå…¼å®¹å‚æ•°
)

# æµå¼å“åº”
for chunk in client.stream_ask(
    prompt="ä»‹ç»ä¸€ä¸‹Pythonçš„å¼‚æ­¥ç¼–ç¨‹",
    temperature=0.5
):
    print(chunk, end="", flush=True)

# ç»“æ„åŒ–JSONå“åº”
json_response = client.ask_json(
    prompt="åˆ—å‡º5ç§ç¼–ç¨‹è¯­è¨€åŠå…¶ç‰¹ç‚¹",
    model="gpt-3.5-turbo-1106"
)
```

## âš™ï¸ æ”¯æŒçš„OpenAIå‚æ•°

SimpleAIHelperçš„æ‰€æœ‰æ–¹æ³•ï¼ˆ`ask`, `stream_ask`, `think`, `stream_think`, `ask_json`ç­‰ï¼‰éƒ½æ”¯æŒä»¥ä¸‹OpenAIå…¼å®¹å‚æ•°ï¼š

| å‚æ•° | æè¿° | é»˜è®¤å€¼ |
|-----|------|-------|
| `model` | ä½¿ç”¨çš„æ¨¡å‹åç§° | å®¢æˆ·ç«¯åˆå§‹åŒ–æ—¶è®¾å®šçš„é»˜è®¤æ¨¡å‹ |
| `temperature` | æ¸©åº¦/éšæœºæ€§ (0-2) | `1.0` |
| `top_p` | æ ¸é‡‡æ ·é˜ˆå€¼ (0-1) | `1.0` |
| `n` | ç”Ÿæˆçš„å›ç­”æ•°é‡ | `1` |
| `max_tokens` | æœ€å¤§æ ‡è®°æ•° | æ— é™åˆ¶ |
| `presence_penalty` | å­˜åœ¨æƒ©ç½š (-2.0-2.0) | `0.0` |
| `frequency_penalty` | é¢‘ç‡æƒ©ç½š (-2.0-2.0) | `0.0` |
| `logit_bias` | æ ‡è®°çš„å¯¹æ•°å‡ ç‡åå·® | `{}` |
| `stop` | ç”Ÿæˆåœæ­¢åºåˆ— | æ—  |
| `user` | ç”¨æˆ·æ ‡è¯†ç¬¦ | æ—  |
| `response_format` | å“åº”æ ¼å¼ (å¦‚`{"type": "json_object"}`) | æ—  |
| `seed` | éšæœºæ•°ç§å­ | æ—  |
| `tools` | å¯ç”¨çš„å·¥å…·åˆ—è¡¨ | æ—  |
| `tool_choice` | å·¥å…·é€‰æ‹©è§„åˆ™ | æ—  |

**ä½¿ç”¨ç¤ºä¾‹**ï¼š

```python
# è®¾ç½®å¤šç§å‚æ•°ï¼Œé’ˆå¯¹åˆ›æ„å†™ä½œ
response = client.ask(
    prompt="åˆ›ä½œä¸€ä¸ªç§‘å¹»å°è¯´å¼€å¤´",
    model="gpt-4",
    temperature=0.8,  # è¾ƒé«˜çš„åˆ›é€ æ€§
    max_tokens=500,   # é™åˆ¶å›ç­”é•¿åº¦
    presence_penalty=0.5,  # é¼“åŠ±è¯é¢˜å¤šæ ·æ€§
    stop=["\n\n", "ç¬¬äºŒç« "]  # åœ¨è¿™äº›æ–‡æœ¬å‡ºç°æ—¶åœæ­¢ç”Ÿæˆ
)

# åœ¨æµå¼ä¼šè¯ä¸­ä½¿ç”¨å‚æ•°
for chunk in session.stream_ask(
    prompt="è§£é‡Šé‡å­çº ç¼ ",
    temperature=0.2,  # ä½æ¸©åº¦ï¼Œæ›´ç¡®å®šæ€§çš„å›ç­”
    top_p=0.8,        # æ›´èšç„¦çš„åˆ†å¸ƒ
    frequency_penalty=0.5  # å‡å°‘é‡å¤
):
    print(chunk, end="", flush=True)

# JSONè¾“å‡ºé…ç½®
structured_result = client.ask_json(
    prompt="åˆ—å‡º5ä¸ªä¸–ç•Œä¸Šæœ€é«˜çš„å»ºç­‘åŠå…¶é«˜åº¦",
    response_format={"type": "json_object"},  # å¼ºåˆ¶JSONæ ¼å¼
    temperature=0.1  # ä¿æŒç»“æœä¸€è‡´æ€§
)
```

### ğŸ”„ ä¼šè¯å‚æ•°ä¼ é€’

åœ¨ä¼šè¯ä¸­ï¼Œå¯ä»¥åœ¨åˆ›å»ºä¼šè¯æ—¶è®¾ç½®é»˜è®¤å‚æ•°ï¼Œä¹Ÿå¯ä»¥åœ¨æ¯æ¬¡è°ƒç”¨æ—¶è¦†ç›–è¿™äº›å‚æ•°ï¼š

```python
# åˆ›å»ºä¼šè¯æ—¶è®¾ç½®é»˜è®¤å‚æ•°
session = client.session(
    system_prompt="ä½ æ˜¯ä¸€ä½ç§‘å­¦æ•™æˆ",
    model="gpt-4-turbo",
    temperature=0.3,
    max_tokens=1000
)

# ç¬¬ä¸€ä¸ªé—®é¢˜ä½¿ç”¨ä¼šè¯é»˜è®¤å‚æ•°
response1 = session.ask("ä»€ä¹ˆæ˜¯é»‘æ´ï¼Ÿ")

# ç¬¬äºŒä¸ªé—®é¢˜è¦†ç›–æŸäº›å‚æ•°
response2 = session.ask(
    "é»‘æ´ä¼šè’¸å‘å—ï¼Ÿ",
    temperature=0.7,  # è¦†ç›–ä¼šè¯é»˜è®¤å€¼0.3
    max_tokens=300    # è¦†ç›–ä¼šè¯é»˜è®¤å€¼1000
)
```

### 3. æ€è€ƒè¿‡ç¨‹åŠŸèƒ½

SimpleAIHelperæä¾›ç‹¬ç‰¹çš„æ€è€ƒè¿‡ç¨‹åˆ†ç¦»åŠŸèƒ½ï¼Œæ”¯æŒä¸¤ç§æ¨¡å¼ï¼š

1. **åŸç”Ÿæ€è€ƒè¿‡ç¨‹**ï¼šé’ˆå¯¹æ”¯æŒreasoning_contentçš„æ¨¡å‹(å¦‚QwQ)
2. **æ¨¡æ‹Ÿæ€è€ƒè¿‡ç¨‹**ï¼šä¸ºæ™®é€šæ¨¡å‹æ·»åŠ ç³»ç»Ÿæç¤ºï¼Œå¼•å¯¼æ¨¡å‹æ˜¾ç¤ºæ€è€ƒè¿‡ç¨‹

```python
# è·å–å®Œæ•´æ€è€ƒç»“æœ
result = client.think("å¦‚ä½•ä¼˜åŒ–æ•°æ®åº“æŸ¥è¯¢æ€§èƒ½ï¼Ÿ")
print(f"æ€è€ƒè¿‡ç¨‹: {result['reasoning']}")
print(f"æœ€ç»ˆç­”æ¡ˆ: {result['answer']}")

# æµå¼æ€è€ƒè¿‡ç¨‹
for chunk in client.stream_think("å¦‚ä½•å®ç°ä¸€ä¸ªåˆ†å¸ƒå¼é”ï¼Ÿ"):
    chunk_type = chunk["type"]  # "reasoning", "transition", "answer"
    content = chunk["content"]
    
    if chunk_type == "reasoning":
        print(f"[æ€è€ƒä¸­] {content}", end="", flush=True)
    elif chunk_type == "answer":
        print(f"[æœ€ç»ˆç­”æ¡ˆ] {content}", end="", flush=True)
```

### 4. ä¼šè¯ç®¡ç†

```python
# åˆ›å»ºä¼šè¯
session = client.session(
    system_prompt="ä½ æ˜¯ä¸€ä½ç»éªŒä¸°å¯Œçš„è½¯ä»¶æ¶æ„å¸ˆ",
    model="gpt-4",  # å¯é€‰ï¼Œä¼šè¯é»˜è®¤æ¨¡å‹
    # å…¶ä»–å¯é€‰å‚æ•°
)

# ä¼šè¯æ–¹æ³•
response = session.ask("ä»€ä¹ˆæ˜¯å¾®æœåŠ¡æ¶æ„ï¼Ÿ")
stream_response = session.stream_ask("å¾®æœåŠ¡æ¶æ„çš„ä¼˜ç¼ºç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ")
think_result = session.think("å¦‚ä½•è®¾è®¡å¾®æœåŠ¡ä¹‹é—´çš„é€šä¿¡ï¼Ÿ")
json_result = session.ask_json("åˆ—å‡º5ç§å¸¸è§çš„å¾®æœåŠ¡è®¾è®¡æ¨¡å¼")

# è·å–ä¼šè¯å†å²
history = session.get_history()
```

### 5. ä¼šè¯æŒä¹…åŒ–

#### SQLiteå­˜å‚¨

```python
# åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
db = client.load_db(
    db_path="conversations.db",  # æ•°æ®åº“æ–‡ä»¶è·¯å¾„
    table="ai_messages"  # å¯é€‰ï¼Œè¡¨å
)

# ä¿å­˜ä¼šè¯
db.save_session(session)

# æŸ¥çœ‹æ‰€æœ‰ä¼šè¯
sessions = db.view_sessions()

# æŸ¥çœ‹ç‰¹å®šä¼šè¯çš„æ¶ˆæ¯
messages = db.view_session_messages(session_id)

# åŠ è½½ä¼šè¯
loaded_session = db.load_session(
    session_id,
    update=False  # æ˜¯å¦åˆ›å»ºæ–°ä¼šè¯ID
)
```

#### JSONå­˜å‚¨

```python
# åˆå§‹åŒ–JSONç®¡ç†å™¨
js = client.load_json("conversations.json")

# ä¸SQLiteæ¥å£ç›¸åŒ
js.save_session(session)
sessions = js.view_sessions()
loaded_session = js.load_session(session_id)
```

## ğŸ§© é«˜çº§ç”¨æ³•

### 1. è‡ªå®šä¹‰æ¶ˆæ¯å†å²

```python
# å‡†å¤‡è‡ªå®šä¹‰æ¶ˆæ¯å†å²
messages = [
    {"role": "system", "content": "ä½ æ˜¯ä¸€ä½æ•°å­¦æ•™æˆ"},
    {"role": "user", "content": "ä»€ä¹ˆæ˜¯é»æ›¼çŒœæƒ³ï¼Ÿ"},
    {"role": "assistant", "content": "é»æ›¼çŒœæƒ³æ˜¯..."}
]

# åœ¨ç°æœ‰å†å²åŸºç¡€ä¸Šç»§ç»­å¯¹è¯
response = client.ask("è¿™ä¸ç´ æ•°åˆ†å¸ƒæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ", messages=messages)
```

### 2. æµå¼æ€è€ƒå¤„ç†

```python
# æ›´ç²¾ç»†çš„æµå¼æ€è€ƒå¤„ç†
reasoning_parts = []
answer_parts = []

for chunk in client.stream_think("å¦‚ä½•å®ç°ä¸€ä¸ªæ— é”é˜Ÿåˆ—ï¼Ÿ"):
    chunk_type = chunk["type"]
    content = chunk["content"]
    
    if chunk_type == "reasoning":
        reasoning_parts.append(content)
        print(content, end="", flush=True)
    elif chunk_type == "transition":
        print("\n--- æ€è€ƒç»“æŸï¼Œå¼€å§‹å›ç­” ---\n")
    elif chunk_type == "answer":
        answer_parts.append(content)
        print(content, end="", flush=True)

# è·å–å®Œæ•´å†…å®¹
full_reasoning = "".join(reasoning_parts)
full_answer = "".join(answer_parts)
```

## ğŸ“ APIå‚è€ƒ

### AI ç±»

åŸºæœ¬å®¢æˆ·ç«¯å®ä¾‹ï¼Œæä¾›ä¸AIæ¨¡å‹äº¤äº’çš„ä¸»è¦æ¥å£ã€‚

| æ–¹æ³•                | æè¿°                             | è¿”å›ç±»å‹              |
|--------------------|----------------------------------|---------------------|
| `__init__`         | åˆå§‹åŒ–å®¢æˆ·ç«¯                      | -                   |
| `ask`              | å‘é€è¯·æ±‚å¹¶è·å–æ™®é€šå“åº”             | str                 |
| `stream_ask`       | æµå¼è·å–å“åº”                      | Generator[str]      |
| `think`            | è·å–å¸¦æ€è€ƒè¿‡ç¨‹çš„å“åº”               | Dict[str, str]      |
| `stream_think`     | æµå¼è·å–æ€è€ƒè¿‡ç¨‹å’Œå›ç­”             | Generator[Dict]     |
| `thinking_display` | ä¼˜é›…è·å–æ€è€ƒè¿‡ç¨‹å’Œå›ç­”             | Dict[str, str]      |
| `ask_json`         | è·å–JSONæ ¼å¼å“åº”                  | Dict/List           |
| `session`          | åˆ›å»ºä¼šè¯å®ä¾‹                      | Session             |
| `load_db`          | åˆå§‹åŒ–SQLiteä¼šè¯ç®¡ç†              | SQLiteManager       |
| `load_json`        | åˆå§‹åŒ–JSONä¼šè¯ç®¡ç†                | JSONManager         |

### Session ç±»

ç®¡ç†å¤šè½®å¯¹è¯çš„ä¼šè¯å®ä¾‹ã€‚

| æ–¹æ³•                | æè¿°                             | è¿”å›ç±»å‹              |
|--------------------|----------------------------------|---------------------|
| `ask`              | åœ¨ä¼šè¯ä¸­å‘é€è¯·æ±‚                   | str                 |
| `stream_ask`       | ä¼šè¯ä¸­æµå¼è·å–å“åº”                 | Generator[str]      |
| `think`            | ä¼šè¯ä¸­è·å–å¸¦æ€è€ƒè¿‡ç¨‹çš„å“åº”          | Dict[str, str]      |
| `stream_think`     | ä¼šè¯ä¸­æµå¼è·å–æ€è€ƒè¿‡ç¨‹å’Œå›ç­”        | Generator[Dict]     |
| `thinking_display` | ä¼šè¯ä¸­ä¼˜é›…è·å–æ€è€ƒè¿‡ç¨‹å’Œå›ç­”        | Dict[str, str]      |
| `ask_json`         | ä¼šè¯ä¸­è·å–JSONæ ¼å¼å“åº”             | Dict/List           |
| `get_history`      | è·å–ä¼šè¯å†å²                      | List[Dict]          |
| `add_message`      | æ·»åŠ æ¶ˆæ¯åˆ°å†å²                    | -                   |

## âš™ï¸ é…ç½®é€‰é¡¹

æ‰€æœ‰æ–¹æ³•éƒ½æ”¯æŒä»¥ä¸‹é€šç”¨å‚æ•°ï¼š

- `model` - æŒ‡å®šè¦ä½¿ç”¨çš„æ¨¡å‹
- `temperature` - æ§åˆ¶ç»“æœçš„éšæœºæ€§ (0-2)
- `top_p` - æ§åˆ¶ç»“æœçš„å¤šæ ·æ€§
- `max_tokens` - é™åˆ¶å“åº”çš„æœ€å¤§é•¿åº¦
- æ”¯æŒæ‰€æœ‰OpenAI APIå…¼å®¹çš„å‚æ•°

## â“ å¸¸è§é—®é¢˜

**Q: å¦‚ä½•è®¾ç½®APIå¯†é’¥ï¼Ÿ**

A: å»ºè®®ä½¿ç”¨ç¯å¢ƒå˜é‡å­˜å‚¨APIå¯†é’¥ï¼š

```python
import os
os.environ["OPENAI_API_KEY"] = "your-api-key"
```

**Q: æ”¯æŒå“ªäº›æ¨¡å‹ï¼Ÿ**

A: æ”¯æŒæ‰€æœ‰OpenAIå…¼å®¹æ¥å£çš„APIæœåŠ¡å’Œæ¨¡å‹ï¼ŒåŒ…æ‹¬ä½†ä¸é™äºï¼š
- OpenAIçš„GPTç³»åˆ—æ¨¡å‹
- ç™¾ç‚¼çš„QwQç³»åˆ—æ¨¡å‹
- è±†åŒ…æ¨¡å‹
- ç¡…è°·æ¨¡å‹
- Claudeæ¨¡å‹(é€šè¿‡å…¼å®¹æ¥å£)

**Q: å¦‚ä½•å¤„ç†è¯·æ±‚é”™è¯¯ï¼Ÿ**

A: ä½¿ç”¨æ ‡å‡†çš„Pythonå¼‚å¸¸å¤„ç†ï¼š

```python
try:
    response = client.ask("ä½ çš„é—®é¢˜")
except Exception as e:
    print(f"å‘ç”Ÿé”™è¯¯: {e}")
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ”¹è¿›å»ºè®®ï¼è¯·æŸ¥çœ‹[è´¡çŒ®æŒ‡å—](CONTRIBUTING.md)äº†è§£æ›´å¤šä¿¡æ¯ã€‚

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨MITè®¸å¯è¯ - è¯¦è§[LICENSE](LICENSE)æ–‡ä»¶ã€‚

## ğŸ“ è”ç³»æ–¹å¼

å¦‚æœ‰ä»»ä½•é—®é¢˜æˆ–å»ºè®®ï¼Œè¯·é€šè¿‡[GitHubé—®é¢˜](https://github.com/yourusername/simpleaihelper/issues)ä¸æˆ‘ä»¬è”ç³»ã€‚ 
