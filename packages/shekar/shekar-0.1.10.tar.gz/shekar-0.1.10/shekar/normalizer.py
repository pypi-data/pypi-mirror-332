import regex as re
from typing import List, Tuple


class Normalizer:
    _diacritics_filters = [
        (r"[Ù°Ù‹ÙŒÙÙÙÙÙ‘Ù’Ù“Ù”Ù–Ø•Ù•Ù™Ù´Ì’Ì]", ""),
    ]

    _punctuation_filters = [
        (r"[^\w\s\d]", ""),
    ]

    _emoji_filters = [
        (r"[ğŸ˜€-ğŸ˜¯]", ""),
        (r"[ğŸŒ-ğŸ–¿]", ""),
        (r"[ğŸš€-ğŸ›¿]", ""),
        (r"[ğŸ‡ -ğŸ‡¿]", ""),
        (r"[ã  -ğ¯¿¿]", ""),
        (r"[â°]", ""),
        (r"[â™€-â™‚]", ""),
        (r"[â˜€-ğŸ”¿]", ""),
        (r"[â€]", ""),
        (r"[â]", ""),
        (r"[â©]", ""),
        (r"[âŒš]", ""),
        (r"[ï¸]", ""),
        (r"[ğŸ’¯]", ""),
        (r"[ã€°]", ""),
        (r"[â±]", ""),
        (r"[âª]", ""),
    ]

    _character_mappings = [
        (r"[Ù€]", ""),
        (r"[ïºïº‚]", "Ø¢"),
        (r"[Ù²Ùµï­ï­‘Ù³ïº‡ïºˆØ¥Ø£Ù±]", "Ø§"),
        (r"[Ù®Ù»Ú€İİ’İ”İ•İ–ï­’ï­•ïºïº’]", "Ø¨"),
        (r"[ï­–ï­—ï­˜ï­™ï­šï­›ï­œï­]", "Ù¾"),
        (r"[Ù¹ÙºÙ¼Ù¿İ“ï­ï­Ÿï­ ï­¡ï­¦ï­¨ïº•ïº˜]", "Øª"),
        (r"[Ù½İ‘ïº™ïºšïº›ïºœï­¢ï­¤]", "Ø«"),
        (r"[ÚƒÚ„ï­²ï­´ï­µï­·ïºïºŸïº ]", "Ø¬"),
        (r"[Ú‡Ú¿ï­ºİ˜ï­¼ï®€ï®İ¯]", "Ú†"),
        (r"[ÚÚ‚Ú…İ—İ®ïº¡ïº¤]", "Ø­"),
        (r"[ïº¥ïº¦ïº§]", "Ø®"),
        (r"[ÚˆÚ‰ÚŠÚ‹ÚÛ®İ™İšï®‚ï®ˆïº©]", "Ø¯"),
        (r"[ÚŒï±›ïº«ïº¬ÚÚÚï®…ï®‡]", "Ø°"),
        (r"[Ú‘Ú’Ú“Ú”Ú•Ú–Û¯İ›ï®Œïº­]", "Ø±"),
        (r"[Ú—İ«ïº¯ïº°]", "Ø²"),
        (r"[Ú™ï®Šï®‹]", "Ú˜"),
        (r"[ÚšÚ›ïº±ïº´]", "Ø³"),
        (r"[ÚœÛºïºµïº¸İœİ­]", "Ø´"),
        (r"[ÚÚïº¹ïº¼]", "Øµ"),
        (r"[Û»ïº½ï»€]", "Ø¶"),
        (r"[ï»ï»ƒï»„]", "Ø·"),
        (r"[ï»…ï»†ï»ˆÚŸ]", "Ø¸"),
        (r"[Ú İİİŸï»‰ï»Šï»‹]", "Ø¹"),
        (r"[Û¼ï»ï»ï»]", "Øº"),
        (r"[Ú¡Ú¢Ú£Ú¤Ú¥Ú¦İ İ¡ï­ªï­«ï­¬ï»‘ï»’ï»“]", "Ù"),
        (r"[Ù¯Ú§Ú¨ï»•ï»—]", "Ù‚"),
        (r"[ÙƒØ»Ø¼ÚªÚ«Ú¬Ú­Ú®İ¢İ£ï®ï®ï¯“ï»™ï»›]", "Ú©"),
        (r"[Ú°Ú±Ú²Ú³Ú´ï®’ï®”ï®–]", "Ú¯"),
        (r"[ÚµÚ¶Ú·Ú¸İªï»ï» ]", "Ù„"),
        (r"[Û¾İ¥İ¦ï»¡ï»¢ï»£]", "Ù…"),
        (r"[Ú¹ÚºÚ»Ú¼Ú½İ§İ¨İ©ï®ï»¥ï»§]", "Ù†"),
        (r"[Ù¶Ù·ï¯—ï¯˜ï¯™ï¯šï¯œï¯ï¯ï¯Ÿïº…Û„Û…Û‰ÛŠÛ‹Ûï¯ ï»­Ø¤×¤]", "Ùˆ"),
        (r"[Ú¾Û¿Û€ÛÛ‚ÛƒÛ•ï®¤ï®¦ï®§ï®¨ï®©ï»©ï»«Ø©]", "Ù‡"),
        (
            r"[Ø Ø½Ø¾Ø¿Ù‰ÙŠÙ¸ÛÛÛÛ‘Û’Û“ï®®ï®¯ï®°ï®±ï¯¤ï¯¥ï¯¦ï¯§ï¯¼ï¯½ï¯¾ï¯¿ï»¯ï»±ï»³ï¯¨ï¯©ï¯«ï¯­ï¯°ï¯³ï¯µï¯·ï¯¹ï¯»ï±]",
            "ÛŒ",
        ),
    ]

    _number_mappings = [
        (r"[0Ù ğŸ¢ğŸ¬]", "Û°"),
        (r"[1Ù¡ğŸ£ğŸ­â‘´â’ˆâ“µâ‘ â¶ğŸ™ğŸ·Ä±]", "Û±"),
        (r"[2Ù¢ğŸ¤ğŸ®â‘µâ’‰â“¶â‘¡â·Â²ğŸğŸ¸ğŸšá’¿Õ·]", "Û²"),
        (r"[3Ù£ğŸ¥ğŸ¯â‘¶â’Šâ“·â‘¢â¸Â³áƒ•]", "Û³"),
        (r"[4Ù¤ğŸ¦ğŸ°â‘·â’‹â“¸â‘£â¹â´]", "Û´"),
        (r"[5Ù¥ğŸ§ğŸ±â‘¸â’Œâ“¹â‘¤âºâµ]", "Ûµ"),
        (r"[6Ù¦ğŸ¨ğŸ²â‘¹â’â“ºâ‘¥â»â¶]", "Û¶"),
        (r"[7Ù§ğŸ©ğŸ³â‘ºâ’â“»â‘¦â¼â·]", "Û·"),
        (r"[8Ù¨ğŸªğŸ´â‘»â’â“¼â‘§â½â¸Û¸]", "Û¸"),
        (r"[9Ù©ğŸ«ğŸµâ‘¼â’â“½â‘¨â¾â¹]", "Û¹"),
        (r"[â‘½â’‘â“¾â‘©]", "Û±Û°"),
        (r"[â‘¾â’’â‘ª]", "Û±Û±"),
        (r"[â‘¿â’“â‘«]", "Û±Û²"),
        (r"[â’€â’”â‘¬]", "Û±Û³"),
        (r"[â’â’•â‘­]", "Û±Û´"),
        (r"[â’‚â’–â‘®]", "Û±Ûµ"),
        (r"[â’ƒâ’—â‘¯]", "Û±Û¶"),
        (r"[â’„â’˜â‘°]", "Û±Û·"),
        (r"[â’…â’™â‘±]", "Û±Û¸"),
        (r"[â’†â’šâ‘²]", "Û±Û¹"),
        (r"[â’‡â’›â‘³]", "Û²Û°"),
    ]

    _punctuation_mappings = [
        (r"[â–•â˜â™âšâ–â”‚]", "|"),
        (r"[ã…¡ä¸€â€”â€“ãƒ¼Ì¶Ù€]", "-"),
        (r"[â–_Ì²]", "_"),
        (r"[â”?ï¿½ØŸÊ•Ê”ğŸ»\x08\x97\x9d]", "ØŸ"),
        (r"[â•ï¼]", "!"),
        (r"[â‰]", "!ØŸ"),
        (r"[â€¼]", "!!"),
        (r"[â„…%]", "Ùª"),
        (r"[Ã·]", "/"),
        (r"[Ã—]", "*"),
        (r"[ï¼š]", ":"),
        (r"[â€º]", ">"),
        (r"[â€¹ï¼œ]", "<"),
        (r"[ã€Š]", "Â«"),
        (r"[ã€‹]", "Â»"),
        (r"[â€¢]", "."),
        (r"[Ù¬,]", "ØŒ"),
        (r"[;ï¼›]", "Ø›"),
    ]

    _space_mappings = [
        (r" {2,}", " "),  # remove extra spaces
        (r"\n{3,}", "\n\n"),  # remove extra newlines
        (r"\u200c{2,}", "\u200c"),  # remove extra ZWNJs
        (r"\u200c{1,} ", " "),  # remove unneded ZWNJs before space
        (r" \u200c{1,}", " "),  # remove unneded ZWNJs after space
        (r"\b\u200c*\B", ""),  # remove unneded ZWNJs at the beginning of words
        (r"\B\u200c*\b", ""),  # remove unneded ZWNJs at the end of words
        (r"[\u200b\u200d\u200e\u200f\u2066\u2067\u202a\u202b\u202d]", ""),
    ]

    _unicode_mappings = [
        ("ï·½", "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÛŒÙ…"),
        ("ï·¼", "Ø±ÛŒØ§Ù„"),
        ("(ï·°|ï·¹)", "ØµÙ„ÛŒ"),
        ("ï·²", "Ø§Ù„Ù„Ù‡"),
        ("ï·³", "Ø§Ú©Ø¨Ø±"),
        ("ï·´", "Ù…Ø­Ù…Ø¯"),
        ("ï·µ", "ØµÙ„Ø¹Ù…"),
        ("ï·¶", "Ø±Ø³ÙˆÙ„"),
        ("ï··", "Ø¹Ù„ÛŒÙ‡"),
        ("ï·¸", "ÙˆØ³Ù„Ù…"),
        ("ï»µ|ï»¶|ï»·|ï»¸|ï»¹|ï»º|ï»»|ï»¼", "Ù„Ø§"),
    ]

    def __init__(
        self,
        unifiy_characters: bool = True,
        unify_numbers: bool = True,
        unify_punctuations: bool = True,
        unify_arabic_unicode: bool = True,
        space_correction: bool = True,
        remove_emojis: bool = True,
        remove_diactrics: bool = True,
        remove_punctuations: bool = False,
        filters: List[Tuple[str, str]] = [],
    ):
        self._unify_numbers = unify_numbers
        self._unify_punctuations = unify_punctuations
        self._unify_arabic_unicode = unify_arabic_unicode
        self._remove_emojis = remove_emojis
        self._remove_diactrics = remove_diactrics
        self._remove_punctuations = remove_punctuations

        self._filters_mappings = []

        if unifiy_characters:
            self._filters_mappings.extend(self._character_mappings)
        if remove_punctuations:
            self._filters_mappings.extend(self._punctuation_filters)
        if remove_emojis:
            self._filters_mappings.extend(self._emoji_filters)
        if remove_diactrics:
            self._filters_mappings.extend(self._diacritics_filters)
        if unify_punctuations and not remove_punctuations:
            self._filters_mappings.extend(self._punctuation_mappings)
        if unify_numbers:
            self._filters_mappings.extend(self._number_mappings)
        if unify_arabic_unicode:
            self._filters_mappings.extend(self._unicode_mappings)
        if space_correction:
            self._filters_mappings.extend(self._space_mappings)
        if filters:
            self._filters_mappings.extend(filters)

    def normalize(self, text):
        for pattern, replacement in self._filters_mappings:
            text = re.sub(pattern, replacement, text)
        text = self.correct_spacings(text)
        text = text.strip()
        return text

    @classmethod
    def unify_numbers(cls, text):
        for pattern, replacement in cls._number_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def unify_punctuations(cls, text):
        for pattern, replacement in cls._punctuation_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def unify_characters(cls, text):
        for pattern, replacement in cls._character_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def unify_arabic_unicode(cls, text):
        for pattern, replacement in cls._unicode_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def remove_emojis(cls, text):
        for pattern, replacement in cls._emoji_filters:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def remove_diactrics(cls, text):
        for pattern, replacement in cls._diacritics_filters:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def remove_punctuations(cls, text):
        for pattern, replacement in cls._punctuation_filters:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def remove_diacritics(cls, text):
        for pattern, replacement in cls._diacritics_filters:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def remove_extra_spaces(cls, text):
        for pattern, replacement in cls._space_mappings:
            text = re.sub(pattern, replacement, text)
        return text

    @classmethod
    def correct_spacings(cls, sentence):
        # copied from ParsiNorm with
        # This Function is a mixture of HAZM and ParsiVar Features

        sentence = re.sub(r"^(Ø¨ÛŒ|Ù…ÛŒ|Ù†Ù…ÛŒ)( )", r"\1â€Œ", sentence)  # verb_prefix
        sentence = re.sub(r"( )(Ù…ÛŒ|Ù†Ù…ÛŒ)( )", r"\1\2â€Œ ", sentence)  # verb_prefix
        sentence = re.sub(r"([^ ]Ù‡) ÛŒ ", r"\1â€ŒÛŒ ", sentence)

        # Issue: "ÙˆØ§Ø¬Ø¯ Ø´Ø±Ø§ÛŒØ· Ø¨ÙˆØ¯Ù†Ø¯" -> "ÙˆØ§Ø¬Ø¯ Ø´Ø±Ø§ÛŒØ·â€ŒØ¨ÙˆØ¯Ù†Ø¯"
        # sentence = re.sub(
        #     r"( )(Ù‡Ø§ÛŒÛŒ|Ù‡Ø§|Ù‡Ø§ÛŒ|Ø§ÛŒÛŒ|Ù‡Ø§ÛŒÙ…|Ù‡Ø§ÛŒØª|Ù‡Ø§ÛŒØ´|Ù‡Ø§ÛŒÙ…Ø§Ù†|Ù‡Ø§ÛŒØªØ§Ù†|Ù‡Ø§ÛŒØ´Ø§Ù†|Ø§Øª|Ø§Ù†|ÛŒÙ†"
        #     r"|Ø§Ù†ÛŒ|Ø¨Ø§Ù†|Ø§Ù…|Ø§ÛŒ|ÛŒÙ…|ÛŒØ¯|Ø§ÛŒØ¯|Ø§Ù†Ø¯|Ø¨ÙˆØ¯Ù…|Ø¨ÙˆØ¯ÛŒ|Ø¨ÙˆØ¯|Ø¨ÙˆØ¯ÛŒÙ…|Ø¨ÙˆØ¯ÛŒØ¯|Ø¨ÙˆØ¯Ù†Ø¯|Ø³Øª|ØªØ±|ØªØ±ÛŒ|ØªØ±ÛŒÙ†|Ú¯Ø±ÛŒ|Ú¯Ø±)( )",
        #     r"â€Œ\2\3",
        #     sentence,
        # )

        # Issue: some suffixes may introduce incorrect spacing!
        # A more complex solution is needed to fix this issue.
        # Example: "Ø¨Ø§ Ú©ÛŒâ€ŒØ¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ù†ÛŒØŸ" <- "Ø¨Ø§ Ú©ÛŒ Ø¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒâ€ŒØ²Ù†ÛŒØŸ"
        # Example: "Ø¨Ù‡ Ù†Ú©ØªÙ‡ Ø±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!" -> "Ø¨Ù‡ Ù†Ú©ØªÙ‡â€ŒØ±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!"

        # complex_word_suffix_pattern = (
        #     r"( )(Ø·Ù„Ø¨Ø§Ù†|Ø·Ù„Ø¨|Ú¯Ø±Ø§ÛŒÛŒ|Ú¯Ø±Ø§ÛŒØ§Ù†|Ø´Ù†Ø§Ø³|Ø´Ù†Ø§Ø³ÛŒ|Ú¯Ø°Ø§Ø±ÛŒ|Ú¯Ø°Ø§Ø±|Ú¯Ø°Ø§Ø±Ø§Ù†|Ø´Ù†Ø§Ø³Ø§Ù†|Ú¯ÛŒØ±ÛŒ|Ù¾Ø°ÛŒØ±ÛŒ|Ø¨Ù†Ø¯ÛŒ|Ø¢ÙˆØ±ÛŒ|Ø³Ø§Ø²ÛŒ|"
        #     r"Ø¨Ù†Ø¯ÛŒ|Ú©Ù†Ù†Ø¯Ù‡|Ú©Ù†Ù†Ø¯Ú¯Ø§Ù†|Ú¯ÛŒØ±ÛŒ|Ù¾Ø±Ø¯Ø§Ø²|Ù¾Ø±Ø¯Ø§Ø²ÛŒ|Ù¾Ø±Ø¯Ø§Ø²Ø§Ù†|Ø¢Ù…ÛŒØ²|Ø³Ù†Ø¬ÛŒ|Ø±ÛŒØ²ÛŒ|Ø¯Ø§Ø±ÛŒ|Ø¯Ù‡Ù†Ø¯Ù‡|Ø¢Ù…ÛŒØ²|Ù¾Ø°ÛŒØ±ÛŒ"
        #     r"|Ù¾Ø°ÛŒØ±|Ù¾Ø°ÛŒØ±Ø§Ù†|Ú¯Ø±|Ø±ÛŒØ²|Ø±ÛŒØ²ÛŒ|Ø±Ø³Ø§Ù†ÛŒ|ÛŒØ§Ø¨|ÛŒØ§Ø¨ÛŒ|Ú¯Ø§Ù†Ù‡|Ú¯Ø§Ù†Ù‡â€ŒØ§ÛŒ|Ø§Ù†Ú¯Ø§Ø±ÛŒ|Ú¯Ø§|Ø¨Ù†Ø¯|Ø±Ø³Ø§Ù†ÛŒ|Ø¯Ù‡Ù†Ø¯Ú¯Ø§Ù†|Ø¯Ø§Ø±)( )"
        # )
        # sentence = re.sub(complex_word_suffix_pattern, r"â€Œ\2\3", sentence)
        sentence = re.sub(r' "([^\n"]+)" ', r'"\1"', sentence)

        punc_after = r".\.:!ØŒØ›ØŸÂ»\]\)\}"
        punc_before = r"Â«\[\(\{"

        sentence = re.sub(
            r" ([" + punc_after + "])|([" + punc_before + "]) ", r"\1\2", sentence
        )
        sentence = re.sub(
            r"([.ØŒ:ØŸ!])([^ {} \dÛ°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹])".format(punc_after), r"\1 \2", sentence
        )
        sentence = re.sub(
            r"([^ " + punc_before + "])([" + punc_before + "])", r"\1 \2", sentence
        )

        sentence = cls.remove_extra_spaces(sentence)
        return sentence
