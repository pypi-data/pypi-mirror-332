import pytest
from shekar.normalizer import Normalizer


@pytest.fixture
def normalizer():
    return Normalizer()


def test_normalize_numbers(normalizer):
    input_text = "Ù Ù¡Ù¢Ù£Ù¤Ù¥Ù¦Ù§Ù¨Ù© â’•34"
    expected_output = "Û°Û±Û²Û³Û´ÛµÛ¶Û·Û¸Û¹ Û±Û´Û³Û´"
    assert normalizer.normalize(input_text) == expected_output


def test_unify_characters(normalizer):
    input_text = "Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ø©"
    expected_output = "Ù†Ø´Ø§Ù†â€ŒØ¯Ù‡Ù†Ø¯Ù‡"
    assert normalizer.normalize(input_text) == expected_output

    input_text = "Ø³Ø§ÛŒØ©"
    expected_output = "Ø³Ø§ÛŒÙ‡"
    assert normalizer.normalize(input_text) == expected_output

    input_text = "Û¿Ø¯Ù Ù…Ø§ Ø»Ù…Ú« Ø¨Û€ ÛÚªÚ‰ÙŠÚ±Ú• Ø£ÚšÙ¼"
    expected_output = "Ù‡Ø¯Ù Ù…Ø§ Ú©Ù…Ú© Ø¨Ù‡ ÛŒÚ©Ø¯ÛŒÚ¯Ø± Ø§Ø³Øª"
    print(normalizer.normalize(input_text))
    print(expected_output)
    assert normalizer.normalize(input_text) == expected_output

    input_text = "Ú©Ø§Ø±ØªÙˆÙ†"
    expected_output = "Ú©Ø§Ø±ØªÙˆÙ†"
    assert normalizer.normalize(input_text) == expected_output

    # correct examples
    input_text = "Ù‡Ù…Ù‡ Ø¨Ø§ Ù‡Ù… Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ù¾Ù„ÛŒØ¯ÛŒ Ùˆ Ø³ØªÙ… Ø®ÙˆØ§Ù‡ÛŒÙ… Ø§ÛŒØ³ØªØ§Ø¯"
    expected_output = "Ù‡Ù…Ù‡ Ø¨Ø§ Ù‡Ù… Ø¯Ø± Ø¨Ø±Ø§Ø¨Ø± Ù¾Ù„ÛŒØ¯ÛŒ Ùˆ Ø³ØªÙ… Ø®ÙˆØ§Ù‡ÛŒÙ… Ø§ÛŒØ³ØªØ§Ø¯"
    assert normalizer.normalize(input_text) == expected_output


def test_unify_punctuations(normalizer):
    input_text = "ØŸ?ØŒÙ¬!%:Â«Â»Ø›"
    expected_output = "ØŸØŸØŒØŒ!Ùª:Â«Â»Ø›"
    assert normalizer.unify_punctuations(input_text) == expected_output


def test_remove_emojis(normalizer):
    input_text = "ğŸ˜ŠğŸ‡®ğŸ‡·Ø³Ù„Ø§Ù… Ú¯Ù„Ø§ÛŒ ØªÙˆ Ø®ÙˆÙ†Ù‡!ğŸ‰ğŸ‰ğŸŠğŸˆ"
    expected_output = "Ø³Ù„Ø§Ù… Ú¯Ù„Ø§ÛŒ ØªÙˆ Ø®ÙˆÙ†Ù‡!"
    assert normalizer.remove_emojis(input_text) == expected_output

    input_text = "ğŸŒ¹ Ø¨Ø§Ø² Ù‡Ù… Ù…Ø±Øº Ø³Ø­Ø±ğŸ” Ø¨Ø± Ø³Ø± Ù…Ù†Ø¨Ø± Ú¯Ù„ "
    expected_output = " Ø¨Ø§Ø² Ù‡Ù… Ù…Ø±Øº Ø³Ø­Ø± Ø¨Ø± Ø³Ø± Ù…Ù†Ø¨Ø± Ú¯Ù„ "
    print(normalizer.remove_emojis(input_text))
    print(expected_output)
    assert normalizer.remove_emojis(input_text) == expected_output


def test_remove_diacritics(normalizer):
    input_text = "Ù…ÙÙ†Ù’"
    expected_output = "Ù…Ù†"
    assert normalizer.remove_diacritics(input_text) == expected_output

    input_text = "Ú©ÙØ¬Ø§ Ù†ÙØ´Ø§Ù†Ù Ù‚ÙØ¯ÙÙ… Ù†Ø§ØªÙÙ…Ø§Ù… Ø®ÙˆØ§Ù‡ÙØ¯ Ù…Ø§Ù†Ø¯ØŸ"
    expected_output = "Ú©Ø¬Ø§ Ù†Ø´Ø§Ù† Ù‚Ø¯Ù… Ù†Ø§ØªÙ…Ø§Ù… Ø®ÙˆØ§Ù‡Ø¯ Ù…Ø§Ù†Ø¯ØŸ"
    assert normalizer.remove_diacritics(input_text) == expected_output


def test_unify_arabic_unicode(normalizer):
    input_text = "ï·½"
    expected_output = "Ø¨Ø³Ù… Ø§Ù„Ù„Ù‡ Ø§Ù„Ø±Ø­Ù…Ù† Ø§Ù„Ø±Ø­ÛŒÙ…"
    assert normalizer.unify_arabic_unicode(input_text) == expected_output

    input_text = "Ù¾Ù†Ø¬Ø§Ù‡ Ù‡Ø²Ø§Ø± ï·¼"
    expected_output = "Ù¾Ù†Ø¬Ø§Ù‡ Ù‡Ø²Ø§Ø± Ø±ÛŒØ§Ù„"
    assert normalizer.unify_arabic_unicode(input_text) == expected_output

    input_text = "ï·² Ø§Ø¹Ù„Ù… "
    expected_output = "Ø§Ù„Ù„Ù‡ Ø§Ø¹Ù„Ù… "
    assert normalizer.unify_arabic_unicode(input_text) == expected_output

    input_text = "ï·² ï·³"
    expected_output = "Ø§Ù„Ù„Ù‡ Ø§Ú©Ø¨Ø±"
    assert normalizer.unify_arabic_unicode(input_text) == expected_output

    input_text = "ï·´"
    expected_output = "Ù…Ø­Ù…Ø¯"
    assert normalizer.unify_arabic_unicode(input_text) == expected_output


def test_remove_punctuations(normalizer):
    input_text = "$@^<</Ù…Ù†:<, ()).^%!?Ù…ÛŒØ±ÙˆÙ…"
    expected_output = "Ù…Ù† Ù…ÛŒØ±ÙˆÙ…"
    assert normalizer.remove_punctuations(input_text) == expected_output


def test_correct_spacings(normalizer):
    """Tests normalization with a Persian sentence."""
    input_text = "   Ø§ÛŒÙ† ÛŒÚ© Ø¬Ù…Ù„Ù‡   Ù†Ù…ÙˆÙ†Ù‡   Ø§Ø³Øª . "
    expected_output = " Ø§ÛŒÙ† ÛŒÚ© Ø¬Ù…Ù„Ù‡ Ù†Ù…ÙˆÙ†Ù‡ Ø§Ø³Øª. "
    assert normalizer.correct_spacings(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø¬Ø§Ø³ØªØŸØªÙˆ Ù…ÛŒØ¯ÙˆÙ†ÛŒØŸÙ†Ù…ÛŒØ¯ÙˆÙ†Ù…!"
    expected_output = "Ø§ÛŒÙ†Ø¬Ø§ Ú©Ø¬Ø§Ø³ØªØŸ ØªÙˆ Ù…ÛŒØ¯ÙˆÙ†ÛŒØŸ Ù†Ù…ÛŒØ¯ÙˆÙ†Ù…!"
    assert normalizer.correct_spacings(input_text) == expected_output

    input_text = "Ù†Ø§ØµØ± Ú¯ÙØª:Â«Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ….Â»"
    expected_output = "Ù†Ø§ØµØ± Ú¯ÙØª: Â«Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ….Â»"
    assert normalizer.correct_spacings(input_text) == expected_output

    input_text = "Ø¨Ø§ Ú©ÛŒ Ø¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒ Ø²Ù†ÛŒØŸ"
    expected_output = "Ø¨Ø§ Ú©ÛŒ Ø¯Ø§Ø±ÛŒ Ø­Ø±Ù Ù…ÛŒ Ø²Ù†ÛŒØŸ"
    assert normalizer.correct_spacings(input_text) == expected_output

    input_text = "Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ….ØªÙˆ Ù†Ù…ÛŒâ€ŒØ¢ÛŒÛŒØŸ"
    expected_output = "Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ…. ØªÙˆ Ù†Ù…ÛŒâ€ŒØ¢ÛŒÛŒØŸ"
    assert normalizer.correct_spacings(input_text) == expected_output

    input_text = "Ø¨Ù‡ Ù†Ú©ØªÙ‡ Ø±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!"
    expected_output = "Ø¨Ù‡ Ù†Ú©ØªÙ‡ Ø±ÛŒØ²ÛŒ Ø§Ø´Ø§Ø±Ù‡ Ú©Ø±Ø¯ÛŒ!"
    assert normalizer.correct_spacings(input_text) == expected_output


def test_remove_extra_spaces(normalizer):
    input_text = "Ø§ÛŒÙ†  ÛŒÚ©  ØªØ³Øª  Ø§Ø³Øª"
    expected_output = "Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª"
    assert normalizer.remove_extra_spaces(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†  ÛŒÚ©\n\n\nØªØ³Øª  Ø§Ø³Øª"
    expected_output = "Ø§ÛŒÙ† ÛŒÚ©\n\nØªØ³Øª Ø§Ø³Øª"
    assert normalizer.remove_extra_spaces(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†\u200cÛŒÚ©\u200cØªØ³Øª\u200cØ§Ø³Øª"
    expected_output = "Ø§ÛŒÙ†\u200cÛŒÚ©\u200cØªØ³Øª\u200cØ§Ø³Øª"
    assert normalizer.remove_extra_spaces(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†\u200c ÛŒÚ©\u200c ØªØ³Øª\u200c Ø§Ø³Øª"
    expected_output = "Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª"
    assert normalizer.remove_extra_spaces(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†  ÛŒÚ©  ØªØ³Øª  Ø§Ø³Øª  "
    expected_output = "Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª "
    assert normalizer.remove_extra_spaces(input_text) == expected_output

    input_text = "Ø§ÛŒÙ†  ÛŒÚ©  ØªØ³Øª  Ø§Ø³Øª\n\n\n\n"
    expected_output = "Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø§Ø³Øª\n\n"
    assert normalizer.remove_extra_spaces(input_text) == expected_output


def test_normalize(normalizer):
    input_text = "Ù†Ø§ØµØ± Ú¯ÙØª:Â«Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ….Â» \u200c ğŸ‰ğŸ‰ğŸŠğŸˆ"
    expected_output = "Ù†Ø§ØµØ± Ú¯ÙØª: Â«Ù…Ù† Ù…ÛŒâ€ŒØ±ÙˆÙ….Â»"
    assert normalizer.normalize(input_text) == expected_output

    input_text = (
        "âš¡ï¸ Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ ÙˆØ§Ø¬Ø¯ Ø´Ø±Ø§ÛŒØ· Ø¨ÙˆØ¯Ù†Ø¯ Ù†ÛŒØ² Ø¨Ø§ Ù¾Ø§Ø¯Ø§Ø´ Ù‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù†Ø§Ú†ÛŒØ² Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯."
    )
    expected_output = (
        " Ú©Ø§Ø±Ø¨Ø±Ø§Ù†ÛŒ Ú©Ù‡ ÙˆØ§Ø¬Ø¯ Ø´Ø±Ø§ÛŒØ· Ø¨ÙˆØ¯Ù†Ø¯ Ù†ÛŒØ² Ø¨Ø§ Ù¾Ø§Ø¯Ø§Ø´ Ù‡Ø§ÛŒ Ø¨Ø³ÛŒØ§Ø± Ù†Ø§Ú†ÛŒØ² Ù…ÙˆØ§Ø¬Ù‡ Ø´Ø¯Ù†Ø¯."
    )
