# -*- coding: utf-8 -*-
"""CUDU_20250305_01.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1knQXLkWyy2n73OowWlhUsM_sNdfX9bq4

# CudaUtility
 Cudaサポートユーティリティ


```
2025/02/24 0.1.0 完成
2025/02/27 0.2.0 check_gpu追加。
2025/03/05 0.2.1 version_symbol改良。11.8.0というバージョン番号にも対応
2025/03/05 0.3.0 is_valid_cuda_version追加。変更しようとする文字列がCUDAのバージョン番号に変更可能か調べる
2025/03/07 0.4.0 version_numberツイス。CU118というシンボルを11.8に変換する
```

# CudaUtility

## 1. GDrive接続
"""

from google.colab import drive
drive.mount('/content/drive')

"""## 2. モジュール定義"""

# @title a. CudaUtility 定義
import os
import torch
import re

class CudaUtility:
    def __init__(self):
        pass
        # GPUの状態や情報を格納するメンバ変数
        self.gpu_available = False
        self.gpu_info = None

    def check_status( self ):
        print( "1️⃣ CUDA関連パッケージインストール状況" )
        get_ipython().system("dpkg -l | grep cuda")
        get_ipython().system("dpkg -l | grep libcudnn")

        print( "2️⃣ CUDAファイル残存状況確認" )
        get_ipython().system("ls -l /usr/local | grep cuda")
        get_ipython().system("ls -l /usr/lib | grep cuda")
        get_ipython().system("ls -l /usr/lib64 | grep cuda")

        print( "3️⃣ 環境変数の影響を確認" )
        get_ipython().system("echo $PATH")
        get_ipython().system("echo $LD_LIBRARY_PATH")

    # 旧称 get_cuda_version_symbol
    def version_symbol(self, cuda_version: str) -> str:
        """
        CUDAのバージョン番号 (例: "11.8", "11.8.0", "12.4") を
        CUDAのシンボル (例: "CU118", "CU124") に変換する。

        入力が "11.8.0" のように3部構成の場合でも、最初の2部を使ってシンボルを生成します。

        :param cuda_version: CUDAのバージョン番号 (例: "11.8", "11.8.0", "12.4")
        :return: 変換されたシンボル (例: "CU118", "CU124")
        """
        parts = cuda_version.split('.')
        if len(parts) < 2:
            raise ValueError(f"Invalid CUDA version format: {cuda_version}")
        major = parts[0]
        minor = parts[1]
        return f"CU{major}{minor}"

    def is_valid_cuda_version( self, cuda_version: str ) -> bool:
        """
        CUDAのバージョン番号が有効かどうかをチェックする関数。
        有効な形式の例:
        - "11.8"
        - "11.8.2"
        その他の形式の場合はFalseを返す。
        """
        # 正規表現パターン:
        # 1. 数字＋ピリオド＋数字 : 必須部分
        # 2. （オプション）さらにピリオド＋数字
        pattern = re.compile(r'^\d+\.\d+(\.\d+)?$')
        return bool(pattern.match(cuda_version))


    def version_number( self, symbol: str) -> str:
        """
        CUDAのシンボル表記（例: "CU118", "CU124", "CU125"）を
        バージョン番号（例: "11.8", "12.4", "12.5"）に変換する。

        :param symbol: CUDAシンボル表記 (例: "CU118")
        :return: バージョン番号 (例: "11.8")
        :raises ValueError: 入力の形式が正しくない場合
        """
        # 大文字に統一して "CU" で始まっているか確認
        symbol = symbol.upper()
        if not symbol.startswith("CU"):
            raise ValueError("CUDAシンボルは 'CU' で始まる必要があります。")

        numeric_part = symbol[2:]
        if len(numeric_part) < 2 or not numeric_part.isdigit():
            raise ValueError("CUDAシンボルの 'CU' の後には、少なくとも2桁の数字が必要です。")

        # 例: "118" -> major = "11", minor = "8"
        major = numeric_part[:2]
        minor = numeric_part[2:] if len(numeric_part) > 2 else "0"

        # int変換して余分な0を除去
        version = f"{int(major)}.{int(minor)}"
        return version


    def check_gpu(self):
        """
        GPUが有効ならTrue、無効ならFalseを返す。
        まずtorch.cuda.is_available()で確認し、Falseの場合は /proc/driver/nvidia/version をチェックする。
        """
        try:
            # PyTorchでGPUが利用可能かどうかチェック
            available = torch.cuda.is_available()
        except Exception as e:
            available = False

        if available:
            self.gpu_available = True
            self.gpu_info = "torch.cuda.is_available() returned True"
            return True
        else:
            # torchがFalseを返した場合、低レベルな方法として /proc/driver/nvidia/version を確認
            if os.path.exists("/proc/driver/nvidia/version"):
                try:
                    with open("/proc/driver/nvidia/version", "r") as f:
                        version_info = f.read().strip()
                    self.gpu_available = True
                    self.gpu_info = version_info
                    return True
                except Exception as e:
                    self.gpu_available = False
                    self.gpu_info = f"Error reading /proc/driver/nvidia/version: {e}"
                    return False
            else:
                self.gpu_available = False
                self.gpu_info = "GPU is not available (torch reports False and /proc/driver/nvidia/version not found)"
                return False

"""## 3. 実行"""

# @title a. 実行
if __name__ == "__main__":
    cudautility = CudaUtility()
    cudautility.check_status()
    print(cudautility.version_symbol("11.8"))
    print(cudautility.version_symbol("11.8.0"))
    print(cudautility.version_symbol("12.4"))
    print( cudautility.is_valid_cuda_version("11.8") )
    print( cudautility.is_valid_cuda_version("11.8.2") )

    print( cudautility.is_valid_cuda_version("fffd;ap") )



    print(cudautility.version_number("CU118"))  # 出力: 11.8
    print(cudautility.version_number("cu124"))  # 出力: 12.4
    print(cudautility.version_number("CU125"))  # 出力: 12.5

# 使用例
if __name__ == "__main__":
    cudau = CudaUtility()
    if cudau.check_gpu():
        print("GPUは有効です。")
        print("GPU情報:")
        print(cudau.gpu_info)
    else:
        print("GPUは無効です。")
        print("詳細:")
        print(cudau.gpu_info)