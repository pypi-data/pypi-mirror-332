<div align="center">
  <img src="./docs/assets/logo.png" alt="promptrefiner Logo" width="200">
  
  # Promptrefiner ğŸš€  
  **Enhancing prompts with intelligent strategies for LLMs**  

  [![PyPI Version](https://img.shields.io/pypi/v/promptrefiner)](https://pypi.org/project/promptrefiner/)
  [![GitHub Repo](https://img.shields.io/badge/GitHub-Code-black?logo=github)](https://github.com/darshit7/promptrefiner)
  [![License](https://img.shields.io/github/license/darshit7/promptrefiner)](https://darshit7.github.io/promptrefiner/LICENSE)
  [![Docs](https://img.shields.io/badge/docs-Promptrefiner-blue)](https://darshit7.github.io/promptrefiner/)
</div>

## ğŸš€ Welcome to Promptrefiner

> **Helping you craft the perfect prompt for better LLM responses!**

PromptRefiner is a lightweight **Python library** that helps users **write better prompts** for Large Language Models (LLMs) with minimal configurations. Many users struggle to craft effective prompts that yield the desired results.  

PromptRefiner **takes user input**, applies a **selected strategy**, and **returns an improved prompt** to get **more specific and effective responses from LLMs (Large Language Models).** It achieves this by leveraging an **LLM to refine the userâ€™s prompt** based on predefined strategies, making it easier to get high-quality responses.

Whether you're using a prompt for **GPT-4, Claude, Mistral, or any other LLM**, PromptRefiner ensures **your input is well-structured** for the best possible output.

---

## âœ¨ Key Features

âœ… **Supports 100+ LLM Clients** â€“ Works with OpenAI, Anthropic, Hugging Face, and more!  
âœ… **Highly Customizable** â€“ Use different LLM clients per strategy or a single client for all.  
âœ… **Command-Line First** â€“ Quickly refine prompts from the CLI for rapid experimentation.  
âœ… **Extensible** â€“ Developers can create their own **custom prompt refinement strategies**.  
âœ… **Seamless Integration** â€“ Works effortlessly in Python applications or scripts.  

---

## ğŸ“¥ Installation

Install PromptRefiner using pip:

```sh
pip install promptrefiner
```

---

## âš¡ Quick Start

### ğŸ”§ **Using from the Command Line**

Before using `promptrefiner` in Python, make sure to **set environment variables** (Windows users should use set instead of export):  

```sh
export PREFINER_API_KEY="your-api-key-here"
export PREFINER_MODEL="openai/gpt-4"  # Change based on your LLM model
```

and there you go...  

```sh
promptrefiner --strategy fewshot "Tell me about AI"
```

### ğŸ **Using in a Python Script**

> Make sure to **set environment variables** `PREFINER_API_KEY` and `PREFINER_MODEL` before using `PromptRefiner` in your python script.

```python
from promptrefiner import PromptRefiner

prompt_refiner = PromptRefiner(strategies=["persona"])
refined_prompt = prompt_refiner.refine("Explain quantum mechanics.")
print(refined_prompt)
```

### â“ Help Section of `promptrefiner`
Access available list of strategies, it's alias and all required help thorugh `--help` option.

```bash
(env) $promptrefiner --help
```
![PromptRefiner Help](./docs/assets/pr_help.jpg)
---

## ğŸ” How It Works

1. **User provides a prompt** (e.g., "Tell me about AI").
2. **Selects a strategy** (e.g., "verbose" for a more detailed response).
3. **PromptRefiner applies a system prompt template** for that strategy.
4. **Sends it to an LLM** for refinement.
5. **Returns the improved prompt** back to the user.

ğŸš€ **Under the hood:** Each strategy is backed by a system prompt template that guides the LLM to refine the userâ€™s input for better results.

---

## ğŸ¤” Why Use PromptRefiner?

ğŸ”¹ **Improve prompt clarity & effectiveness** â€“ Get sharper, more relevant responses.  
ğŸ”¹ **Save time** â€“ No need to manually tweak prompts for better results.  
ğŸ”¹ **Optimized for developers & researchers** â€“ Quickly test different prompting strategies.  
ğŸ”¹ **Fine-tune for different LLMs** â€“ Customize strategies for specific AI models.  
ğŸ”¹ **Works for various use cases:**  

- Chatbots & AI assistants
- Content generation & summarization
- Data extraction from LLMs
- Code generation improvements

---

## ğŸš€ Join Us & Contribute!

We welcome **contributors, feedback, and feature suggestions!** ğŸš€

ğŸ“Œ **GitHub Repo**: [darshit7/promptrefiner](https://github.com/darshit7/promptrefiner)  
ğŸ“Œ **Documentation**: [Promptrefiner](https://darshit7.github.io/promptrefiner/)  
ğŸ“Œ **Report Issues & Ideas**: [Coming Soon](#)

ğŸ‘¥ **Want to improve PromptRefiner?** Open a GitHub issue or contribute a pull request! ğŸ› ï¸

---

ğŸš€ **Refine your prompts. Supercharge your AI interactions. Try PromptRefiner today!**