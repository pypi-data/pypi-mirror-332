{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import random\n",
    "import rtsvg\n",
    "rt = rtsvg.RACETrack()\n",
    "\n",
    "df = pl.read_csv('../../data/2013_vast_challenge/mc3_netflow/nf/nf-chunk1.csv')\n",
    "df = rt.columnsAreTimestamps(df, 'parsedDate')\n",
    "df = df.rename({'TimeSeconds':                '_del1_',\n",
    "                'parsedDate':                 'timestamp',\n",
    "                'dateTimeStr':                '_del2_',\n",
    "                'ipLayerProtocol':            'pro',\n",
    "                'ipLayerProtocolCode':        '_del3_',\n",
    "                'firstSeenSrcIp':             'sip',\n",
    "                'firstSeenDestIp':            'dip',\n",
    "                'firstSeenSrcPort':           'spt',\n",
    "                'firstSeenDestPort':          'dpt',\n",
    "                'moreFragments':              '_del4_',\n",
    "                'contFragments':              '_del5_',\n",
    "                'durationSeconds':            'dur',\n",
    "                'firstSeenSrcPayloadBytes':   '_del6_',\n",
    "                'firstSeenDestPayloadBytes':  '_del7_',\n",
    "                'firstSeenSrcTotalBytes':     'soct',\n",
    "                'firstSeenDestTotalBytes':    'doct',\n",
    "                'firstSeenSrcPacketCount':    'spkt',\n",
    "                'firstSeenDestPacketCount':   'dpkt',\n",
    "                'recordForceOut':             '_del8_'})\n",
    "df = df.drop(['_del1_', '_del2_', '_del3_', '_del4_', '_del5_', '_del6_', '_del7_', '_del8_'])\n",
    "#df = df.sample(100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# spreadLines() - attempt to implement this visualization\n",
    "#\n",
    "# Based on:\n",
    "#\n",
    "# @misc{kuo2024spreadlinevisualizingegocentricdynamic,\n",
    "#       title={SpreadLine: Visualizing Egocentric Dynamic Influence}, \n",
    "#       author={Yun-Hsin Kuo and Dongyu Liu and Kwan-Liu Ma},\n",
    "#       year={2024},\n",
    "#       eprint={2408.08992},\n",
    "#       archivePrefix={arXiv},\n",
    "#       primaryClass={cs.HC},\n",
    "#       url={https://arxiv.org/abs/2408.08992}, \n",
    "# }\n",
    "# \n",
    "def spreadLines(rt_self,\n",
    "                df,\n",
    "                relationships,\n",
    "                node_focus,\n",
    "                ts_field        = None,  # Will attempt to guess based on datatypes\n",
    "                every           = '1d',  # \"the every field for the group_by_dynamic\" ... 1d, 1h, 1m\n",
    "                color_by        = None,\n",
    "                count_by        = None,\n",
    "                count_by_set    = False,\n",
    "                widget_id       = None,\n",
    "                w               = 1024,\n",
    "                h               = 512,\n",
    "                x_ins           = 32,\n",
    "                y_ins           = 8,\n",
    "                txt_h           = 12):\n",
    "    if rt_self.isPolars(df) == False: raise Exception('spreadLines() - only supports polars dataframe')\n",
    "    return SpreadLines(**locals())\n",
    "\n",
    "#\n",
    "#\n",
    "#\n",
    "class SpreadLines(object):\n",
    "    #\n",
    "    # transform all fields (if they area t-field)\n",
    "    # - replace those fields w/ the new versions (i actually don't think the names change...)\n",
    "    #\n",
    "    def __transformFields__(self):\n",
    "        # Gather up all of the fields that are going to be used\n",
    "        _all_columns_ = [self.ts_field]\n",
    "        if self.color_by is not None: _all_columns_.append(self.color_by)\n",
    "        if self.count_by is not None: _all_columns_.append(self.count_by)\n",
    "        for _relationship_ in self.relationships:\n",
    "            _fm_, _to_ = _relationship_[0], _relationship_[1]\n",
    "            if   type(_fm_) is str: _all_columns_.append(_fm_)\n",
    "            elif type(_fm_) is tuple:\n",
    "                for i in range(len(_fm_)): _all_columns_.append(_fm_[i])\n",
    "            if   type(_to_) is str: _all_columns_.append(_to_)\n",
    "            elif type(_to_) is tuple:\n",
    "                for i in range(len(_to_)): _all_columns_.append(_to_[i])\n",
    "        # Transform the fields\n",
    "        self.df, _new_columns_ = self.rt_self.transformFieldListAndDataFrame(self.df, _all_columns_)\n",
    "        # Remap them\n",
    "        col_i = 0\n",
    "        self.ts_field        = _new_columns_[col_i]\n",
    "        col_i += 1\n",
    "        if self.color_by is not None: \n",
    "            self.color_by = _new_columns_[col_i]\n",
    "            col_i += 1\n",
    "        if self.count_by is not None:\n",
    "            self.count_by = _new_columns_[col_i]\n",
    "            col_i += 1\n",
    "        _new_relationships_ = []\n",
    "        for _relationship_ in self.relationships:\n",
    "            _fm_, _to_ = _relationship_[0], _relationship_[1]\n",
    "            if   type(_fm_) is str: \n",
    "                _fm_ = _new_columns_[col_i]\n",
    "                col_i += 1\n",
    "            elif type(_fm_) is tuple:\n",
    "                as_list = []\n",
    "                for i in range(len(_fm_)):\n",
    "                    as_list.append(_new_columns_[col_i])                    \n",
    "                    col_i += 1\n",
    "                _fm_ = tuple(as_list)\n",
    "            if   type(_to_) is str: \n",
    "                _to_ = _new_columns_[col_i]\n",
    "                col_i += 1\n",
    "            elif type(_to_) is tuple:\n",
    "                as_list = []\n",
    "                for i in range(len(_to_)): \n",
    "                    as_list.append(_new_columns_[col_i])\n",
    "                    col_i += 1\n",
    "                _to_ = tuple(as_list)\n",
    "            _new_relationships_.append((_fm_, _to_))\n",
    "        self.relationships = _new_relationships_\n",
    "\n",
    "\n",
    "    #\n",
    "    # __consolidateRelationships__() - simplify the relationship fields into a single field\n",
    "    # ... and use standard naming\n",
    "    # ... replaces the \"relationships\" field w/ the consolidated field names\n",
    "    # ... use (__fm0__, __to0__),( __fm1__, __to1__), etc.\n",
    "    #\n",
    "    def __consolidateRelationships__(self):\n",
    "        new_relationships = []\n",
    "        for i in range(len(self.relationships)):\n",
    "            _fm_, _to_ = self.relationships[i]\n",
    "            new_fm = f'__fm{i}__'\n",
    "            new_to = f'__to{i}__'\n",
    "            if type(_fm_) is str: self.df = self.df.with_columns(pl.col(_fm_).alias(new_fm))\n",
    "            else:                 self.df = self.rt_self.createConcatColumn(self.df, _fm_, new_fm)\n",
    "            if type(_to_) is str: self.df = self.df.with_columns(pl.col(_to_).alias(new_to))\n",
    "            else:                 self.df = self.rt_self.createConcatColumn(self.df, _to_, new_to)\n",
    "            new_relationships.append((new_fm, new_to))\n",
    "        self.relationships = new_relationships\n",
    "\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    def __init__(self, rt_self, **kwargs):\n",
    "        self.rt_self       = rt_self\n",
    "        self.df            = rt_self.copyDataFrame(kwargs['df'])\n",
    "        self.relationships = kwargs['relationships']\n",
    "        self.node_focus    = kwargs['node_focus']\n",
    "        self.ts_field      = self.rt_self.guessTimestampField(self.df) if kwargs['ts_field'] is None else kwargs['ts_field']\n",
    "        self.every         = kwargs['every']\n",
    "        self.color_by      = kwargs['color_by']\n",
    "        self.count_by      = kwargs['count_by']\n",
    "        self.count_by_set  = kwargs['count_by_set']\n",
    "        self.widget_id     = f'spreadlines_{random.randint(0,65535)}' if kwargs['widget_id'] is None else kwargs['widget_id']\n",
    "        self.w             = kwargs['w']\n",
    "        self.h             = kwargs['h']\n",
    "        self.x_ins         = kwargs['x_ins']\n",
    "        self.y_ins         = kwargs['y_ins']\n",
    "        self.txt_h         = kwargs['txt_h']\n",
    "        # Unwrap any fields w/ the appropriate transforms\n",
    "        self.__transformFields__()\n",
    "        # Consolidate the fm's and to's into a simple field (__fm0__, __to0__),( __fm1__, __to1__), etc.\n",
    "        self.__consolidateRelationships__()\n",
    "        # How many bins?  And what's in those bins for nodes next to the focus?\n",
    "        self.df = self.df.sort(self.ts_field)\n",
    "        _bin_                    = 0\n",
    "        _dfs_containing_focus_   = [] # focus  -> alter1 or alter1 -> focus\n",
    "        _dfs_containing_alter2s_ = [] # alter1 -> alter2 or alter2 -> alter1  ... note does not include focus or alter1 <-> alter1\n",
    "        self.bin_to_timestamps   = {}\n",
    "        self.bin_to_alter1s      = {}\n",
    "        self.bin_to_alter2s      = {}\n",
    "        for k, k_df in self.df.group_by_dynamic(self.ts_field, every=self.every):\n",
    "            _timestamp_     = k[0]\n",
    "            _found_matches_ = False\n",
    "            # find the first alters\n",
    "            for i in range(len(self.relationships)):\n",
    "                _fm_, _to_ = self.relationships[i]\n",
    "                \n",
    "                # From Is Focus\n",
    "                _df_fm_is_focus_ = k_df.filter(pl.col(_fm_) == self.node_focus)\n",
    "                _df_fm_is_focus_ = _df_fm_is_focus_.with_columns(pl.lit(_fm_).alias('__focus_col__'), pl.lit(_to_).alias('__alter_col__'), pl.lit(1).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('to').alias('__alter_side__'))\n",
    "                if len(_df_fm_is_focus_) > 0: \n",
    "                    _dfs_containing_focus_.append(_df_fm_is_focus_)\n",
    "                    if _bin_ not in self.bin_to_alter1s:        self.bin_to_alter1s[_bin_]       = {}\n",
    "                    if 'to'  not in self.bin_to_alter1s[_bin_]: self.bin_to_alter1s[_bin_]['to'] = set()\n",
    "                    self.bin_to_alter1s[_bin_]['to'] |= set(_df_fm_is_focus_[_to_])\n",
    "                    _found_matches_ = True\n",
    "\n",
    "                # To Is Focus\n",
    "                _df_to_is_focus_ = k_df.filter(pl.col(_to_) == self.node_focus)\n",
    "                _df_to_is_focus_ = _df_to_is_focus_.with_columns(pl.lit(_to_).alias('__focus_col__'), pl.lit(_fm_).alias('__alter_col__'), pl.lit(1).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('fm').alias('__alter_side__'))\n",
    "                if len(_df_to_is_focus_) > 0:\n",
    "                    _dfs_containing_focus_.append(_df_to_is_focus_)\n",
    "                    if _bin_ not in self.bin_to_alter1s:        self.bin_to_alter1s[_bin_]       = {}\n",
    "                    if 'fm'  not in self.bin_to_alter1s[_bin_]: self.bin_to_alter1s[_bin_]['fm'] = set()\n",
    "                    self.bin_to_alter1s[_bin_]['fm'] |= set(_df_to_is_focus_[_fm_])\n",
    "                    _found_matches_ = True\n",
    "\n",
    "                # For any shared nodes between the two sides, keep them on the 'fm' side\n",
    "                if _bin_ in self.bin_to_alter1s and 'fm' in self.bin_to_alter1s[_bin_] and 'to' in self.bin_to_alter1s[_bin_]:\n",
    "                    _shared_nodes_ = self.bin_to_alter1s[_bin_]['fm'] & self.bin_to_alter1s[_bin_]['to']\n",
    "                    if len(_shared_nodes_) > 0: self.bin_to_alter1s[_bin_]['to'] -= _shared_nodes_\n",
    "\n",
    "            # find the second alters\n",
    "            if _found_matches_:\n",
    "                _all_alter1s_ = set()\n",
    "                if 'fm' in self.bin_to_alter1s[_bin_]: _all_alter1s_ |= self.bin_to_alter1s[_bin_]['fm']\n",
    "                if 'to' in self.bin_to_alter1s[_bin_]: _all_alter1s_ |= self.bin_to_alter1s[_bin_]['to']\n",
    "                # Go through all the relationships\n",
    "                for i in range(len(self.relationships)):\n",
    "                    _fm_, _to_ = self.relationships[i]\n",
    "                    if 'fm' in self.bin_to_alter1s[_bin_]:\n",
    "                        _df_          = k_df.filter(pl.col(_fm_).is_in(self.bin_to_alter1s[_bin_]['fm']) | pl.col(_to_).is_in(self.bin_to_alter1s[_bin_]['fm']))\n",
    "                        _set_alter2s_ = (set(_df_[_fm_]) | set(_df_[_to_])) - (_all_alter1s_ | set([self.node_focus]))\n",
    "                        if len(_set_alter2s_) > 0:\n",
    "                            if _bin_ not in self.bin_to_alter2s:        self.bin_to_alter2s[_bin_]       = {}\n",
    "                            if 'fm'  not in self.bin_to_alter2s[_bin_]: self.bin_to_alter2s[_bin_]['fm'] = set()\n",
    "                            self.bin_to_alter2s[_bin_]['fm'] |= _set_alter2s_\n",
    "\n",
    "                            _df_ = k_df.filter(pl.col(_fm_).is_in(self.bin_to_alter1s[_bin_]['fm']) & pl.col(_to_).is_in(_set_alter2s_))\n",
    "                            _df_ = _df_.with_columns(pl.lit(_fm_).alias('__alter1_col__'), pl.lit(_to_).alias('__alter2_col__'), pl.lit(2).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('fm').alias('__alter_side__'))\n",
    "                            _dfs_containing_alter2s_.append(_df_)\n",
    "\n",
    "                            _df_ = k_df.filter(pl.col(_to_).is_in(self.bin_to_alter1s[_bin_]['fm']) & pl.col(_fm_).is_in(_set_alter2s_))\n",
    "                            _df_ = _df_.with_columns(pl.lit(_to_).alias('__alter1_col__'), pl.lit(_fm_).alias('__alter2_col__'), pl.lit(2).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('fm').alias('__alter_side__'))\n",
    "                            _dfs_containing_alter2s_.append(_df_)\n",
    "\n",
    "                    if 'to' in self.bin_to_alter1s[_bin_]:\n",
    "                        _df_          = k_df.filter(pl.col(_fm_).is_in(self.bin_to_alter1s[_bin_]['to']) | pl.col(_to_).is_in(self.bin_to_alter1s[_bin_]['to']))\n",
    "                        _set_alter2s_ = (set(_df_[_fm_]) | set(_df_[_to_])) - (_all_alter1s_ | set([self.node_focus]))\n",
    "                        if len(_set_alter2s_) > 0:\n",
    "                            if _bin_ not in self.bin_to_alter2s:        self.bin_to_alter2s[_bin_]       = {}\n",
    "                            if 'to'  not in self.bin_to_alter2s[_bin_]: self.bin_to_alter2s[_bin_]['to'] = set()\n",
    "                            self.bin_to_alter2s[_bin_]['to'] |= _set_alter2s_\n",
    "\n",
    "                            _df_ = k_df.filter(pl.col(_fm_).is_in(self.bin_to_alter1s[_bin_]['to']) & pl.col(_to_).is_in(_set_alter2s_))\n",
    "                            _df_ = _df_.with_columns(pl.lit(_fm_).alias('__alter1_col__'), pl.lit(_to_).alias('__alter2_col__'), pl.lit(2).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('to').alias('__alter_side__'))\n",
    "                            _dfs_containing_alter2s_.append(_df_)\n",
    "\n",
    "                            _df_ = k_df.filter(pl.col(_to_).is_in(self.bin_to_alter1s[_bin_]['to']) & pl.col(_fm_).is_in(_set_alter2s_))\n",
    "                            _df_ = _df_.with_columns(pl.lit(_to_).alias('__alter1_col__'), pl.lit(_fm_).alias('__alter2_col__'), pl.lit(2).alias('__alter_level__'), pl.lit(_bin_).alias('__bin__'), pl.lit(_timestamp_).alias('__bin_ts__'), pl.lit('to').alias('__alter_side__'))\n",
    "                            _dfs_containing_alter2s_.append(_df_)\n",
    "\n",
    "                # For any shared nodes between the two sides, keep them on the 'fm' side\n",
    "                if _bin_ in self.bin_to_alter2s and 'fm' in self.bin_to_alter2s[_bin_] and 'to' in self.bin_to_alter2s[_bin_]:\n",
    "                    _shared_nodes_ = self.bin_to_alter2s[_bin_]['fm'] & self.bin_to_alter2s[_bin_]['to']\n",
    "                    if len(_shared_nodes_) > 0: self.bin_to_alter2s[_bin_]['to'] -= _shared_nodes_\n",
    "\n",
    "            if _found_matches_: \n",
    "                self.bin_to_timestamps[_bin_] = _timestamp_\n",
    "                _bin_ += 1\n",
    "        \n",
    "        # Concatenate the pieces and parts\n",
    "        if len(_dfs_containing_focus_) > 0:   self.df_alter1s = pl.concat(_dfs_containing_focus_).unique()    # unique because we may have duplicate rows on the two sides\n",
    "        else:                                 self.df_alter1s = pl.DataFrame()\n",
    "        if len(_dfs_containing_alter2s_) > 0: self.df_alter2s = pl.concat(_dfs_containing_alter2s_).unique()  # unique because we may have duplicate rows on the two sides\n",
    "        else:                                 self.df_alter2s = pl.DataFrame()\n",
    "\n",
    "    # nodesInBin() - return the set of nodes that exist in this bin\n",
    "    def nodesInBin(self, bin):\n",
    "        nodes_in_this_bin = set()\n",
    "        if bin in self.bin_to_alter1s and 'fm' in self.bin_to_alter1s[bin]: nodes_in_this_bin |= self.bin_to_alter1s[bin]['fm']\n",
    "        if bin in self.bin_to_alter1s and 'to' in self.bin_to_alter1s[bin]: nodes_in_this_bin |= self.bin_to_alter1s[bin]['to']\n",
    "        if bin in self.bin_to_alter2s and 'fm' in self.bin_to_alter2s[bin]: nodes_in_this_bin |= self.bin_to_alter2s[bin]['fm']\n",
    "        if bin in self.bin_to_alter2s and 'to' in self.bin_to_alter2s[bin]: nodes_in_this_bin |= self.bin_to_alter2s[bin]['to']\n",
    "        return nodes_in_this_bin\n",
    "\n",
    "    # nodesExistInOtherBins() - return the set of nodes that exist in this bin AND'ed with all the other bins\n",
    "    def nodesExistsInOtherBins(self, bin):\n",
    "        nodes_in_this_bin = self.nodesInBin(bin)\n",
    "        all_other_bins    = set()\n",
    "        for _bin_ in (self.bin_to_alter1s.keys()|self.bin_to_alter2s.keys()):\n",
    "            if _bin_ == bin: continue\n",
    "            all_other_bins |= self.nodesInBin( _bin_)\n",
    "        return nodes_in_this_bin & all_other_bins\n",
    "\n",
    "    #\n",
    "    # svgSketch() - produce a basic sketch of how many nodes would occur where in the final rendering...\n",
    "    #\n",
    "    def svgSketch(self):\n",
    "        w_usable, h_usable = self.w - 2*self.x_ins, self.h - 2*self.y_ins\n",
    "        y_mid              = self.y_ins + h_usable/2\n",
    "        bin_to_x           = {}\n",
    "        bin_inter_dist     = w_usable/(len(self.bin_to_alter1s) - 1)\n",
    "        for _bin_ in self.bin_to_alter1s: bin_to_x[_bin_] = self.x_ins + _bin_*bin_inter_dist\n",
    "        _y_diff_alter1s_, _y_diff_alter2s_ = h_usable/8, 2*h_usable/8\n",
    "\n",
    "        svg = [f'<svg x=\"0\" y=\"0\" width=\"{self.w}\" height=\"{self.h}\">']\n",
    "        svg.append(f'<rect x=\"0\" y=\"0\" width=\"{self.w}\" height=\"{self.h}\" fill=\"{self.rt_self.co_mgr.getTVColor(\"background\",\"default\")}\" />')\n",
    "\n",
    "        svg.append(f'<line x1=\"{self.x_ins}\" y1=\"{y_mid}\" x2=\"{self.x_ins+w_usable}\" y2=\"{y_mid}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"4\" />')        \n",
    "        for _bin_ in bin_to_x:\n",
    "            _x_ = bin_to_x[_bin_]\n",
    "            svg.append(f'<line x1=\"{_x_}\" y1=\"{self.y_ins}\" x2=\"{_x_}\" y2=\"{self.y_ins + h_usable}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" />')\n",
    "            svg.append(f'<circle cx=\"{_x_}\" cy=\"{y_mid}\" r=\"5\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" fill=\"{self.rt_self.co_mgr.getTVColor('data','default')}\" />')\n",
    "            _date_str_ = self.bin_to_timestamps[_bin_].strftime(self.__dateFormat__())\n",
    "            svg.append(self.rt_self.svgText(_date_str_, _x_-2, self.y_ins + h_usable + 4, rt.co_mgr.getTVColor('axis','minor'), anchor='begin', rotation=270))\n",
    "            if _bin_ in self.bin_to_alter1s and 'fm' in self.bin_to_alter1s[_bin_]: # top of the image\n",
    "                _y_         = y_mid - _y_diff_alter1s_\n",
    "                _num_nodes_ = len(self.bin_to_alter1s[_bin_]['fm'])\n",
    "                svg.append(self.rt_self.svgText(str(_num_nodes_), _x_+2, _y_ + 4, 'black', anchor='begin', rotation=90))\n",
    "                if _bin_ in self.bin_to_alter2s and 'fm' in self.bin_to_alter2s[_bin_]:\n",
    "                    _y_         = y_mid - _y_diff_alter2s_\n",
    "                    _num_nodes_ = len(self.bin_to_alter2s[_bin_]['fm'])\n",
    "                    svg.append(self.rt_self.svgText(str(_num_nodes_), _x_+2, _y_ + 4, 'black', anchor='begin', rotation=90))\n",
    "            if _bin_ in self.bin_to_alter1s and 'to' in self.bin_to_alter1s[_bin_]: # bottom of the image\n",
    "                _y_         = y_mid + _y_diff_alter1s_\n",
    "                _num_nodes_ = len(self.bin_to_alter1s[_bin_]['to'])\n",
    "                svg.append(self.rt_self.svgText(str(_num_nodes_), _x_+2, _y_ + 4, 'black', anchor='begin', rotation=90))\n",
    "                if _bin_ in self.bin_to_alter2s and 'to' in self.bin_to_alter2s[_bin_]:\n",
    "                    _y_         = y_mid + _y_diff_alter2s_\n",
    "                    _num_nodes_ = len(self.bin_to_alter2s[_bin_]['to'])\n",
    "                    svg.append(self.rt_self.svgText(str(_num_nodes_), _x_+2, _y_ + 4, 'black', anchor='begin', rotation=90))\n",
    "\n",
    "        svg.append('</svg>')\n",
    "        return ''.join(svg)\n",
    "\n",
    "    def __dateFormat__(self):\n",
    "        if   'd' in self.every: return '%Y-%m-%d'\n",
    "        elif 'h' in self.every: return '%Y-%m-%d %H'\n",
    "        else:                   return '%Y-%m-%d %H:%M'\n",
    "\n",
    "    def packable(self, nodes, x, y, y_max, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer):\n",
    "        node_to_xy = {}\n",
    "        h = abs(y - y_max)\n",
    "        n = len(nodes)\n",
    "        if n > 0:\n",
    "            # single strand\n",
    "            r = ((h - (n-1)*circle_inter_d)/n)/2.0\n",
    "            if r >= r_min:\n",
    "                r          = min(r, r_pref)\n",
    "                left_overs = 0\n",
    "                out_of     = n\n",
    "                for _node_i_ in range(len(nodes)):\n",
    "                    _node_ = nodes[-(_node_i_+1)]\n",
    "                    #if mul == -1: _node_ = nodes[_node_i_]\n",
    "                    #else:         _node_ = nodes[-(_node_i_+1)]\n",
    "                    node_to_xy[_node_] = (x, y+mul*r, r)\n",
    "                    y += mul*(2*r+circle_inter_d)\n",
    "            else:\n",
    "                # m-strands\n",
    "                m_max = w_max / (2*r_min+circle_spacer)\n",
    "                for m in range(2,int(m_max)+1):\n",
    "                    r = (h - (n//m)*circle_inter_d)/(n//m)/2.0\n",
    "                    if r >= r_min:\n",
    "                        r = min(r, r_pref)\n",
    "                        total_width_required = m*(2*r) + (m-1)*circle_spacer\n",
    "                        if total_width_required > w_max: continue\n",
    "                        _col_, nodes_in_this_column = 0, 0\n",
    "                        nodes_per_column = n//m\n",
    "                        left_overs       = n - nodes_per_column*m\n",
    "                        out_of           = nodes_per_column\n",
    "                        if left_overs > 0: m += 1\n",
    "                        total_width_required = m*(2*r) + (m-1)*circle_spacer\n",
    "                        _columns_ = []\n",
    "                        _column_  = []\n",
    "                        for _node_ in nodes:\n",
    "                            _x_col_ = x - total_width_required/2.0 + _col_*(2*r+circle_spacer) + r\n",
    "                            _y_row_ = y+mul*r+mul*nodes_in_this_column*(2*r+circle_inter_d)                        \n",
    "                            _column_.append((_x_col_, _y_row_))\n",
    "                            nodes_in_this_column += 1\n",
    "                            if nodes_in_this_column >= nodes_per_column: \n",
    "                                _columns_.append(_column_)\n",
    "                                _column_  = []\n",
    "                                _col_, nodes_in_this_column = _col_+1, 0\n",
    "                        if len(_column_) > 0: _columns_.append(_column_)\n",
    "                        # Allocate the across first... and then down...\n",
    "                        _xi_, _yi_ = 0, 0\n",
    "                        for _node_i_ in range(len(nodes)):\n",
    "                            if mul == -1: _node_ = nodes[len(nodes) - 1 - _node_i_]\n",
    "                            else:         _node_ = nodes[_node_i_]\n",
    "                            if _yi_ >= len(_columns_[_xi_]): _yi_, _xi_ = _yi_ + 1, 0\n",
    "                            _xy_ = _columns_[_xi_][_yi_]\n",
    "                            node_to_xy[_node_] = (_xy_[0], _xy_[1], r) \n",
    "                            _xi_ += 1\n",
    "                            if _xi_ >= len(_columns_): _yi_, _xi_ = _yi_ + 1, 0\n",
    "                        break\n",
    "\n",
    "        if len(node_to_xy) == 0: return None, None, None\n",
    "        return node_to_xy, left_overs, out_of\n",
    "\n",
    "    def renderAlter(self, nodes, befores, afters, x, y, y_max, w_max, mul=1, r_min=4.0, r_pref=7.0, circle_inter_d=2.0, circle_spacer=3, h_collapsed_sections=16):\n",
    "        xmin, ymin, xmax, ymax = x-r_pref-circle_inter_d, y-r_pref-circle_inter_d, x+r_pref+circle_inter_d, y+r_pref+circle_inter_d\n",
    "        # Create the started/stopped triangles for a single node\n",
    "        def svgTriangle(x,y,r,s,d):\n",
    "            nonlocal xmin, ymin, xmax, ymax\n",
    "            p0      = (x+d*(r/2.0), y)\n",
    "            p1      = (x+d*(r+s),   y+r)\n",
    "            p2      = (x+d*(r+s),   y-r)\n",
    "            for _pt_ in [p0,p1,p2]: xmin, ymin, xmax, ymax = min(xmin, _pt_[0]), min(ymin, _pt_[1]), max(xmax, _pt_[0]), max(ymax, _pt_[1])\n",
    "            _path_  = f'M {p0[0]} {p0[1]} L {p1[0]} {p1[1]} L {p2[0]} {p2[1]} Z'\n",
    "            _color_ = '#ff0000' if d == 1 else '#0000ff'\n",
    "            return f'<path d=\"{_path_}\" stroke=\"none\" fill=\"{_color_}\" />'\n",
    "        # Create the started/stopped triangles for the clouds\n",
    "        def svgCloudTriangle(x,y,offset,s,d):\n",
    "            nonlocal xmin, ymin, xmax, ymax\n",
    "            p0      = (x+d*(offset), y)\n",
    "            p1      = (x+d*(offset+s),   y+s)\n",
    "            p2      = (x+d*(offset+s),   y-s)\n",
    "            for _pt_ in [p0,p1,p2]: xmin, ymin, xmax, ymax = min(xmin, _pt_[0]), min(ymin, _pt_[1]), max(xmax, _pt_[0]), max(ymax, _pt_[1])\n",
    "            _path_  = f'M {p0[0]} {p0[1]} L {p1[0]} {p1[1]} L {p2[0]} {p2[1]} Z'\n",
    "            _color_ = '#d3494e' if d == 1 else '#658cbb'\n",
    "            return f'<path d=\"{_path_}\" stroke=\"none\" fill=\"{_color_}\" />'\n",
    "        # Place the nodes onto the canvas\n",
    "        def placeNodeToXYs(n2xy):\n",
    "            nonlocal xmin, ymin, xmax, ymax\n",
    "            for _node_, _xyr_ in n2xy.items():\n",
    "                svg.append(f'<circle cx=\"{_xyr_[0]}\" cy=\"{_xyr_[1]}\" r=\"{_xyr_[2]}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.75\" fill=\"none\"/>')\n",
    "                xmin, ymin, xmax, ymax = min(xmin, _xyr_[0]-_xyr_[2]), min(ymin, _xyr_[1]-_xyr_[2]), max(xmax, _xyr_[0]+_xyr_[2]), max(ymax, _xyr_[1]+_xyr_[2])\n",
    "                if _node_ not in befores: svg.append(svgTriangle(_xyr_[0], _xyr_[1], _xyr_[2], circle_spacer/2, -1))\n",
    "                if _node_ not in afters:  svg.append(svgTriangle(_xyr_[0], _xyr_[1], _xyr_[2], circle_spacer/2,  1))\n",
    "        # Render the summarization cloud\n",
    "        def summarizationCloud(n, y_cloud, ltriangle, rtriangle):\n",
    "            nonlocal xmin, ymin, xmax, ymax\n",
    "            svg.append(self.rt_self.iconCloud(x,y_cloud, fg='#e0e0e0', bg='#e0e0e0'))\n",
    "            if ltriangle: svg.append(svgCloudTriangle(x, y_cloud, 16, 6, -1))\n",
    "            if rtriangle: svg.append(svgCloudTriangle(x, y_cloud, 16, 6,  1))\n",
    "            svg.append(self.rt_self.svgText(str(n), x, y_cloud + 4, 'black', anchor='middle'))\n",
    "            xmin, ymin, xmax, ymax = min(xmin, x-16), min(ymin, y_cloud-6), max(xmax, x+16), max(ymax, y_cloud+6)\n",
    "        # Render the main SVG ... geometry and some guide lines (for reference/debug, commented out now)\n",
    "        h       = abs(y_max - y)\n",
    "        svg     = []\n",
    "        #svg.append(f'<line x1=\"{x-w_max/2.0}\" y1=\"{y}\"     x2=\"{x+w_max/2.0}\" y2=\"{y}\"     stroke=\"#0000ff\" stroke-width=\"4.0\" />') # render the \"start\"\n",
    "        #svg.append(f'<line x1=\"{x-w_max/2.0}\" y1=\"{y_max}\" x2=\"{x+w_max/2.0}\" y2=\"{y_max}\" stroke=\"#ff0000\" stroke-width=\"0.8\" />')\n",
    "        #svg.append(f'<line x1=\"{x}\"           y1=\"{0}\"     x2=\"{x}\"           y2=\"{384}\"   stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" />')\n",
    "        # Make sure there are nodes...\n",
    "        if len(nodes) > 0:\n",
    "            # Sort the nodes into the 4 categories\n",
    "            nodes_sorter = []\n",
    "            nodes_isolated, nodes_started, nodes_stopped, nodes_continuous = [], [], [], []\n",
    "            for _node_ in nodes:\n",
    "                if   _node_ in befores and _node_ in afters: nodes_sorter.append((3, _node_)), nodes_continuous.append(_node_)\n",
    "                elif _node_ in befores:                      nodes_sorter.append((2, _node_)), nodes_stopped   .append(_node_)\n",
    "                elif _node_ in afters:                       nodes_sorter.append((1, _node_)), nodes_started   .append(_node_)\n",
    "                else:                                        nodes_sorter.append((0, _node_)), nodes_isolated  .append(_node_)\n",
    "            nodes_sorter  = sorted(nodes_sorter)\n",
    "            nodes_ordered = [x[1] for x in nodes_sorter]\n",
    "\n",
    "            # Try putting them all down first... which won't work for any non-trivial number of nodes\n",
    "            node_to_xy, leftovers, out_of = self.packable(nodes_ordered, x, y, y_max, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer)\n",
    "            if node_to_xy is not None:\n",
    "                placeNodeToXYs(node_to_xy) # no summarization necessary\n",
    "            else:\n",
    "                top_adjust = h_collapsed_sections if mul == 1 else -h_collapsed_sections\n",
    "                node_to_xy, leftovers, out_of = self.packable(nodes_started+nodes_stopped+nodes_continuous, x, y, y_max-top_adjust, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer)\n",
    "                if node_to_xy is not None:\n",
    "                    placeNodeToXYs(node_to_xy) # summarize isolated nodes only\n",
    "                    y_off = ymin if mul == 1 else ymax\n",
    "                    summarizationCloud(len(nodes_isolated), y_off+mul*0.5*h_collapsed_sections, True, True)\n",
    "                else:\n",
    "                    top_adjust = 2*h_collapsed_sections if mul == 1 else -2*h_collapsed_sections\n",
    "                    node_to_xy, leftovers, out_of = self.packable(nodes_started              +nodes_continuous, x, y, y_max-top_adjust, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer)\n",
    "                    if node_to_xy is not None:\n",
    "                        placeNodeToXYs(node_to_xy) # summarize isolated nodes and nodes_stopped\n",
    "                        y_off = ymax if mul == 1 else ymin\n",
    "                        summarizationCloud(len(nodes_stopped),  y_off+mul*0.5*h_collapsed_sections, False,  True)\n",
    "                        summarizationCloud(len(nodes_isolated), y_off+mul*1.5*h_collapsed_sections, True,   True)\n",
    "                    else:\n",
    "                        node_to_xy, leftovers, out_of = self.packable(nodes_stopped+nodes_continuous, x, y, y_max-top_adjust, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer)\n",
    "                        if node_to_xy is not None:\n",
    "                            placeNodeToXYs(node_to_xy) # summarize isolated nodes and nodes_started\n",
    "                            y_off = ymax if mul == 1 else ymin\n",
    "                            summarizationCloud(len(nodes_started),   y_off+mul*0.5*h_collapsed_sections, True,  False)\n",
    "                            summarizationCloud(len(nodes_isolated),  y_off+mul*1.5*h_collapsed_sections, True,  True)\n",
    "                        else:\n",
    "                            top_adjust = 3*h_collapsed_sections if mul == 1 else -3*h_collapsed_sections\n",
    "                            node_to_xy, leftovers, out_of = self.packable(nodes_continuous, x, y, y_max-top_adjust, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer)\n",
    "                            if node_to_xy is not None:\n",
    "                                placeNodeToXYs(node_to_xy) # summarize everyting but the continuous nodes (nodes seen in both directions)\n",
    "                                y_off = ymax if mul == 1 else ymin\n",
    "                                summarizationCloud(len(nodes_started),   y_off+mul*0.5*h_collapsed_sections, True,  False)\n",
    "                                summarizationCloud(len(nodes_stopped),   y_off+mul*1.5*h_collapsed_sections, False, True)\n",
    "                                summarizationCloud(len(nodes_isolated),  y_off+mul*2.5*h_collapsed_sections, True,  True)\n",
    "                            else:\n",
    "                                # everything is summarized :(\n",
    "                                summarizationCloud(len(nodes_continuous), y+mul*0.5*h_collapsed_sections, False,  False)\n",
    "                                summarizationCloud(len(nodes_started),    y+mul*1.5*h_collapsed_sections, True,   False)\n",
    "                                summarizationCloud(len(nodes_stopped),    y+mul*2.5*h_collapsed_sections, False,  True)\n",
    "                                summarizationCloud(len(nodes_isolated),   y+mul*3.5*h_collapsed_sections, True,   True)\n",
    "        \n",
    "        xmin, ymin, xmax, ymax = xmin - r_pref, ymin - r_pref, xmax + r_pref, ymax + r_pref\n",
    "        # svg.append(f'<rect x=\"{xmin}\" y=\"{ymin}\" width=\"{xmax-xmin}\" height=\"{ymax-ymin}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "        return ''.join(svg), (xmin, ymin, xmax, ymax)\n",
    "\n",
    "#\n",
    "# spreadLines()\n",
    "#\n",
    "sl = spreadLines(rt, df, [('sip','dip')], '172.30.0.4', every=\"4h\", h=384)\n",
    "rt.tile([sl.svgSketch()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rt.histogram(df, bin_by='sip', count_by='dip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sl = spreadLines(rt, df, [('sip','dip')], '172.10.0.6', every=\"1h\", h=384) # highest out-degree node\n",
    "#rt.tile([sl.svgSketch()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rt.histogram(df, bin_by='dip', count_by='sip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sl = spreadLines(rt, df, [('sip','dip')], '172.0.0.1', every=\"1h\", h=384) # highest in-degree node\n",
    "rt.tile([sl.svgSketch()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def renderBin(self, bin, w_bin_min=16, h_bin=384, r_min=3.0, r_pref=5.0):\n",
    "    svgTriangle = lambda x: f'<path d=\"M {x[0][0]} {x[0][1]} L {x[1][0]} {x[1][1]} L {x[2][0]} {x[2][1]} Z\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" fill=\"{self.rt_self.co_mgr.getTVColor(\"data\",\"default\")}\" />'\n",
    "    nodes_in_bin             = self.nodesInBin(bin)\n",
    "    nodes_also_in_other_bins = self.nodesExistsInOtherBins(bin)\n",
    "\n",
    "    svg = [f'<circle cx=\"0\" cy=\"0\" r=\"{r_pref}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" fill=\"{self.rt_self.co_mgr.getTVColor(\"data\",\"default\")}\" />']\n",
    "\n",
    "    alter1_h_alloc = h_bin/6\n",
    "    alter2_h_alloc = h_bin/6\n",
    "\n",
    "    y = 0 - 2*r_pref \n",
    "    if 'fm' in self.bin_to_alter1s[bin]:\n",
    "        if len(self.bin_to_alter1s[bin]['fm']) * r_min < alter1_h_alloc:\n",
    "            r = alter1_h_alloc/len(self.bin_to_alter1s[bin]['fm'])/2\n",
    "            if r < r_min:  r = r_min\n",
    "            if r > r_pref: r = r_pref\n",
    "            for _node_ in self.bin_to_alter1s[bin]['fm']:\n",
    "                svg.append(f'<circle cx=\"0\" cy=\"{y}\" r=\"{r}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" fill=\"none\" />')\n",
    "                if _node_ not in nodes_also_in_other_bins: svg.append(svgTriangle([( r,y), ( 2*r,y-r), ( 2*r,y+r)])), svg.append(svgTriangle([(-r,y), (-2*r,y+r), (-2*r,y-r)]))\n",
    "                y -= 2*r\n",
    "\n",
    "    y = 0 + 2*r_pref\n",
    "    if 'to' in self.bin_to_alter1s[bin]:\n",
    "        if len(self.bin_to_alter1s[bin]['to']) * r_min < alter1_h_alloc:\n",
    "            r = alter1_h_alloc/len(self.bin_to_alter1s[bin]['fm'])/2\n",
    "            if r < r_min:  r = r_min\n",
    "            if r > r_pref: r = r_pref\n",
    "            for _node_ in self.bin_to_alter1s[bin]['to']:\n",
    "                svg.append(f'<circle cx=\"0\" cy=\"{y}\" r=\"{r}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"1.0\" fill=\"none\" />')\n",
    "                if _node_ not in nodes_also_in_other_bins: svg.append(svgTriangle([(r,y), (2*r, y-r), (2*r, y+r)])), svg.append(svgTriangle([(-r,y),(-2*r,y+r), (-2*r,y-r)]))\n",
    "                y += 2*r\n",
    "\n",
    "    return ''.join(svg), w_bin_min\n",
    "\n",
    "_svg_, _bin_w_ = renderBin(sl, 2)\n",
    "_hdr_ = f'<svg x=\"0\" y=\"0\" width=\"{384}\" height=\"{384}\" viewBox=\"-{384/2} -{384/2} {384} {384}\">'\n",
    "_bg_  = f'<rect x=\"{-384/2}\" y=\"{-384/2}\" width=\"{384}\" height=\"{384}\" fill=\"{rt.co_mgr.getTVColor(\"background\",\"default\")}\" />'\n",
    "_ftr_ = '</svg>'\n",
    "#rt.tile([_hdr_ + _bg_ + _svg_ + _ftr_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# packable... works... but does the nodes in the wrong orientation...\n",
    "def WORKS_packable(self, nodes, x, y, y_max, w_max, mul, r_min, r_pref, circle_inter_d, circle_spacer):\n",
    "    node_to_xy = {}\n",
    "    h = abs(y - y_max)\n",
    "    n = len(nodes)\n",
    "    if n > 0:\n",
    "        # single strand\n",
    "        r = ((h - (n-1)*circle_inter_d)/n)/2.0\n",
    "        if r >= r_min:\n",
    "            r          = min(r, r_pref)\n",
    "            left_overs = 0\n",
    "            out_of     = n\n",
    "            for _node_ in nodes:\n",
    "                node_to_xy[_node_] = (x, y+mul*r, r)\n",
    "                y += mul*(2*r+circle_inter_d)\n",
    "        else:\n",
    "            # m-strands\n",
    "            m_max = w_max / (2*r_min+circle_spacer)\n",
    "            for m in range(2,int(m_max)+1):\n",
    "                r = (h - (n//m)*circle_inter_d)/(n//m)/2.0\n",
    "                if r >= r_min:\n",
    "                    r = min(r, r_pref)\n",
    "                    total_width_required = m*(2*r) + (m-1)*circle_spacer\n",
    "                    if total_width_required > w_max: continue\n",
    "                    _col_, nodes_in_this_column = 0, 0\n",
    "                    nodes_per_column = n//m\n",
    "                    left_overs       = n - nodes_per_column*m\n",
    "                    out_of           = nodes_per_column\n",
    "                    if left_overs > 0: m += 1\n",
    "                    total_width_required = m*(2*r) + (m-1)*circle_spacer\n",
    "                    for _node_ in nodes:\n",
    "                        _x_col_ = x - total_width_required/2.0 + _col_*(2*r+circle_spacer) + r\n",
    "                        _y_row_ = y+mul*r+mul*nodes_in_this_column*(2*r+circle_inter_d)\n",
    "                        node_to_xy[_node_] = (_x_col_, _y_row_, r)\n",
    "                        nodes_in_this_column += 1\n",
    "                        if nodes_in_this_column >= nodes_per_column: _col_, nodes_in_this_column = _col_+1, 0\n",
    "                    break\n",
    "    if len(node_to_xy) == 0: return None, None, None\n",
    "    return node_to_xy, left_overs, out_of\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrates various configurations of a single alter render\n",
    "_tiles_ = []\n",
    "for _num_of_nodes_ in range(500, 1500, 300):\n",
    "    _hdr_ = f'<svg x=\"0\" y=\"0\" width=\"{384}\" height=\"{384}\">'\n",
    "    _bg_  = f'<rect x=\"0\" y=\"0\" width=\"{384}\" height=\"{384}\" fill=\"{rt.co_mgr.getTVColor(\"background\",\"default\")}\" />'\n",
    "    _ftr_ = '</svg>'\n",
    "    _nodes_, _befores_, _afters_ = set(), set(), set()\n",
    "    for i in range(_num_of_nodes_):\n",
    "        _nodes_.add(i)\n",
    "        if random.random() < 0.3: _befores_.add(i)\n",
    "        if random.random() < 0.3: _afters_.add(i)\n",
    "    _svg_, _bounds_ = sl.renderAlter(_nodes_, _befores_, _afters_, 175, 300, 200, 128, mul=-1)\n",
    "    xmin, ymin, xmax, ymax = _bounds_\n",
    "    _box_ = f'<rect x=\"{xmin}\" y=\"{ymin}\" width=\"{xmax-xmin}\" height=\"{ymax-ymin}\" stroke=\"{rt.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"10\" />'\n",
    "    _tiles_.append(_hdr_ + _bg_ + _svg_ + _box_ + _ftr_)\n",
    "    _svg_, _bounds_ = sl.renderAlter(_nodes_, _befores_, _afters_, 175, 100, 300,  64, mul= 1)\n",
    "    xmin, ymin, xmax, ymax = _bounds_\n",
    "    _box_ = f'<rect x=\"{xmin}\" y=\"{ymin}\" width=\"{xmax-xmin}\" height=\"{ymax-ymin}\" stroke=\"{rt.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"10\" />'\n",
    "    _tiles_.append(_hdr_ + _bg_ + _svg_ + _box_ + _ftr_)\n",
    "#rt.table(_tiles_, per_row=4, spacer=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renderBin(self, \n",
    "              bin,                        # bin index\n",
    "              x,                          # center of the bin \n",
    "              y,                          # center of the bin\n",
    "              max_w,                      # max width of the bin (i.e., the max width of any of the alters)\n",
    "              max_h,                      # max height of the bin (halfed in each direction from y)\n",
    "              r_min                = 4.0, \n",
    "              r_pref               = 7.0, \n",
    "              circle_inter_d       = 2.0, \n",
    "              circle_spacer        = 3,\n",
    "              alter_separation_h   = 48, \n",
    "              h_collapsed_sections = 16):\n",
    "    _all_nodes_in_this_bin = self.nodesInBin(bin)\n",
    "    _nodes_in_other_bins_  = self.nodesExistsInOtherBins(bin)\n",
    "    _befores_, _afters_    = set(), set()\n",
    "    for i in range(bin):                                       _befores_ |= self.nodesInBin(i)\n",
    "    for i in range(bin+1, len(self.bin_to_timestamps.keys())): _afters_  |= self.nodesInBin(i)\n",
    "    svg         = [f'<circle cx=\"{x}\" cy=\"{y}\" r=\"{r_pref}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"minor\")}\" stroke-width=\"0.4\" fill=\"{self.rt_self.co_mgr.getTVColor(\"data\",\"default\")}\" />']\n",
    "    max_alter_h = max_h/5.0\n",
    "    # Approximations of the alters\n",
    "    #svg.append(f'<rect x=\"{x-max_w/2}\" y=\"{y-r_pref-max_alter_h}\"                      width=\"{max_w}\" height=\"{max_alter_h}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "    #svg.append(f'<rect x=\"{x-max_w/2}\" y=\"{y-r_pref-2*max_alter_h-alter_separation_h}\" width=\"{max_w}\" height=\"{max_alter_h}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "    #svg.append(f'<rect x=\"{x-max_w/2}\" y=\"{y+r_pref}\"                                  width=\"{max_w}\" height=\"{max_alter_h}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "    #svg.append(f'<rect x=\"{x-max_w/2}\" y=\"{y+r_pref+  max_alter_h+alter_separation_h}\" width=\"{max_w}\" height=\"{max_alter_h}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "\n",
    "    # Actual alters\n",
    "    if 'fm' in self.bin_to_alter1s[bin]:\n",
    "        _svg_, _bounds_ = self.renderAlter(self.bin_to_alter1s[bin]['fm'], _befores_, _afters_, x, y-r_pref-2*circle_inter_d, y-r_pref-max_alter_h,                  max_w, -1, r_min, r_pref, circle_inter_d, circle_spacer, h_collapsed_sections)\n",
    "        svg.append(_svg_)\n",
    "        alter1s_fm_bounds = _bounds_\n",
    "    else:\n",
    "        alter1s_fm_bounds = None\n",
    "        _bounds_          = (x-r_pref, y-r_pref-2*circle_inter_d-5, x+r_pref, y-r_pref-2*circle_inter_d)\n",
    "    #svg.append(f'<rect x=\"{_bounds_[0]}\" y=\"{_bounds_[1]}\" width=\"{_bounds_[2]-_bounds_[0]}\" height=\"{_bounds_[3]-_bounds_[1]}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "\n",
    "    if 'fm' in self.bin_to_alter2s[bin]:\n",
    "        _svg_, _bounds_ = self.renderAlter(self.bin_to_alter2s[bin]['fm'], _befores_, _afters_, x, _bounds_[1]-alter_separation_h, _bounds_[1]-alter_separation_h-max_alter_h, max_w, -1, r_min, r_pref, circle_inter_d, circle_spacer, h_collapsed_sections)\n",
    "        svg.append(_svg_)\n",
    "        alter2s_fm_bounds = _bounds_\n",
    "        #svg.append(f'<rect x=\"{_bounds_[0]}\" y=\"{_bounds_[1]}\" width=\"{_bounds_[2]-_bounds_[0]}\" height=\"{_bounds_[3]-_bounds_[1]}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "    else:\n",
    "        alter2s_fm_bounds = None\n",
    "\n",
    "    if 'to' in self.bin_to_alter1s[bin]:\n",
    "        _svg_, _bounds_ = self.renderAlter(self.bin_to_alter1s[bin]['to'], _befores_, _afters_, x, y+r_pref+2*circle_inter_d, y+r_pref+2*circle_inter_d+max_alter_h, max_w,  1, r_min, r_pref, circle_inter_d, circle_spacer, h_collapsed_sections)\n",
    "        svg.append(_svg_)\n",
    "        alter1s_to_bounds = _bounds_\n",
    "    else: \n",
    "        _bounds_ = (x-r_pref, y+r_pref+2*circle_inter_d, x+r_pref, y+r_pref+2*circle_inter_d+5)\n",
    "        alter1s_to_bounds = None\n",
    "    #svg.append(f'<rect x=\"{_bounds_[0]}\" y=\"{_bounds_[1]}\" width=\"{_bounds_[2]-_bounds_[0]}\" height=\"{_bounds_[3]-_bounds_[1]}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "\n",
    "    if 'to' in self.bin_to_alter2s[bin]:\n",
    "        _svg_, _bounds_ = self.renderAlter(self.bin_to_alter2s[bin]['to'], _befores_, _afters_, x, _bounds_[3]+alter_separation_h, _bounds_[3]+alter_separation_h+max_alter_h, max_w, 1, r_min, r_pref, circle_inter_d, circle_spacer, h_collapsed_sections)\n",
    "        svg.append(_svg_)\n",
    "        alter2s_to_bounds = _bounds_\n",
    "        # svg.append(f'<rect x=\"{_bounds_[0]}\" y=\"{_bounds_[1]}\" width=\"{_bounds_[2]-_bounds_[0]}\" height=\"{_bounds_[3]-_bounds_[1]}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"0.8\" fill=\"none\" rx=\"{r_pref}\" />')\n",
    "    else:\n",
    "        alter2s_to_bounds = None\n",
    "\n",
    "    # Calculate the outline of the bin\n",
    "    overall_w = 2*r_pref\n",
    "    if alter1s_fm_bounds is not None: overall_w = max(overall_w, alter1s_fm_bounds[2]-alter1s_fm_bounds[0])\n",
    "    if alter1s_to_bounds is not None: overall_w = max(overall_w, alter1s_to_bounds[2]-alter1s_to_bounds[0])\n",
    "    if alter2s_fm_bounds is not None: overall_w = max(overall_w, alter2s_fm_bounds[2]-alter2s_fm_bounds[0])\n",
    "    if alter2s_to_bounds is not None: overall_w = max(overall_w, alter2s_to_bounds[2]-alter2s_to_bounds[0])\n",
    "    narrow_w = overall_w - 2*r_pref\n",
    "    _amt_    = 2*r_pref\n",
    "    d_array  = [f'M {x-overall_w/2.0} {y}']\n",
    "    if alter1s_to_bounds is None:\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y+  _amt_}  C {x-overall_w/2.0} {y+2*_amt_} {x-overall_w/2.0} {y+2*_amt_} {x-narrow_w/2.0}  {y+2*_amt_}')\n",
    "        d_array.append(f'L {x+narrow_w/2.0}  {y+2*_amt_}  C {x+overall_w/2.0} {y+2*_amt_} {x+overall_w/2.0} {y+2*_amt_} {x+overall_w/2.0} {y+  _amt_}')\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y}')\n",
    "    elif alter2s_to_bounds is None:\n",
    "        ah = alter1s_to_bounds[3]-alter1s_to_bounds[1]-2*_amt_\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y+ah+  _amt_}  C {x-overall_w/2.0} {y+ah+2*_amt_} {x-overall_w/2.0} {y+ah+2*_amt_} {x-narrow_w/2.0}  {y+ah+2*_amt_}')\n",
    "        d_array.append(f'L {x+narrow_w/2.0}  {y+ah+2*_amt_}  C {x+overall_w/2.0} {y+ah+2*_amt_} {x+overall_w/2.0} {y+ah+2*_amt_} {x+overall_w/2.0} {y+ah+  _amt_}')\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y}')\n",
    "    else:\n",
    "        ah  = alter1s_to_bounds[3]-alter1s_to_bounds[1]-2*_amt_\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y+ah+  _amt_}  C {x-overall_w/2.0} {y+ah+2*_amt_} {x-overall_w/2.0} {y+ah+2*_amt_} {x-narrow_w/2.0}  {y+ah+2*_amt_}')\n",
    "        a2y  = alter2s_to_bounds[1] + 2*r_pref\n",
    "        d_array.append(f'L {x-narrow_w/2.0}  {a2y}           C {x-overall_w/2.0} {a2y}          {x-overall_w/2.0} {a2y}          {x-overall_w/2.0} {a2y+2*_amt_}')\n",
    "        a2y2 = alter2s_to_bounds[3] - 2*_amt_\n",
    "        d_array.append(f'L {x-overall_w/2.0} {a2y2}')\n",
    "        d_array.append(f'C {x-overall_w/2.0} {a2y2+2*_amt_} {x-overall_w/2.0} {a2y2+2*_amt_} {x-narrow_w/2.0}  {a2y2+2*_amt_}')\n",
    "        d_array.append(f'L {x+narrow_w/2.0}  {a2y2+2*_amt_}  C {x+overall_w/2.0} {a2y2+2*_amt_} {x+overall_w/2.0} {a2y2+2*_amt_} {x+overall_w/2.0} {a2y2}')\n",
    "        d_array.append(f'L {x+overall_w/2.0} {a2y +2*_amt_}  C {x+overall_w/2.0} {a2y}          {x+overall_w/2.0} {a2y}          {x+narrow_w/2.0}  {a2y}')\n",
    "        d_array.append(f'L {x+narrow_w/2.0}  {y+ah+2*_amt_}  C {x+overall_w/2.0} {y+ah+2*_amt_} {x+overall_w/2.0} {y+ah+2*_amt_} {x+overall_w/2.0} {y+ah+  _amt_}')\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y}')\n",
    "\n",
    "    if alter1s_fm_bounds is None:\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y-  _amt_}  C {x+overall_w/2.0} {y-2*_amt_} {x+overall_w/2.0} {y-2*_amt_} {x+narrow_w/2.0}  {y-2*_amt_}')\n",
    "        d_array.append(f'L {x-narrow_w/2.0}  {y-2*_amt_}  C {x-overall_w/2.0} {y-2*_amt_} {x-overall_w/2.0} {y-2*_amt_} {x-overall_w/2.0} {y-  _amt_}')\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y}')\n",
    "    elif alter2s_fm_bounds is None:\n",
    "        ah = alter1s_fm_bounds[3]-alter1s_fm_bounds[1]-2*_amt_\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y-ah-  _amt_}  C {x+overall_w/2.0} {y-ah-2*_amt_} {x+overall_w/2.0} {y-ah-2*_amt_} {x+narrow_w/2.0}  {y-ah-2*_amt_}')\n",
    "        d_array.append(f'L {x-narrow_w/2.0}  {y-ah-2*_amt_}  C {x-overall_w/2.0} {y-ah-2*_amt_} {x-overall_w/2.0} {y-ah-2*_amt_} {x-overall_w/2.0} {y-ah-  _amt_}')\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y}')\n",
    "    else:\n",
    "        ah  = alter1s_fm_bounds[3]-alter1s_fm_bounds[1]-2*_amt_\n",
    "        d_array.append(f'L {x+overall_w/2.0} {y-ah-  _amt_}  C {x+overall_w/2.0} {y-ah-2*_amt_} {x+overall_w/2.0} {y-ah-2*_amt_} {x+narrow_w/2.0}  {y-ah-2*_amt_}')\n",
    "        a2y  = alter2s_fm_bounds[3] - 2*r_pref\n",
    "        d_array.append(f'L {x+narrow_w/2.0}  {a2y}           C {x+overall_w/2.0} {a2y}          {x+overall_w/2.0} {a2y}          {x+overall_w/2.0} {a2y-2*_amt_}')\n",
    "        a2y2 = alter2s_fm_bounds[1] + 2*_amt_\n",
    "        d_array.append(f'L {x+overall_w/2.0} {a2y2}')\n",
    "        d_array.append(f'C {x+overall_w/2.0} {a2y2-2*_amt_} {x+overall_w/2.0} {a2y2-2*_amt_} {x+narrow_w/2.0}  {a2y2-2*_amt_}')\n",
    "        d_array.append(f'L {x-narrow_w/2.0}  {a2y2-2*_amt_}  C {x-overall_w/2.0} {a2y2-2*_amt_} {x-overall_w/2.0} {a2y2-2*_amt_} {x-overall_w/2.0} {a2y2}')\n",
    "        d_array.append(f'L {x-overall_w/2.0} {a2y -2*_amt_}  C {x-overall_w/2.0} {a2y}          {x-overall_w/2.0} {a2y}          {x-narrow_w/2.0}  {a2y}')\n",
    "        d_array.append(f'L {x-narrow_w/2.0}  {y-ah-2*_amt_}  C {x-overall_w/2.0} {y-ah-2*_amt_} {x-overall_w/2.0} {y-ah-2*_amt_} {x-overall_w/2.0} {y-ah-  _amt_}')\n",
    "        d_array.append(f'L {x-overall_w/2.0} {y}')\n",
    "\n",
    "    svg.append(f'<path d=\"{\"\".join(d_array)}\" stroke=\"{self.rt_self.co_mgr.getTVColor(\"axis\",\"major\")}\" stroke-width=\"2.0\" fill=\"none\" />')\n",
    "\n",
    "    return ''.join(svg), (x-max_w/2, y-max_h/2, x+max_w/2, y+max_h/2)\n",
    "\n",
    "sl.renderBin = renderBin.__get__(sl, SpreadLines)\n",
    "\n",
    "alter_inter_d = 192\n",
    "max_bin_w     = 64\n",
    "max_bin_h     = 450*2\n",
    "svg = []\n",
    "svg.append(f'<svg x=\"0\" y=\"0\" width=\"{1536}\" height=\"{768}\" viewBox=\"0 0 2048 1024\">')\n",
    "svg.append(f'<rect x=\"0\" y=\"0\" width=\"{2048}\" height=\"{1024}\" fill=\"{rt.co_mgr.getTVColor(\"background\",\"default\")}\" />')\n",
    "_bins_ordered_ = list(sl.bin_to_timestamps.keys())\n",
    "_bins_ordered_.sort()\n",
    "x = max_bin_w\n",
    "for _bin_ in _bins_ordered_:\n",
    "    _svg_, _bounds_ = sl.renderBin(_bin_, x, (1024-max_bin_h)/2 + max_bin_h/2, max_bin_w, max_bin_h)\n",
    "    svg.append(_svg_)\n",
    "    xmin, ymin, xmax, ymax = _bounds_\n",
    "    x += alter_inter_d + max_bin_w\n",
    "svg.append('</svg>')\n",
    "rt.tile([''.join(svg)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
